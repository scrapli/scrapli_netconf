{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"scrapli_netconf","text":"<p>scrapli_netconf is a netconf driver built on top of scrapli. The purpose  of scrapli_netconf is to provide a fast, flexible, thoroughly tested, well typed, well documented, simple API that   supports both synchronous and asynchronous usage. Working together scrapli and scrapli_netconf aim to provide a    consistent (as is practical) look and feel when automating devices over telnet, SSH, or netconf (over SSH). </p> <p>scrapli_netconf aims to be fully RFC compliant at some point, but at the moment does not implement all netconf  features/methods.</p>"},{"location":"changelog/","title":"CHANGELOG","text":""},{"location":"changelog/#20230130","title":"2023.01.30","text":"<ul> <li>Handle parsing out control characters that seem to pop up on some JunOS boxes with at least ssh2 transport, see #127.</li> <li>Hopefully improved some handling with possible \"over reading\" during initial session establishment. See #122 for a    lot of history on this one, and #126 for at least a partial fix (if not full fix?!)</li> <li>Thanks to sanjmonkey for expanding support for \"with-defaults\" parsing from    capabilities in #129</li> </ul>"},{"location":"changelog/#20220730","title":"2022.07.30","text":"<ul> <li>Thank you to the very awesome  dmulyalin for adding support for commit-confirmed    in #97!</li> <li>Some other things, I'm sure of it... if nothing else just housekeeping things... if we've missed something you    added in  here, let us know and it will get added!</li> </ul>"},{"location":"changelog/#20220130","title":"2022.01.30","text":"<ul> <li>Removed deprecated <code>filters</code> argument</li> <li>Removed deprecated <code>NetconfScrape</code> and <code>AsyncNetconfScrape</code></li> <li>Improved <code>raise_for_status</code> exception messages, see #92 and #90</li> <li>Dropped Python3.6 support as it is now EOL! Of course, scrapli probably still works just fine with 3.6 (if you    install the old 3.6 requirements), but we won't test/support it anymore.</li> </ul>"},{"location":"changelog/#20210730","title":"2021.07.30","text":"<ul> <li>Force system transport ssh connections to allocate a tty (-tt); fixes issue that would prevent system transport    from sending any command &gt; 1024 chars.</li> <li>Added <code>use_compressed_parser</code> argument to the driver constructor -- defaults to <code>True</code> which means we \"squish\" all    the whitespace out of any input we get from the user before sending it to the netconf server, generally this is no    problem, but some devices (looking at you NX-OS!) lock up and stop reading at some character counts (4096 in NX-OS    it seems) causing the connection to timeout and die. By not \"squishing\" whitespace out this does not happen.</li> <li>Fixed some typing issues and pinned to scrapli pre-release to take advantage of updated typing/packaging setup  </li> <li>Deprecate <code>filters</code> argument on <code>get_config</code> -- will be supported (by decorator) until 2022.01.30 (and    pre-releases). This was done to make the arguments consistent for <code>get</code>, <code>get_config</code>, and <code>rpc</code>.</li> <li>Better handling of multiple filter elements in a filter string</li> <li>Smarter message building -- previously most of the final bytes payload that we send to the servers got built in    the base driver class, and then some more (1.1 encoding) got added in the channel base class -- silly! Fixed this,    so it is all done in the driver which eliminated a bunch of duplication (yay!).</li> <li>Deprecating <code>comms_ansi</code> -- see also scrapli changelog for this release (2021.07.30) for more details. This was    never used here in scrapli_netconf so should be a non issue, but will not be fully deprecated until 2022.01.30.</li> <li>Re-fix #10... see #68 -- now there is a test with a comment so I don't break this again :)</li> <li>Added <code>copy_config</code> method, thanks to Roman Dodin for adding this in scrapligo first!</li> <li>Added handling/warning about <code>use_compressed_parser</code> if we catch a timeout exception when looking for prompt after    writing inputs -- since I don't know (can't know?) which platforms may require this flag set to False this seems    like a reasonable way to let users know and point them in the right direction to get things working!</li> <li>Reswizzled the echo check to be like the scrapligo version -- much simpler/less moving parts, so should be good!</li> </ul>"},{"location":"changelog/#20210130","title":"2021.01.30","text":"<ul> <li>Big overhaul in line with the scrapli core overhaul... mostly this was about reconciliation of the channel and    transport things and putting stuff where it should have been in the first place... see the changelog at scrapli    core for much more details</li> <li>FUTURE BREAKING CHANGE -- <code>NetconfScrape</code> and <code>AsyncNetconfScrape</code> have been renamed to <code>NetconfDriver</code> and    <code>AsyncNetconfDriver</code> -- there are alias classes so you can continue to use <code>NetconfScrape</code> and    <code>AsyncNetconfScrape</code> but there is a warning, and these will be removed at some point in the future!</li> </ul>"},{"location":"changelog/#20210117","title":"2021.01.17","text":"<ul> <li>Support for future \"vrouter\" setup for testing</li> <li>Flatten all channel inputs (no pretty printed xml) -- seems to behave much more nicely across the board!</li> <li>Updated test to match some recent scrapli core updates (multipl easync transports)</li> </ul>"},{"location":"changelog/#20201115","title":"2020.11.15","text":"<ul> <li>Support namespaces in hello messages -- primarily to support \"rfc-compliant\" mode in JunOS -- thank you   Gary Napier for finding this and coming up with the fix!</li> <li>Another fixup to chunk checker -- think that the itty bitty chunk issues have now been solved :)</li> </ul>"},{"location":"changelog/#20201024","title":"2020.10.24","text":"<ul> <li>Improve the \"echo\" checker -- and add this for sync as well, because...</li> <li>SSH2 and Paramiko are now supported transports!</li> <li>As part of the \"improved echo checker\" sync channel now also overrides the read_until_input method like the async  channel does -- again, for the same reasons.</li> <li>All transports minus system are now optional extras -- this means that asyncssh is no longer an install requirement</li> <li>As expected with above point -- added optional extras install options in setup.py as well as a \"full\" option just  like scrapli core</li> <li>MAYBE BREAKING CHANGE: shouldn't be an issue for 99.9999% of people, however, the asyncssh transport is no longer  imported and available in the transport package</li> <li>Add <code>error_messages</code> attribute to response object -- initialized as an empty list and the text of any <code>rpc-error/error -message</code> fields are placed into this list if there are any in the response from the server</li> <li>Improve netconf 1.1 chunk matching regex to not ignore/chop off Nokia error messages that contained <code>#</code> symbols</li> </ul>"},{"location":"changelog/#20201010","title":"2020.10.10","text":"<ul> <li>Handle netconf 1.1 devices that have chunk sizes of 1</li> <li>Ensure results are \"pretty printed\"</li> <li>Above two items were worked out with thanks to Hugo Tinoco! PS - this has been tested on Nokia devices now too!</li> <li>Hopefully improved asyncssh \"echo checker\" (see _check_echo) method in async_channel for details</li> <li>Update CI to use 3.9 instead of 3.9-dev (and update deprecated set-env)</li> <li>Remove transport session locks</li> </ul>"},{"location":"changelog/#20200923","title":"2020.09.23","text":"<ul> <li>Strip server capabilities so we don't save capabilities with newlines/whitespace</li> <li>Add <code>validate</code> and <code>delete_config</code> methods</li> </ul>"},{"location":"changelog/#20200918","title":"2020.09.18","text":"<ul> <li>Fix some pins for dev requirements</li> <li>Add 3.9-dev to actions</li> <li>Fix <code>scrapli-asycnssh</code> not in setup.py <code>install_requires</code></li> <li>Retest everything! In general, just get this updated/ready for <code>nornir-scrapli</code>!</li> </ul>"},{"location":"changelog/#20200726","title":"2020.07.26","text":"<ul> <li>Update to match scrapli core -- moved to updated timeout decorator, fixed a test to match a better exception message</li> </ul>"},{"location":"changelog/#20200712","title":"2020.07.12","text":"<ul> <li>Minor improvements to response recording (should be a tick faster)</li> <li>Update decorators for async things to use the improved <code>async_operation_timeout</code> in scrapli 2020.07.12</li> <li>Set <code>strip_namespaces</code> to <code>False</code> for <code>AsyncNetconfScrape</code> for consistency/sanity</li> <li>Update a few dev pins, update required pins to ensure no major lxml updates break things</li> </ul>"},{"location":"changelog/#20200704","title":"2020.07.04","text":"<ul> <li>First real release??? :)</li> </ul>"},{"location":"changelog/#20200419","title":"2020.04.19","text":"<ul> <li>Initial pypi release... very beta still</li> </ul>"},{"location":"about/code_of_conduct/","title":"Code of Conduct","text":"<p>Be excellent to each other!</p>"},{"location":"about/contributing/","title":"Contributing","text":"<p>Thanks for thinking about contributing! Contributions are not expected, but are quite welcome.</p> <p>Contributions of all kinds are welcomed -- typos, doc updates, adding examples, bug fixes, and feature adds.</p> <p>Some notes on contributing:</p> <ul> <li>Please open a GitHub discussion topic for any potential feature adds/changes to discuss them prior to opening a PR,   this way everyone has a chance to chime in and make sure we're all on the same page!</li> <li>Please open an issue to discuss any bugs/bug fixes prior to opening a PR.</li> <li>Once we all have discussed any adds/changes, pull requests are very much welcome and appreciated!</li> <li>All PRs should pass tests/CI linting -- checkout the Makefile for some shortcuts for linting and testing.</li> <li>Please include tests! Even simple/basic tests are better than nothing -- it helps make sure changes in the future    don't break functionality or make things act in unexpected ways!</li> </ul>"},{"location":"more_scrapli/nornir_scrapli/","title":"Nornir scrapli","text":"<p>If you want to use scrapli, but don't want to deal with handling concurrency yourself, there is great news! The  nornir_scrapli plugin allows you to use scrapli (and scrapli netconf  and scrapli cfg) within the Nornir framework!</p>"},{"location":"more_scrapli/scrapli/","title":"Scrapli","text":"<p>scrapli (docs) is the  \"parent\" scrapli library. Check it out if you need to connect to devices with telnet or ssh!</p>"},{"location":"more_scrapli/scrapli_cfg/","title":"Scrapli Cfg","text":"<p>scrapli_cfg (docs)  is utility that accepts a scrapli Telnet or SSH connection and provides configuration management capabilities.  scrapli_cfg allows you to load candidate configurations for merge or replace operations, generate diffs of the  current vs candidate, and of course commit or abort the candidate configuration.</p>"},{"location":"more_scrapli/scrapli_community/","title":"Scrapli Community","text":"<p>If you would like to use scrapli, but the platform(s) that you work with are not supported in the \"core\" scrapli  platforms, you should check out scrapli_community! This is the place  for users to share \"non-core\" scrapli platforms.</p>"},{"location":"more_scrapli/scrapli_replay/","title":"Scrapli Replay","text":"<p>scrapli_replay (docs)  is a set of tools used to help test scrapli programs. scrapli_replay includes a utility to capture command  input/output from real life servers and replay them in a semi-interactive fashion, as well as a pytest plugin that  patches and records and replays session data (like vcr.py) for scrapli connections. </p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>channel<ul> <li>async_channel</li> <li>base_channel</li> <li>sync_channel</li> </ul> </li> <li>constants</li> <li>driver<ul> <li>async_driver</li> <li>base_driver</li> <li>sync_driver</li> </ul> </li> <li>exceptions</li> <li>helper</li> <li>response</li> <li>transport<ul> <li>plugins<ul> <li>asyncssh<ul> <li>transport</li> </ul> </li> <li>paramiko<ul> <li>transport</li> </ul> </li> <li>ssh2<ul> <li>transport</li> </ul> </li> <li>system<ul> <li>transport</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/constants/","title":"constants","text":"<p>scrapli_netconf.constants</p>"},{"location":"reference/exceptions/","title":"exceptions","text":"<p>scrapli_netconf.exceptions</p>"},{"location":"reference/exceptions/#exceptions.CapabilityNotSupported","title":"<code>CapabilityNotSupported</code>","text":"<p>         Bases: <code>ScrapliException</code></p> <p>Exception for unsupported capabilities</p> Source code in <code>scrapli_netconf/exceptions.py</code> <pre><code>class CapabilityNotSupported(ScrapliException):\n\"\"\"Exception for unsupported capabilities\"\"\"\n</code></pre>"},{"location":"reference/exceptions/#exceptions.CouldNotExchangeCapabilities","title":"<code>CouldNotExchangeCapabilities</code>","text":"<p>         Bases: <code>ScrapliException</code></p> <p>Exception for failure of capabilities exchange</p> Source code in <code>scrapli_netconf/exceptions.py</code> <pre><code>class CouldNotExchangeCapabilities(ScrapliException):\n\"\"\"Exception for failure of capabilities exchange\"\"\"\n</code></pre>"},{"location":"reference/helper/","title":"helper","text":"<p>scrapli_netconf.helper</p>"},{"location":"reference/helper/#helper.remove_namespaces","title":"<code>remove_namespaces(tree: Element) -&gt; Element</code>","text":"<p>Remove all namespace tags from Element object</p> <p>Replace element tags like: {http://cisco.com/ns/yang/Cisco-IOS-XR-ipv4-bgp-oper}connection-state With: connection-state</p> <p>Parameters:</p> Name Type Description Default <code>tree</code> <code>Element</code> <p>lxml Element</p> required <p>Returns:</p> Name Type Description <code>Element</code> <code>Element</code> <p>lxml Element with namespaces stripped out</p> Source code in <code>scrapli_netconf/helper.py</code> <pre><code>def remove_namespaces(tree: Element) -&gt; Element:\n\"\"\"\n    Remove all namespace tags from Element object\n\n    Replace element tags like: {http://cisco.com/ns/yang/Cisco-IOS-XR-ipv4-bgp-oper}connection-state\n    With: connection-state\n\n    Args:\n        tree: lxml Element\n\n    Returns:\n        Element: lxml Element with namespaces stripped out\n\n    Raises:\n        N/A\n\n    \"\"\"\n    for el in tree.getiterator():\n        if not hasattr(el.tag, \"find\"):\n            continue\n        el.tag = re.sub(r\"^{.*}\", \"\", el.tag)\n    objectify.deannotate(tree, cleanup_namespaces=True)\n    return tree\n</code></pre>"},{"location":"reference/response/","title":"response","text":"<p>scrapli_netconf.response</p>"},{"location":"reference/response/#response.NetconfResponse","title":"<code>NetconfResponse</code>","text":"<p>         Bases: <code>Response</code></p> Source code in <code>scrapli_netconf/response.py</code> <pre><code>class NetconfResponse(Response):\n    # intentionally overriding base class' list of strings for failed when contains\n    failed_when_contains: List[bytes]  # type: ignore[assignment]\n\n    def __init__(\n        self,\n        netconf_version: NetconfVersion,\n        xml_input: Element,\n        strip_namespaces: bool = True,\n        failed_when_contains: Optional[Union[bytes, List[bytes]]] = None,\n        **kwargs: Any,\n    ):\n\"\"\"\n        Scrapli Netconf NetconfResponse\n\n        Store channel_input, resulting output, and start/end/elapsed time information. Attempt to\n        determine if command was successful or not and reflect that in a failed attribute.\n\n        Args:\n            netconf_version: string of netconf version; `1.0`|`1.1`\n            xml_input: lxml Element of input to be sent to device\n            strip_namespaces: strip out all namespaces if True, otherwise ignore them\n            failed_when_contains: list of bytes that, if present in final output, represent a\n                failed command/interaction -- should generally be left alone for netconf. Note that\n                this differs from the base scrapli Response object as we want to be parsing/checking\n                for these strings in raw byte strings we get back from the device\n            kwargs: kwargs for instantiation of scrapli Response object supertype\n\n        Returns:\n            N/A  # noqa: DAR202\n\n        Raises:\n            ValueError: if invalid netconf_version string\n\n        \"\"\"\n        if netconf_version not in (NetconfVersion.VERSION_1_0, NetconfVersion.VERSION_1_1):\n            raise ValueError(f\"`netconf_version` should be one of 1.0|1.1, got `{netconf_version}`\")\n\n        self.netconf_version = netconf_version\n        self.xml_input = xml_input\n        self.strip_namespaces = strip_namespaces\n        self.xml_result: Element\n\n        super().__init__(**kwargs)\n\n        if failed_when_contains is None:\n            # match on both opening and closing tags too so we never have to think about/compare\n            # things with namespaces (the closing tags wont have namespaces)\n            failed_when_contains = [\n                b\"&lt;/rpc-error&gt;\",\n                b\"&lt;/rpc-errors&gt;\",\n                b\"&lt;rpc-error&gt;\",\n                b\"&lt;rpc-errors&gt;\",\n            ]\n        if isinstance(failed_when_contains, bytes):\n            failed_when_contains = [failed_when_contains]\n        self.failed_when_contains = failed_when_contains\n\n        self.error_messages: List[str] = []\n\n    def record_response(self, result: bytes) -&gt; None:\n\"\"\"\n        Record channel_input results and elapsed time of channel input/reading output\n\n        Args:\n            result: bytes result of channel_input\n\n        Returns:\n            N/A\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.finish_time = datetime.now()\n        self.elapsed_time = (self.finish_time - self.start_time).total_seconds()\n        self.raw_result = result\n\n        if not self.failed_when_contains:\n            self.failed = False\n        elif not any(err in self.raw_result for err in self.failed_when_contains):\n            self.failed = False\n\n        if self.netconf_version == NetconfVersion.VERSION_1_0:\n            self._record_response_netconf_1_0()\n        else:\n            self._record_response_netconf_1_1()\n\n        if self.failed:\n            self._fetch_error_messages()\n\n    @classmethod\n    def _parse_raw_result(cls, raw_result: bytes) -&gt; bytes:\n        # remove the message end characters and xml document header see:\n        # https://github.com/scrapli/scrapli_netconf/issues/1\n        _raw_result = raw_result.replace(b\"]]&gt;]]&gt;\", b\"\").replace(\n            b'&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;', b\"\"\n        )\n\n        parsed_result: Union[bytes, None] = etree.fromstring(\n            _raw_result,\n            parser=PARSER,\n        )\n\n        if parsed_result is None:\n            # if we failed to parse, try again after stripping out control chars, if we still\n            # end up with None, oh well, raise an exception later on down the road\n            parsed_result = etree.fromstring(\n                CONTROL_CHARS.sub(b\"\", _raw_result),\n                parser=PARSER,\n            )\n\n        return parsed_result\n\n    def _record_response_netconf_1_0(self) -&gt; None:\n\"\"\"\n        Record response for netconf version 1.0\n\n        Args:\n            N/A\n\n        Returns:\n            N/A  # noqa: DAR202\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.xml_result = self._parse_raw_result(self.raw_result)\n\n        if self.strip_namespaces:\n            self.xml_result = remove_namespaces(self.xml_result)\n            self.result = etree.tostring(self.xml_result, pretty_print=True).decode()\n        else:\n            self.result = etree.tostring(self.xml_result, pretty_print=True).decode()\n\n    def _validate_chunk_size_netconf_1_1(self, result: Tuple[int, bytes]) -&gt; None:\n\"\"\"\n        Validate individual chunk size; handle parsing trailing new lines for chunk sizes\n\n        It seems that some platforms behave slightly differently than others (looking at you IOSXE)\n        in the way they count chunk sizes with respect to trailing whitespace. Per my reading of the\n        RFC, the response for a netconf 1.1 response should look like this:\n\n        ```\n        ##XYZ\n        &lt;somexml&gt;\n        ##\n        ```\n\n        Where \"XYZ\" is an integer number of the count of chars in the following chunk (the chars up\n        to the next \"##\" symbols), then the actual XML response, then a new line(!!!!) and a pair of\n        hash symbols to indicate the chunk is complete.\n\n        IOSXE seems to *not* want to see the newline between the XML payload and the double hash\n        symbols... instead when it sees that newline it immediately returns the response. This\n        breaks the core behavior of scrapli in that scrapli always writes the input, then reads the\n        written inputs off the channel *before* sending a return character. This ensures that we\n        never have to deal with stripping out the inputs and such because it has already been read.\n        With IOSXE Behaving this way, we have to instead use `send_input` with the `eager` flag set\n        -- this means that we do *not* read the inputs, we simply send a return. We then have to do\n        a little extra parsing to strip out the inputs, but thats no big deal...\n\n        Where this finally gets to \"spacing\" -- IOSXE seems to include trailing newlines *sometimes*\n        but not other times, whereas IOSXR (for example) *always* counts a single trailing newline\n        (after the XML). SO.... long story long... (the above chunk stuff doesn't necessarily matter\n        for this, but felt like as good a place to document it as any...) this method deals w/\n        newline counts -- we check the expected chunk length against the actual char count, the char\n        count with all trailing whitespace stripped, and the count of the chunk + a *single*\n        trailing newline character...\n\n        FIN\n\n        Args:\n            result: Tuple from re.findall parsing the full response object\n\n        Returns:\n            N/A\n\n        Raises:\n            N/A\n\n        \"\"\"\n        expected_len, result_value = result\n\n        actual_len = len(result_value)\n        rstripped_len = len(result_value.rstrip())\n\n        trailing_newline_count = actual_len - rstripped_len\n        if trailing_newline_count &gt; 1:\n            extraneous_trailing_newline_count = trailing_newline_count - 1\n        else:\n            extraneous_trailing_newline_count = 1\n        trimmed_newline_len = actual_len - extraneous_trailing_newline_count\n\n        if rstripped_len == 0:\n            # at least nokia tends to have itty bitty chunks of one element, and/or chunks that have\n            # *only* whitespace and our regex ignores this, so if there was/is nothing in the result\n            # section we can assume it was just whitespace and move on w/our lives\n            actual_len = expected_len\n\n        if expected_len == actual_len:\n            return\n        if expected_len == rstripped_len:\n            return\n        if expected_len == trimmed_newline_len:\n            return\n\n        LOG.critical(\n            f\"Return element length invalid, expected {expected_len} got {actual_len} for \"\n            f\"element: {repr(result_value)}\"\n        )\n        self.failed = True\n\n    def _record_response_netconf_1_1(self) -&gt; None:\n\"\"\"\n        Record response for netconf version 1.1\n\n        Args:\n            N/A\n\n        Returns:\n            N/A\n\n        Raises:\n            N/A\n\n        \"\"\"\n        chunk_sizes = re.finditer(pattern=CHUNK_MATCH_1_1, string=self.raw_result)\n\n        result_sections: List[Tuple[int, bytes]] = []\n\n        for chunk_match in chunk_sizes:\n            chunk_size = int(chunk_match.groupdict().get(\"size\", 0))\n            chunk_end_pos = chunk_match.span()[1]\n            result_sections.append(\n                (chunk_size, self.raw_result[chunk_end_pos : chunk_end_pos + chunk_size])  # noqa\n            )\n\n        # validate all received data\n        for result in result_sections:\n            self._validate_chunk_size_netconf_1_1(result=result)\n\n        self.xml_result = etree.fromstring(\n            b\"\\n\".join(\n                [\n                    # remove the message end characters and xml document header see:\n                    # https://github.com/scrapli/scrapli_netconf/issues/1\n                    result[1].replace(b'&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;', b\"\")\n                    for result in result_sections\n                ]\n            ),\n            parser=PARSER,\n        )\n\n        if self.strip_namespaces:\n            self.xml_result = remove_namespaces(self.xml_result)\n            self.result = etree.tostring(self.xml_result, pretty_print=True).decode()\n        else:\n            self.result = etree.tostring(self.xml_result, pretty_print=True).decode()\n\n    def _fetch_error_messages(self) -&gt; None:\n\"\"\"\n        Fetch all error messages (if any)\n\n        RFC states that there MAY be more than one rpc-error so we just xpath for all\n        \"error-message\" tags and pull out the text of those elements. The strip is just to remove\n        leading/trailing white space to make things look a bit nicer.\n\n        Args:\n            N/A\n\n        Returns:\n            N/A\n\n        Raises:\n            N/A\n\n        \"\"\"\n        err_messages = self.xml_result.xpath(\"//rpc-error/error-message\")\n        self.error_messages = [err.text.strip() for err in err_messages]\n\n    def get_xml_elements(self) -&gt; Dict[str, Element]:\n\"\"\"\n        Parse each section under \"data\" into a dict of {tag: Element} for easy viewing/parsing\n\n        Args:\n            N/A\n\n        Returns:\n            xml_elements: dictionary of tag: Element\n\n        Raises:\n            N/A\n\n        \"\"\"\n        xml_elements = {}\n        data_element = self.xml_result.find(\"data\", namespaces=self.xml_result.nsmap)\n\n        # juniper doesn't return data in a \"data\" element for bare rpc calls, guard against that\n        # breaking the iterchildren()\n        if data_element is not None:\n            for child in data_element.iterchildren():\n                _tag = etree.QName(child.tag).localname\n                xml_elements[_tag] = child\n        return xml_elements\n\n    def textfsm_parse_output(\n        self, template: Union[str, TextIO, None] = None, to_dict: bool = True\n    ) -&gt; Union[Dict[str, Any], List[Any]]:\n\"\"\"\n        Parse results with textfsm, always return structured data\n\n        Returns an empty list if parsing fails!\n\n        Args:\n            template: string path to textfsm template or opened textfsm template file\n            to_dict: convert textfsm output from list of lists to list of dicts -- basically create\n                dict from header and row data so it is easier to read/parse the output\n\n        Returns:\n            structured_result: empty list or parsed data from textfsm\n\n        Raises:\n            NotImplementedError: always!\n\n        \"\"\"\n        raise NotImplementedError(\"No textfsm parsing for netconf output!\")\n\n    def genie_parse_output(self) -&gt; Union[Dict[str, Any], List[Any]]:\n\"\"\"\n        Override scrapli Response `genie_parse_output` method; not applicable for netconf\n\n        Args:\n            N/A\n\n        Returns:\n            N/A\n\n        Raises:\n            NotImplementedError: always\n\n        \"\"\"\n        raise NotImplementedError(\"No genie parsing for netconf output!\")\n\n    def raise_for_status(self) -&gt; None:\n\"\"\"\n        Raise a `ScrapliCommandFailure` if any elements are failed\n\n        Overrides scrapli core Response.raise_for_status to include rpc error message(s).\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliCommandFailure: if any elements are failed\n\n        \"\"\"\n        if self.failed:\n            raise ScrapliCommandFailure(\n                f\"operation failed, reported rpc errors: {self.error_messages}\"\n            )\n</code></pre>"},{"location":"reference/response/#response.NetconfResponse.__init__","title":"<code>__init__(netconf_version: NetconfVersion, xml_input: Element, strip_namespaces: bool = True, failed_when_contains: Optional[Union[bytes, List[bytes]]] = None, **kwargs: Any)</code>","text":"<p>Scrapli Netconf NetconfResponse</p> <p>Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute.</p> <p>Parameters:</p> Name Type Description Default <code>netconf_version</code> <code>NetconfVersion</code> <p>string of netconf version; <code>1.0</code>|<code>1.1</code></p> required <code>xml_input</code> <code>Element</code> <p>lxml Element of input to be sent to device</p> required <code>strip_namespaces</code> <code>bool</code> <p>strip out all namespaces if True, otherwise ignore them</p> <code>True</code> <code>failed_when_contains</code> <code>Optional[Union[bytes, List[bytes]]]</code> <p>list of bytes that, if present in final output, represent a failed command/interaction -- should generally be left alone for netconf. Note that this differs from the base scrapli Response object as we want to be parsing/checking for these strings in raw byte strings we get back from the device</p> <code>None</code> <code>kwargs</code> <p>kwargs for instantiation of scrapli Response object supertype</p> required <p>Returns:</p> Type Description <p>N/A  # noqa: DAR202</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if invalid netconf_version string</p> Source code in <code>scrapli_netconf/response.py</code> <pre><code>def __init__(\n    self,\n    netconf_version: NetconfVersion,\n    xml_input: Element,\n    strip_namespaces: bool = True,\n    failed_when_contains: Optional[Union[bytes, List[bytes]]] = None,\n    **kwargs: Any,\n):\n\"\"\"\n    Scrapli Netconf NetconfResponse\n\n    Store channel_input, resulting output, and start/end/elapsed time information. Attempt to\n    determine if command was successful or not and reflect that in a failed attribute.\n\n    Args:\n        netconf_version: string of netconf version; `1.0`|`1.1`\n        xml_input: lxml Element of input to be sent to device\n        strip_namespaces: strip out all namespaces if True, otherwise ignore them\n        failed_when_contains: list of bytes that, if present in final output, represent a\n            failed command/interaction -- should generally be left alone for netconf. Note that\n            this differs from the base scrapli Response object as we want to be parsing/checking\n            for these strings in raw byte strings we get back from the device\n        kwargs: kwargs for instantiation of scrapli Response object supertype\n\n    Returns:\n        N/A  # noqa: DAR202\n\n    Raises:\n        ValueError: if invalid netconf_version string\n\n    \"\"\"\n    if netconf_version not in (NetconfVersion.VERSION_1_0, NetconfVersion.VERSION_1_1):\n        raise ValueError(f\"`netconf_version` should be one of 1.0|1.1, got `{netconf_version}`\")\n\n    self.netconf_version = netconf_version\n    self.xml_input = xml_input\n    self.strip_namespaces = strip_namespaces\n    self.xml_result: Element\n\n    super().__init__(**kwargs)\n\n    if failed_when_contains is None:\n        # match on both opening and closing tags too so we never have to think about/compare\n        # things with namespaces (the closing tags wont have namespaces)\n        failed_when_contains = [\n            b\"&lt;/rpc-error&gt;\",\n            b\"&lt;/rpc-errors&gt;\",\n            b\"&lt;rpc-error&gt;\",\n            b\"&lt;rpc-errors&gt;\",\n        ]\n    if isinstance(failed_when_contains, bytes):\n        failed_when_contains = [failed_when_contains]\n    self.failed_when_contains = failed_when_contains\n\n    self.error_messages: List[str] = []\n</code></pre>"},{"location":"reference/response/#response.NetconfResponse.genie_parse_output","title":"<code>genie_parse_output() -&gt; Union[Dict[str, Any], List[Any]]</code>","text":"<p>Override scrapli Response <code>genie_parse_output</code> method; not applicable for netconf</p> <p>Returns:</p> Type Description <code>Union[Dict[str, Any], List[Any]]</code> <p>N/A</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>always</p> Source code in <code>scrapli_netconf/response.py</code> <pre><code>def genie_parse_output(self) -&gt; Union[Dict[str, Any], List[Any]]:\n\"\"\"\n    Override scrapli Response `genie_parse_output` method; not applicable for netconf\n\n    Args:\n        N/A\n\n    Returns:\n        N/A\n\n    Raises:\n        NotImplementedError: always\n\n    \"\"\"\n    raise NotImplementedError(\"No genie parsing for netconf output!\")\n</code></pre>"},{"location":"reference/response/#response.NetconfResponse.get_xml_elements","title":"<code>get_xml_elements() -&gt; Dict[str, Element]</code>","text":"<p>Parse each section under \"data\" into a dict of {tag: Element} for easy viewing/parsing</p> <p>Returns:</p> Name Type Description <code>xml_elements</code> <code>Dict[str, Element]</code> <p>dictionary of tag: Element</p> Source code in <code>scrapli_netconf/response.py</code> <pre><code>def get_xml_elements(self) -&gt; Dict[str, Element]:\n\"\"\"\n    Parse each section under \"data\" into a dict of {tag: Element} for easy viewing/parsing\n\n    Args:\n        N/A\n\n    Returns:\n        xml_elements: dictionary of tag: Element\n\n    Raises:\n        N/A\n\n    \"\"\"\n    xml_elements = {}\n    data_element = self.xml_result.find(\"data\", namespaces=self.xml_result.nsmap)\n\n    # juniper doesn't return data in a \"data\" element for bare rpc calls, guard against that\n    # breaking the iterchildren()\n    if data_element is not None:\n        for child in data_element.iterchildren():\n            _tag = etree.QName(child.tag).localname\n            xml_elements[_tag] = child\n    return xml_elements\n</code></pre>"},{"location":"reference/response/#response.NetconfResponse.raise_for_status","title":"<code>raise_for_status() -&gt; None</code>","text":"<p>Raise a <code>ScrapliCommandFailure</code> if any elements are failed</p> <p>Overrides scrapli core Response.raise_for_status to include rpc error message(s).</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ScrapliCommandFailure</code> <p>if any elements are failed</p> Source code in <code>scrapli_netconf/response.py</code> <pre><code>def raise_for_status(self) -&gt; None:\n\"\"\"\n    Raise a `ScrapliCommandFailure` if any elements are failed\n\n    Overrides scrapli core Response.raise_for_status to include rpc error message(s).\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        ScrapliCommandFailure: if any elements are failed\n\n    \"\"\"\n    if self.failed:\n        raise ScrapliCommandFailure(\n            f\"operation failed, reported rpc errors: {self.error_messages}\"\n        )\n</code></pre>"},{"location":"reference/response/#response.NetconfResponse.record_response","title":"<code>record_response(result: bytes) -&gt; None</code>","text":"<p>Record channel_input results and elapsed time of channel input/reading output</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>bytes</code> <p>bytes result of channel_input</p> required <p>Returns:</p> Type Description <code>None</code> <p>N/A</p> Source code in <code>scrapli_netconf/response.py</code> <pre><code>def record_response(self, result: bytes) -&gt; None:\n\"\"\"\n    Record channel_input results and elapsed time of channel input/reading output\n\n    Args:\n        result: bytes result of channel_input\n\n    Returns:\n        N/A\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self.finish_time = datetime.now()\n    self.elapsed_time = (self.finish_time - self.start_time).total_seconds()\n    self.raw_result = result\n\n    if not self.failed_when_contains:\n        self.failed = False\n    elif not any(err in self.raw_result for err in self.failed_when_contains):\n        self.failed = False\n\n    if self.netconf_version == NetconfVersion.VERSION_1_0:\n        self._record_response_netconf_1_0()\n    else:\n        self._record_response_netconf_1_1()\n\n    if self.failed:\n        self._fetch_error_messages()\n</code></pre>"},{"location":"reference/response/#response.NetconfResponse.textfsm_parse_output","title":"<code>textfsm_parse_output(template: Union[str, TextIO, None] = None, to_dict: bool = True) -&gt; Union[Dict[str, Any], List[Any]]</code>","text":"<p>Parse results with textfsm, always return structured data</p> <p>Returns an empty list if parsing fails!</p> <p>Parameters:</p> Name Type Description Default <code>template</code> <code>Union[str, TextIO, None]</code> <p>string path to textfsm template or opened textfsm template file</p> <code>None</code> <code>to_dict</code> <code>bool</code> <p>convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output</p> <code>True</code> <p>Returns:</p> Name Type Description <code>structured_result</code> <code>Union[Dict[str, Any], List[Any]]</code> <p>empty list or parsed data from textfsm</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>always!</p> Source code in <code>scrapli_netconf/response.py</code> <pre><code>def textfsm_parse_output(\n    self, template: Union[str, TextIO, None] = None, to_dict: bool = True\n) -&gt; Union[Dict[str, Any], List[Any]]:\n\"\"\"\n    Parse results with textfsm, always return structured data\n\n    Returns an empty list if parsing fails!\n\n    Args:\n        template: string path to textfsm template or opened textfsm template file\n        to_dict: convert textfsm output from list of lists to list of dicts -- basically create\n            dict from header and row data so it is easier to read/parse the output\n\n    Returns:\n        structured_result: empty list or parsed data from textfsm\n\n    Raises:\n        NotImplementedError: always!\n\n    \"\"\"\n    raise NotImplementedError(\"No textfsm parsing for netconf output!\")\n</code></pre>"},{"location":"reference/channel/","title":"channel","text":"<p>scrapli_netconf.channel</p>"},{"location":"reference/channel/async_channel/","title":"async_channel","text":"<p>scrapli_netconf.channel.async_channel</p>"},{"location":"reference/channel/async_channel/#channel.async_channel.AsyncNetconfChannel","title":"<code>AsyncNetconfChannel</code>","text":"<p>         Bases: <code>AsyncChannel</code>, <code>BaseNetconfChannel</code></p> Source code in <code>channel/async_channel.py</code> <pre><code>class AsyncNetconfChannel(AsyncChannel, BaseNetconfChannel):\n    def __init__(\n        self,\n        transport: AsyncTransport,\n        base_channel_args: BaseChannelArgs,\n        netconf_base_channel_args: NetconfBaseChannelArgs,\n    ):\n        super().__init__(transport=transport, base_channel_args=base_channel_args)\n\n        self._netconf_base_channel_args = netconf_base_channel_args\n\n        # always use `]]&gt;]]&gt;` as the initial prompt to match\n        self._base_channel_args.comms_prompt_pattern = \"]]&gt;]]&gt;\"\n        self._server_echo = False\n        self._establishing_server_echo = False\n        self._capabilities_buf = b\"\"\n        self._read_buf = b\"\"\n\n    async def open_netconf(self) -&gt; None:\n\"\"\"\n        Open the netconf channel\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        # open in scrapli core is where we open channel log (if applicable), do that\n        self.open()\n\n        raw_server_capabilities = await self._get_server_capabilities()\n        self._process_capabilities_exchange(raw_server_capabilities=raw_server_capabilities)\n        await self._send_client_capabilities()\n\n    @timeout_wrapper\n    async def _get_server_capabilities(self) -&gt; bytes:\n\"\"\"\n        Read until all server capabilities have been sent by server\n\n        Args:\n            N/A\n\n        Returns:\n            bytes: raw bytes containing server capabilities\n\n        Raises:\n            N/A\n\n        \"\"\"\n        capabilities_buf = self._capabilities_buf\n\n        # reset this to empty to avoid any confusion now that we are moving on\n        self._capabilities_buf = b\"\"\n\n        async with self._channel_lock():\n            while b\"]]&gt;]]&gt;\" not in capabilities_buf:\n                capabilities_buf += await self.read()\n            self.logger.debug(f\"received raw server capabilities: {repr(capabilities_buf)}\")\n        return capabilities_buf\n\n    @timeout_wrapper\n    async def _send_client_capabilities(\n        self,\n    ) -&gt; None:\n\"\"\"\n        Send client capabilities to the netconf server\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        async with self._channel_lock():\n            _ = self._pre_send_client_capabilities(\n                client_capabilities=self._netconf_base_channel_args.client_capabilities\n            )\n            self.send_return()\n\n    async def read(self) -&gt; bytes:\n\"\"\"\n        Read chunks of output from the channel\n\n        Prior to super-ing \"normal\" scrapli read, check if there is anything on our read_buf, if\n        there is, return that first\n\n        Args:\n            N/A\n\n        Returns:\n            bytes: output read from channel\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if self._read_buf:\n            read_buf = self._read_buf\n            self._read_buf = b\"\"\n            return read_buf\n\n        return await super().read()\n\n    async def _read_until_input(self, channel_input: bytes) -&gt; bytes:\n\"\"\"\n        Async read until all input has been entered.\n\n        Args:\n            channel_input: string to write to channel\n\n        Returns:\n            bytes: output read from channel\n\n        Raises:\n            N/A\n\n        \"\"\"\n        output = b\"\"\n\n        if self._server_echo is None or self._server_echo is False:\n            # if server_echo is `None` we dont know if the server echoes yet, so just return nothing\n            # if its False we know it doesnt echo and we can return empty byte string anyway\n            return output\n\n        if not channel_input:\n            self.logger.info(f\"Read: {repr(output)}\")\n            return output\n\n        while True:\n            output += await self.read()\n\n            if self._establishing_server_echo:\n                output, partition, new_buf = output.partition(b\"]]&gt;]]&gt;\")\n                self._read_buf += new_buf\n                output += partition\n                break\n\n            # if we have all the input *or* we see the closing rpc tag we know we are done here\n            if channel_input in output or b\"rpc&gt;\" in output:\n                break\n\n        self.logger.info(f\"Read: {repr(output)}\")\n        return output\n\n    async def send_input_netconf(self, channel_input: str) -&gt; bytes:\n\"\"\"\n        Send inputs to netconf server\n\n        Args:\n            channel_input: string of the base xml message to send to netconf server\n\n        Returns:\n            bytes: bytes result of message sent to netconf server\n\n        Raises:\n            N/A\n\n        \"\"\"\n        bytes_final_channel_input = channel_input.encode()\n\n        buf: bytes\n        buf, _ = await super().send_input(\n            channel_input=channel_input, strip_prompt=False, eager=True\n        )\n\n        if bytes_final_channel_input in buf:\n            buf = buf.split(bytes_final_channel_input)[1]\n\n        buf = await self._read_until_prompt(buf=buf)\n\n        if self._server_echo is None:\n            # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT\n            # echo the input commands back to the client. In the case of \"normal\" scrapli netconf\n            # with the system transport this happens anyway because we combine the stdin and stdout\n            # fds into a single pty, however for other transports we have an actual stdin and\n            # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems\n            # to want to echo inputs back onto to the stdout for the channel. This is totally ok\n            # and we can deal with it, we just need to *know* that it is happening, so while the\n            # _server_echo attribute is still `None`, we can go ahead and see if the input we sent\n            # is in the output we read off the channel. If it is *not* we know the server does *not*\n            # echo and we can move on. If it *is* in the output, we know the server echoes, and we\n            # also have one additional step in that we need to read \"until prompt\" again in order to\n            # capture the reply to our rpc.\n            #\n            # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\")\n\n            self.logger.debug(\"server echo is unset, determining if server echoes inputs now\")\n\n            # we may be reading the remainder of the echo from our capabilities message -- if we see\n            # that we know the server echoes, but we still need to read until our latest input.\n            if b\"&lt;/hello&gt;]]&gt;]]&gt;\" in buf:\n                self.logger.debug(\"server echoes inputs, setting _server_echo to 'true'\")\n                self._server_echo = True\n\n                _, _, buf = buf.partition(b\"&lt;/hello&gt;]]&gt;]]&gt;\")\n                if buf:\n                    # if we read past the end of the\n                    self._read_buf += buf\n\n                # read up till our new input now to consume it from the channel\n                self._establishing_server_echo = True\n                await self._read_until_input(bytes_final_channel_input)\n            elif bytes_final_channel_input in buf:\n                self.logger.debug(\"server echoes inputs, setting _server_echo to 'true'\")\n                self._server_echo = True\n            else:\n                self.logger.debug(\"server does *not* echo inputs, setting _server_echo to 'false'\")\n                self._server_echo = False\n\n            if self._server_echo:\n                # done with the establishment process\n                self._establishing_server_echo = False\n\n                # since echo is True and we only read until our input (because our inputs always end\n                # with a \"prompt\" that we read until) we need to once again read until prompt, this\n                # read will read all the way up through the *reply* to the prompt at end of the\n                # reply message\n                buf = await self._read_until_prompt(buf=b\"\")\n\n        if self._netconf_base_channel_args.netconf_version == NetconfVersion.VERSION_1_1:\n            # netconf 1.1 with \"chunking\" style message format needs an extra return char here\n            self.send_return()\n\n        # we should be able to simply partition here and put any \"over reads\" back into the read buf\n\n        return buf\n</code></pre>"},{"location":"reference/channel/async_channel/#channel.async_channel.AsyncNetconfChannel.open_netconf","title":"<code>open_netconf() -&gt; None</code>  <code>async</code>","text":"<p>Open the netconf channel</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>channel/async_channel.py</code> <pre><code>async def open_netconf(self) -&gt; None:\n\"\"\"\n    Open the netconf channel\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    # open in scrapli core is where we open channel log (if applicable), do that\n    self.open()\n\n    raw_server_capabilities = await self._get_server_capabilities()\n    self._process_capabilities_exchange(raw_server_capabilities=raw_server_capabilities)\n    await self._send_client_capabilities()\n</code></pre>"},{"location":"reference/channel/async_channel/#channel.async_channel.AsyncNetconfChannel.read","title":"<code>read() -&gt; bytes</code>  <code>async</code>","text":"<p>Read chunks of output from the channel</p> <p>Prior to super-ing \"normal\" scrapli read, check if there is anything on our read_buf, if there is, return that first</p> <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>output read from channel</p> Source code in <code>channel/async_channel.py</code> <pre><code>async def read(self) -&gt; bytes:\n\"\"\"\n    Read chunks of output from the channel\n\n    Prior to super-ing \"normal\" scrapli read, check if there is anything on our read_buf, if\n    there is, return that first\n\n    Args:\n        N/A\n\n    Returns:\n        bytes: output read from channel\n\n    Raises:\n        N/A\n\n    \"\"\"\n    if self._read_buf:\n        read_buf = self._read_buf\n        self._read_buf = b\"\"\n        return read_buf\n\n    return await super().read()\n</code></pre>"},{"location":"reference/channel/async_channel/#channel.async_channel.AsyncNetconfChannel.send_input_netconf","title":"<code>send_input_netconf(channel_input: str) -&gt; bytes</code>  <code>async</code>","text":"<p>Send inputs to netconf server</p> <p>Parameters:</p> Name Type Description Default <code>channel_input</code> <code>str</code> <p>string of the base xml message to send to netconf server</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>bytes result of message sent to netconf server</p> Source code in <code>channel/async_channel.py</code> <pre><code>async def send_input_netconf(self, channel_input: str) -&gt; bytes:\n\"\"\"\n    Send inputs to netconf server\n\n    Args:\n        channel_input: string of the base xml message to send to netconf server\n\n    Returns:\n        bytes: bytes result of message sent to netconf server\n\n    Raises:\n        N/A\n\n    \"\"\"\n    bytes_final_channel_input = channel_input.encode()\n\n    buf: bytes\n    buf, _ = await super().send_input(\n        channel_input=channel_input, strip_prompt=False, eager=True\n    )\n\n    if bytes_final_channel_input in buf:\n        buf = buf.split(bytes_final_channel_input)[1]\n\n    buf = await self._read_until_prompt(buf=buf)\n\n    if self._server_echo is None:\n        # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT\n        # echo the input commands back to the client. In the case of \"normal\" scrapli netconf\n        # with the system transport this happens anyway because we combine the stdin and stdout\n        # fds into a single pty, however for other transports we have an actual stdin and\n        # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems\n        # to want to echo inputs back onto to the stdout for the channel. This is totally ok\n        # and we can deal with it, we just need to *know* that it is happening, so while the\n        # _server_echo attribute is still `None`, we can go ahead and see if the input we sent\n        # is in the output we read off the channel. If it is *not* we know the server does *not*\n        # echo and we can move on. If it *is* in the output, we know the server echoes, and we\n        # also have one additional step in that we need to read \"until prompt\" again in order to\n        # capture the reply to our rpc.\n        #\n        # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\")\n\n        self.logger.debug(\"server echo is unset, determining if server echoes inputs now\")\n\n        # we may be reading the remainder of the echo from our capabilities message -- if we see\n        # that we know the server echoes, but we still need to read until our latest input.\n        if b\"&lt;/hello&gt;]]&gt;]]&gt;\" in buf:\n            self.logger.debug(\"server echoes inputs, setting _server_echo to 'true'\")\n            self._server_echo = True\n\n            _, _, buf = buf.partition(b\"&lt;/hello&gt;]]&gt;]]&gt;\")\n            if buf:\n                # if we read past the end of the\n                self._read_buf += buf\n\n            # read up till our new input now to consume it from the channel\n            self._establishing_server_echo = True\n            await self._read_until_input(bytes_final_channel_input)\n        elif bytes_final_channel_input in buf:\n            self.logger.debug(\"server echoes inputs, setting _server_echo to 'true'\")\n            self._server_echo = True\n        else:\n            self.logger.debug(\"server does *not* echo inputs, setting _server_echo to 'false'\")\n            self._server_echo = False\n\n        if self._server_echo:\n            # done with the establishment process\n            self._establishing_server_echo = False\n\n            # since echo is True and we only read until our input (because our inputs always end\n            # with a \"prompt\" that we read until) we need to once again read until prompt, this\n            # read will read all the way up through the *reply* to the prompt at end of the\n            # reply message\n            buf = await self._read_until_prompt(buf=b\"\")\n\n    if self._netconf_base_channel_args.netconf_version == NetconfVersion.VERSION_1_1:\n        # netconf 1.1 with \"chunking\" style message format needs an extra return char here\n        self.send_return()\n\n    # we should be able to simply partition here and put any \"over reads\" back into the read buf\n\n    return buf\n</code></pre>"},{"location":"reference/channel/base_channel/","title":"base_channel","text":"<p>scrapli_netconf.channel.base_channel</p>"},{"location":"reference/channel/base_channel/#channel.base_channel.BaseNetconfChannel","title":"<code>BaseNetconfChannel</code>","text":"<p>         Bases: <code>BaseChannel</code></p> Source code in <code>channel/base_channel.py</code> <pre><code>class BaseNetconfChannel(BaseChannel):\n    _netconf_base_channel_args: NetconfBaseChannelArgs\n\n    def _process_capabilities_exchange(self, raw_server_capabilities: bytes) -&gt; None:\n\"\"\"\n        Process received capabilities; return client capabilities\n\n        Args:\n            raw_server_capabilities: raw bytes containing server capabilities\n\n        Returns:\n            None\n\n        Raises:\n            CapabilityNotSupported: if user has provided a preferred netconf version but it is not\n                available in servers offered capabilities\n\n        \"\"\"\n        server_capabilities = self._parse_server_capabilities(\n            raw_server_capabilities=raw_server_capabilities\n        )\n        self._netconf_base_channel_args.server_capabilities = server_capabilities\n\n        if \"urn:ietf:params:netconf:base:1.1\" in server_capabilities:\n            final_channel_version = NetconfVersion.VERSION_1_1\n        else:\n            final_channel_version = NetconfVersion.VERSION_1_0\n\n        if self._netconf_base_channel_args.netconf_version != NetconfVersion.UNKNOWN:\n            if self._netconf_base_channel_args.netconf_version == NetconfVersion.VERSION_1_0:\n                if \"urn:ietf:params:netconf:base:1.0\" not in server_capabilities:\n                    raise CapabilityNotSupported(\n                        \"user requested netconf version 1.0 but capability not offered\"\n                    )\n                final_channel_version = NetconfVersion.VERSION_1_0\n            elif self._netconf_base_channel_args.netconf_version == NetconfVersion.VERSION_1_1:\n                if \"urn:ietf:params:netconf:base:1.1\" not in server_capabilities:\n                    raise CapabilityNotSupported(\n                        \"user requested netconf version 1.1 but capability not offered\"\n                    )\n                final_channel_version = NetconfVersion.VERSION_1_1\n\n        if final_channel_version == NetconfVersion.VERSION_1_0:\n            self._netconf_base_channel_args.netconf_version = NetconfVersion.VERSION_1_0\n            self._base_channel_args.comms_prompt_pattern = \"]]&gt;]]&gt;\"\n            self._netconf_base_channel_args.client_capabilities = (\n                NetconfClientCapabilities.CAPABILITIES_1_0\n            )\n        else:\n            self._netconf_base_channel_args.netconf_version = NetconfVersion.VERSION_1_1\n            self._base_channel_args.comms_prompt_pattern = r\"^##$\"\n            self._netconf_base_channel_args.client_capabilities = (\n                NetconfClientCapabilities.CAPABILITIES_1_1\n            )\n\n    def _parse_server_capabilities(self, raw_server_capabilities: bytes) -&gt; List[str]:\n\"\"\"\n        Parse netconf server capabilities\n\n        Args:\n            raw_server_capabilities: raw bytes containing server capabilities\n\n        Returns:\n            N/A  # noqa: DAR202\n\n        Raises:\n            CouldNotExchangeCapabilities: if server capabilities cannot be parsed\n\n        \"\"\"\n        server_capabilities = []\n\n        # matches hello with or without namespace\n        filtered_raw_server_capabilities = re.search(\n            pattern=rb\"(&lt;(\\w+\\:){0,1}hello.*&lt;\\/(\\w+\\:){0,1}hello&gt;)\",\n            string=raw_server_capabilities,\n            flags=re.I | re.S,\n        )\n        if filtered_raw_server_capabilities is None:\n            msg = \"failed to parse server capabilities\"\n            raise CouldNotExchangeCapabilities(msg)\n\n        # IOSXR/XR7 7.3.1 returns corrupt '&lt;capabil\\n\\nity&gt;' property on call-home line, so replace\n        # newlines to have a parsable read\n        server_capabilities_xml = etree.fromstring(\n            filtered_raw_server_capabilities.groups()[0].replace(b\"\\n\", b\"\")\n        )\n        for elem in server_capabilities_xml.iter():\n            if \"capability\" not in elem.tag:\n                continue\n            server_capabilities.append(elem.text.strip())\n        self.logger.info(f\"server capabilities received and parsed: {server_capabilities}\")\n        return server_capabilities\n\n    def _process_output(self, buf: bytes, strip_prompt: bool) -&gt; bytes:\n\"\"\"\n        Override scrapli _process_output as this is unnecessary for scrapli_netconf\n\n        Args:\n            buf: bytes output from the device\n            strip_prompt: ignored in this base class; for LSP reasons for subclasses\n\n        Returns:\n            bytes: output of joined output lines optionally with prompt removed\n\n        Raises:\n            N/A\n\n        \"\"\"\n        _ = strip_prompt\n        return buf\n\n    def _pre_send_client_capabilities(\n        self, client_capabilities: NetconfClientCapabilities\n    ) -&gt; bytes:\n\"\"\"\n        Handle pre \"_send_client_capabilities\" tasks for consistency between sync/async versions\n\n        Args:\n            client_capabilities: string of client netconf capabilities to send to server\n\n        Returns:\n            bytes: bytes of client capabilities to send to the channel\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.logger.info(\"sending client capabilities\")\n        bytes_client_capabilities: bytes = client_capabilities.value.encode()\n        self.logger.debug(f\"attempting to send capabilities: {client_capabilities}\")\n        self.write(client_capabilities.value)\n        return bytes_client_capabilities\n</code></pre>"},{"location":"reference/channel/sync_channel/","title":"sync_channel","text":"<p>scrapli_netconf.channel.sync_channel</p>"},{"location":"reference/channel/sync_channel/#channel.sync_channel.NetconfChannel","title":"<code>NetconfChannel</code>","text":"<p>         Bases: <code>Channel</code>, <code>BaseNetconfChannel</code></p> Source code in <code>channel/sync_channel.py</code> <pre><code>class NetconfChannel(Channel, BaseNetconfChannel):\n    def __init__(\n        self,\n        transport: Transport,\n        base_channel_args: BaseChannelArgs,\n        netconf_base_channel_args: NetconfBaseChannelArgs,\n    ):\n        super().__init__(transport=transport, base_channel_args=base_channel_args)\n\n        self._netconf_base_channel_args = netconf_base_channel_args\n\n        # always use `]]&gt;]]&gt;` as the initial prompt to match\n        self._base_channel_args.comms_prompt_pattern = \"]]&gt;]]&gt;\"\n        self._server_echo: Optional[bool] = None\n        self._establishing_server_echo = False\n        self._capabilities_buf = b\"\"\n        self._read_buf = b\"\"\n\n    def open_netconf(self) -&gt; None:\n\"\"\"\n        Open the netconf channel\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        # open in scrapli core is where we open channel log (if applicable), do that\n        self.open()\n\n        raw_server_capabilities = self._get_server_capabilities()\n        self._process_capabilities_exchange(raw_server_capabilities=raw_server_capabilities)\n        self._send_client_capabilities()\n\n    @staticmethod\n    def _authenticate_check_hello(buf: bytes) -&gt; bool:\n\"\"\"\n        Check if \"hello\" message is in output\n\n        Args:\n            buf: bytes output from the channel\n\n        Returns:\n            bool: true if hello message is seen, otherwise false\n\n        Raises:\n            N/A\n\n        \"\"\"\n        hello_match = re.search(pattern=HELLO_MATCH, string=buf)\n        if hello_match:\n            return True\n        return False\n\n    @timeout_wrapper\n    def channel_authenticate_netconf(\n        self, auth_password: str, auth_private_key_passphrase: str\n    ) -&gt; None:\n\"\"\"\n        Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system)\n\n        Args:\n            auth_password: password to authenticate with\n            auth_private_key_passphrase: passphrase for ssh key if necessary\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliAuthenticationFailed: if password prompt seen more than twice\n            ScrapliAuthenticationFailed: if passphrase prompt seen more than twice\n\n        \"\"\"\n        self.logger.debug(\"attempting in channel netconf authentication\")\n\n        password_count = 0\n        passphrase_count = 0\n        authenticate_buf = b\"\"\n\n        with self._channel_lock():\n            while True:\n                buf = self.read()\n\n                authenticate_buf += buf.lower()\n                self._capabilities_buf += buf\n\n                self._ssh_message_handler(output=authenticate_buf)\n\n                if b\"password\" in authenticate_buf:\n                    # clear the authentication buffer so we don't re-read the password prompt\n                    authenticate_buf = b\"\"\n                    password_count += 1\n                    if password_count &gt; 2:\n                        msg = \"password prompt seen more than once, assuming auth failed\"\n                        self.logger.critical(msg)\n                        raise ScrapliAuthenticationFailed(msg)\n                    self.write(channel_input=auth_password, redacted=True)\n                    self.send_return()\n\n                if b\"enter passphrase for key\" in authenticate_buf:\n                    # clear the authentication buffer so we don't re-read the passphrase prompt\n                    authenticate_buf = b\"\"\n                    passphrase_count += 1\n                    if passphrase_count &gt; 2:\n                        msg = \"passphrase prompt seen more than once, assuming auth failed\"\n                        self.logger.critical(msg)\n                        raise ScrapliAuthenticationFailed(msg)\n                    self.write(channel_input=auth_private_key_passphrase, redacted=True)\n                    self.send_return()\n\n                if self._authenticate_check_hello(buf=authenticate_buf):\n                    self.logger.info(\n                        \"found start of server capabilities, authentication successful\"\n                    )\n                    return\n\n    @timeout_wrapper\n    def _get_server_capabilities(self) -&gt; bytes:\n\"\"\"\n        Read until all server capabilities have been sent by server\n\n        Args:\n            N/A\n\n        Returns:\n            bytes: raw bytes containing server capabilities\n\n        Raises:\n            N/A\n\n        \"\"\"\n        capabilities_buf = self._capabilities_buf\n\n        # reset this to empty to avoid any confusion now that we are moving on\n        self._capabilities_buf = b\"\"\n\n        with self._channel_lock():\n            while b\"]]&gt;]]&gt;\" not in capabilities_buf:\n                capabilities_buf += self.read()\n\n            capabilities_buf, _, over_read_buf = capabilities_buf.partition(b\"]]&gt;]]&gt;\")\n            if over_read_buf:\n                self._read_buf += over_read_buf\n\n            self.logger.debug(f\"received raw server capabilities: {repr(capabilities_buf)}\")\n        return capabilities_buf\n\n    @timeout_wrapper\n    def _send_client_capabilities(\n        self,\n    ) -&gt; None:\n\"\"\"\n        Send client capabilities to the netconf server\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        with self._channel_lock():\n            bytes_client_capabilities = self._pre_send_client_capabilities(\n                client_capabilities=self._netconf_base_channel_args.client_capabilities\n            )\n            self._read_until_input(channel_input=bytes_client_capabilities)\n            self.send_return()\n\n    def read(self) -&gt; bytes:\n\"\"\"\n        Read chunks of output from the channel\n\n        Prior to super-ing \"normal\" scrapli read, check if there is anything on our read_buf, if\n        there is, return that first\n\n        Args:\n            N/A\n\n        Returns:\n            bytes: output read from channel\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if self._read_buf:\n            read_buf = self._read_buf\n            self._read_buf = b\"\"\n            return read_buf\n\n        return super().read()\n\n    def _read_until_input(self, channel_input: bytes) -&gt; bytes:\n\"\"\"\n        Sync read until all input has been entered.\n\n        Args:\n            channel_input: string to write to channel\n\n        Returns:\n            bytes: output read from channel\n\n        Raises:\n            N/A\n\n        \"\"\"\n        output = b\"\"\n\n        if self._server_echo is None or self._server_echo is False:\n            # if server_echo is `None` we dont know if the server echoes yet, so just return nothing\n            # if its False we know it doesnt echo and we can return empty byte string anyway\n            return output\n\n        if not channel_input:\n            self.logger.info(f\"Read: {repr(output)}\")\n            return output\n\n        while True:\n            output += self.read()\n\n            if self._establishing_server_echo:\n                output, partition, new_buf = output.partition(b\"]]&gt;]]&gt;\")\n                self._read_buf += new_buf\n                output += partition\n                break\n\n            # if we have all the input *or* we see the closing rpc tag we know we are done here\n            if channel_input in output or b\"rpc&gt;\" in output:\n                break\n\n        self.logger.info(f\"Read: {repr(output)}\")\n        return output\n\n    def send_input_netconf(self, channel_input: str) -&gt; bytes:  # noqa: mccabe\n\"\"\"\n        Send inputs to netconf server\n\n        Args:\n            channel_input: string of the base xml message to send to netconf server\n\n        Returns:\n            bytes: bytes result of message sent to netconf server\n\n        Raises:\n            ScrapliTimeout: re-raises channel timeouts with additional message if channel input may\n                be big enough to require setting `use_compressed_parser` to false -- note that this\n                has only been seen as an issue with NXOS so far.\n\n        \"\"\"\n        bytes_final_channel_input = channel_input.encode()\n\n        buf: bytes\n        buf, _ = super().send_input(channel_input=channel_input, strip_prompt=False, eager=True)\n\n        if bytes_final_channel_input in buf:\n            # if we got the input AND the rpc-reply we can strip out our inputs so we just have the\n            # reply remaining\n            buf = buf.split(bytes_final_channel_input)[1]\n\n        try:\n            buf = self._read_until_prompt(buf=buf)\n        except ScrapliTimeout as exc:\n            if len(channel_input) &gt;= 4096:\n                msg = (\n                    \"timed out finding prompt after sending input, input is greater than 4096 \"\n                    \"chars, try setting 'use_compressed_parser' to False\"\n                )\n                self.logger.info(msg)\n                raise ScrapliTimeout(msg) from exc\n            raise ScrapliTimeout from exc\n\n        if self._server_echo is None:\n            # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT\n            # echo the input commands back to the client. In the case of \"normal\" scrapli netconf\n            # with the system transport this happens anyway because we combine the stdin and stdout\n            # fds into a single pty, however for other transports we have an actual stdin and\n            # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems\n            # to want to echo inputs back onto to the stdout for the channel. This is totally ok\n            # and we can deal with it, we just need to *know* that it is happening, so while the\n            # _server_echo attribute is still `None`, we can go ahead and see if the input we sent\n            # is in the output we read off the channel. If it is *not* we know the server does *not*\n            # echo and we can move on. If it *is* in the output, we know the server echoes, and we\n            # also have one additional step in that we need to read \"until prompt\" again in order to\n            # capture the reply to our rpc.\n            #\n            # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\")\n\n            self.logger.debug(\"server echo is unset, determining if server echoes inputs now\")\n\n            # we may be reading the remainder of the echo from our capabilities message -- if we see\n            # that we know the server echoes, but we still need to read until our latest input.\n            if b\"&lt;/hello&gt;]]&gt;]]&gt;\" in buf:\n                self.logger.debug(\"server echoes inputs, setting _server_echo to 'true'\")\n                self._server_echo = True\n\n                _, _, buf = buf.partition(b\"&lt;/hello&gt;]]&gt;]]&gt;\")\n                if buf:\n                    # if we read past the end of the\n                    self._read_buf += buf\n\n                # read up till our new input now to consume it from the channel\n                self._establishing_server_echo = True\n                self._read_until_input(bytes_final_channel_input)\n            elif bytes_final_channel_input in buf:\n                self.logger.debug(\"server echoes inputs, setting _server_echo to 'true'\")\n                self._server_echo = True\n            else:\n                self.logger.debug(\"server does *not* echo inputs, setting _server_echo to 'false'\")\n                self._server_echo = False\n\n            if self._server_echo:\n                # done with the establishment process\n                self._establishing_server_echo = False\n\n                # since echo is True and we only read until our input (because our inputs always end\n                # with a \"prompt\" that we read until) we need to once again read until prompt, this\n                # read will read all the way up through the *reply* to the prompt at end of the\n                # reply message\n                buf = self._read_until_prompt(buf=b\"\")\n\n        if self._netconf_base_channel_args.netconf_version == NetconfVersion.VERSION_1_1:\n            # netconf 1.1 with \"chunking\" style message format needs an extra return char here\n            self.send_return()\n\n        # we should be able to simply partition here and put any \"over reads\" back into the read buf\n\n        return buf\n</code></pre>"},{"location":"reference/channel/sync_channel/#channel.sync_channel.NetconfChannel.channel_authenticate_netconf","title":"<code>channel_authenticate_netconf(auth_password: str, auth_private_key_passphrase: str) -&gt; None</code>","text":"<p>Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system)</p> <p>Parameters:</p> Name Type Description Default <code>auth_password</code> <code>str</code> <p>password to authenticate with</p> required <code>auth_private_key_passphrase</code> <code>str</code> <p>passphrase for ssh key if necessary</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ScrapliAuthenticationFailed</code> <p>if password prompt seen more than twice</p> <code>ScrapliAuthenticationFailed</code> <p>if passphrase prompt seen more than twice</p> Source code in <code>channel/sync_channel.py</code> <pre><code>@timeout_wrapper\ndef channel_authenticate_netconf(\n    self, auth_password: str, auth_private_key_passphrase: str\n) -&gt; None:\n\"\"\"\n    Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system)\n\n    Args:\n        auth_password: password to authenticate with\n        auth_private_key_passphrase: passphrase for ssh key if necessary\n\n    Returns:\n        None\n\n    Raises:\n        ScrapliAuthenticationFailed: if password prompt seen more than twice\n        ScrapliAuthenticationFailed: if passphrase prompt seen more than twice\n\n    \"\"\"\n    self.logger.debug(\"attempting in channel netconf authentication\")\n\n    password_count = 0\n    passphrase_count = 0\n    authenticate_buf = b\"\"\n\n    with self._channel_lock():\n        while True:\n            buf = self.read()\n\n            authenticate_buf += buf.lower()\n            self._capabilities_buf += buf\n\n            self._ssh_message_handler(output=authenticate_buf)\n\n            if b\"password\" in authenticate_buf:\n                # clear the authentication buffer so we don't re-read the password prompt\n                authenticate_buf = b\"\"\n                password_count += 1\n                if password_count &gt; 2:\n                    msg = \"password prompt seen more than once, assuming auth failed\"\n                    self.logger.critical(msg)\n                    raise ScrapliAuthenticationFailed(msg)\n                self.write(channel_input=auth_password, redacted=True)\n                self.send_return()\n\n            if b\"enter passphrase for key\" in authenticate_buf:\n                # clear the authentication buffer so we don't re-read the passphrase prompt\n                authenticate_buf = b\"\"\n                passphrase_count += 1\n                if passphrase_count &gt; 2:\n                    msg = \"passphrase prompt seen more than once, assuming auth failed\"\n                    self.logger.critical(msg)\n                    raise ScrapliAuthenticationFailed(msg)\n                self.write(channel_input=auth_private_key_passphrase, redacted=True)\n                self.send_return()\n\n            if self._authenticate_check_hello(buf=authenticate_buf):\n                self.logger.info(\n                    \"found start of server capabilities, authentication successful\"\n                )\n                return\n</code></pre>"},{"location":"reference/channel/sync_channel/#channel.sync_channel.NetconfChannel.open_netconf","title":"<code>open_netconf() -&gt; None</code>","text":"<p>Open the netconf channel</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>channel/sync_channel.py</code> <pre><code>def open_netconf(self) -&gt; None:\n\"\"\"\n    Open the netconf channel\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    # open in scrapli core is where we open channel log (if applicable), do that\n    self.open()\n\n    raw_server_capabilities = self._get_server_capabilities()\n    self._process_capabilities_exchange(raw_server_capabilities=raw_server_capabilities)\n    self._send_client_capabilities()\n</code></pre>"},{"location":"reference/channel/sync_channel/#channel.sync_channel.NetconfChannel.read","title":"<code>read() -&gt; bytes</code>","text":"<p>Read chunks of output from the channel</p> <p>Prior to super-ing \"normal\" scrapli read, check if there is anything on our read_buf, if there is, return that first</p> <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>output read from channel</p> Source code in <code>channel/sync_channel.py</code> <pre><code>def read(self) -&gt; bytes:\n\"\"\"\n    Read chunks of output from the channel\n\n    Prior to super-ing \"normal\" scrapli read, check if there is anything on our read_buf, if\n    there is, return that first\n\n    Args:\n        N/A\n\n    Returns:\n        bytes: output read from channel\n\n    Raises:\n        N/A\n\n    \"\"\"\n    if self._read_buf:\n        read_buf = self._read_buf\n        self._read_buf = b\"\"\n        return read_buf\n\n    return super().read()\n</code></pre>"},{"location":"reference/channel/sync_channel/#channel.sync_channel.NetconfChannel.send_input_netconf","title":"<code>send_input_netconf(channel_input: str) -&gt; bytes</code>","text":"<p>Send inputs to netconf server</p> <p>Parameters:</p> Name Type Description Default <code>channel_input</code> <code>str</code> <p>string of the base xml message to send to netconf server</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>bytes result of message sent to netconf server</p> <p>Raises:</p> Type Description <code>ScrapliTimeout</code> <p>re-raises channel timeouts with additional message if channel input may be big enough to require setting <code>use_compressed_parser</code> to false -- note that this has only been seen as an issue with NXOS so far.</p> Source code in <code>channel/sync_channel.py</code> <pre><code>def send_input_netconf(self, channel_input: str) -&gt; bytes:  # noqa: mccabe\n\"\"\"\n    Send inputs to netconf server\n\n    Args:\n        channel_input: string of the base xml message to send to netconf server\n\n    Returns:\n        bytes: bytes result of message sent to netconf server\n\n    Raises:\n        ScrapliTimeout: re-raises channel timeouts with additional message if channel input may\n            be big enough to require setting `use_compressed_parser` to false -- note that this\n            has only been seen as an issue with NXOS so far.\n\n    \"\"\"\n    bytes_final_channel_input = channel_input.encode()\n\n    buf: bytes\n    buf, _ = super().send_input(channel_input=channel_input, strip_prompt=False, eager=True)\n\n    if bytes_final_channel_input in buf:\n        # if we got the input AND the rpc-reply we can strip out our inputs so we just have the\n        # reply remaining\n        buf = buf.split(bytes_final_channel_input)[1]\n\n    try:\n        buf = self._read_until_prompt(buf=buf)\n    except ScrapliTimeout as exc:\n        if len(channel_input) &gt;= 4096:\n            msg = (\n                \"timed out finding prompt after sending input, input is greater than 4096 \"\n                \"chars, try setting 'use_compressed_parser' to False\"\n            )\n            self.logger.info(msg)\n            raise ScrapliTimeout(msg) from exc\n        raise ScrapliTimeout from exc\n\n    if self._server_echo is None:\n        # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT\n        # echo the input commands back to the client. In the case of \"normal\" scrapli netconf\n        # with the system transport this happens anyway because we combine the stdin and stdout\n        # fds into a single pty, however for other transports we have an actual stdin and\n        # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems\n        # to want to echo inputs back onto to the stdout for the channel. This is totally ok\n        # and we can deal with it, we just need to *know* that it is happening, so while the\n        # _server_echo attribute is still `None`, we can go ahead and see if the input we sent\n        # is in the output we read off the channel. If it is *not* we know the server does *not*\n        # echo and we can move on. If it *is* in the output, we know the server echoes, and we\n        # also have one additional step in that we need to read \"until prompt\" again in order to\n        # capture the reply to our rpc.\n        #\n        # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\")\n\n        self.logger.debug(\"server echo is unset, determining if server echoes inputs now\")\n\n        # we may be reading the remainder of the echo from our capabilities message -- if we see\n        # that we know the server echoes, but we still need to read until our latest input.\n        if b\"&lt;/hello&gt;]]&gt;]]&gt;\" in buf:\n            self.logger.debug(\"server echoes inputs, setting _server_echo to 'true'\")\n            self._server_echo = True\n\n            _, _, buf = buf.partition(b\"&lt;/hello&gt;]]&gt;]]&gt;\")\n            if buf:\n                # if we read past the end of the\n                self._read_buf += buf\n\n            # read up till our new input now to consume it from the channel\n            self._establishing_server_echo = True\n            self._read_until_input(bytes_final_channel_input)\n        elif bytes_final_channel_input in buf:\n            self.logger.debug(\"server echoes inputs, setting _server_echo to 'true'\")\n            self._server_echo = True\n        else:\n            self.logger.debug(\"server does *not* echo inputs, setting _server_echo to 'false'\")\n            self._server_echo = False\n\n        if self._server_echo:\n            # done with the establishment process\n            self._establishing_server_echo = False\n\n            # since echo is True and we only read until our input (because our inputs always end\n            # with a \"prompt\" that we read until) we need to once again read until prompt, this\n            # read will read all the way up through the *reply* to the prompt at end of the\n            # reply message\n            buf = self._read_until_prompt(buf=b\"\")\n\n    if self._netconf_base_channel_args.netconf_version == NetconfVersion.VERSION_1_1:\n        # netconf 1.1 with \"chunking\" style message format needs an extra return char here\n        self.send_return()\n\n    # we should be able to simply partition here and put any \"over reads\" back into the read buf\n\n    return buf\n</code></pre>"},{"location":"reference/driver/","title":"driver","text":"<p>scrapli_netconf.driver</p>"},{"location":"reference/driver/async_driver/","title":"async_driver","text":"<p>scrapli_netconf.driver.async_driver</p>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver","title":"<code>AsyncNetconfDriver</code>","text":"<p>         Bases: <code>AsyncDriver</code>, <code>NetconfBaseDriver</code></p> Source code in <code>driver/async_driver.py</code> <pre><code>class AsyncNetconfDriver(AsyncDriver, NetconfBaseDriver):\n    # kinda hate this but need to tell mypy that channel in netconf land is in fact a channel of\n    # type `NetconfChannel`\n    channel: AsyncNetconfChannel\n\n    def __init__(\n        self,\n        host: str,\n        port: int = 830,\n        strip_namespaces: bool = False,\n        strict_datastores: bool = False,\n        auth_username: str = \"\",\n        auth_password: str = \"\",\n        auth_private_key: str = \"\",\n        auth_private_key_passphrase: str = \"\",\n        auth_strict_key: bool = True,\n        auth_bypass: bool = False,\n        timeout_socket: float = 15.0,\n        timeout_transport: float = 30.0,\n        timeout_ops: float = 30.0,\n        comms_prompt_pattern: str = r\"^[a-z0-9.\\-@()/:]{1,48}[#&gt;$]\\s*$\",\n        comms_return_char: str = \"\\n\",\n        ssh_config_file: Union[str, bool] = False,\n        ssh_known_hosts_file: Union[str, bool] = False,\n        on_init: Optional[Callable[..., Any]] = None,\n        on_open: Optional[Callable[..., Any]] = None,\n        on_close: Optional[Callable[..., Any]] = None,\n        transport: str = \"system\",\n        transport_options: Optional[Dict[str, Any]] = None,\n        channel_log: Union[str, bool] = False,\n        channel_lock: bool = False,\n        preferred_netconf_version: Optional[str] = None,\n        use_compressed_parser: bool = True,\n    ) -&gt; None:\n        super().__init__(\n            host=host,\n            port=port,\n            auth_username=auth_username,\n            auth_password=auth_password,\n            auth_private_key=auth_private_key,\n            auth_private_key_passphrase=auth_private_key_passphrase,\n            auth_strict_key=auth_strict_key,\n            auth_bypass=auth_bypass,\n            timeout_socket=timeout_socket,\n            timeout_transport=timeout_transport,\n            timeout_ops=timeout_ops,\n            comms_prompt_pattern=comms_prompt_pattern,\n            comms_return_char=comms_return_char,\n            ssh_config_file=ssh_config_file,\n            ssh_known_hosts_file=ssh_known_hosts_file,\n            on_init=on_init,\n            on_open=on_open,\n            on_close=on_close,\n            transport=transport,\n            transport_options=transport_options,\n            channel_log=channel_log,\n            channel_lock=channel_lock,\n        )\n\n        _preferred_netconf_version = self._determine_preferred_netconf_version(\n            preferred_netconf_version=preferred_netconf_version\n        )\n        _preferred_xml_parser = self._determine_preferred_xml_parser(\n            use_compressed_parser=use_compressed_parser\n        )\n        self._netconf_base_channel_args = NetconfBaseChannelArgs(\n            netconf_version=_preferred_netconf_version, xml_parser=_preferred_xml_parser\n        )\n\n        self.channel = AsyncNetconfChannel(\n            transport=self.transport,\n            base_channel_args=self._base_channel_args,\n            netconf_base_channel_args=self._netconf_base_channel_args,\n        )\n\n        self.strip_namespaces = strip_namespaces\n        self.strict_datastores = strict_datastores\n        self.server_capabilities: List[str] = []\n        self.readable_datastores: List[str] = []\n        self.writeable_datastores: List[str] = []\n        self.message_id = 101\n\n    async def open(self) -&gt; None:\n\"\"\"\n        Open netconf connection to server\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self._pre_open_closing_log(closing=False)\n\n        await self.transport.open_netconf()\n        await self.channel.open_netconf()\n\n        self._build_readable_datastores()\n        self._build_writeable_datastores()\n\n        self._post_open_closing_log(closing=False)\n\n    async def get(self, filter_: str, filter_type: str = \"subtree\") -&gt; NetconfResponse:\n\"\"\"\n        Netconf get operation\n\n        Args:\n            filter_: string filter to apply to the get\n            filter_type: type of filter; subtree|xpath\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_get(filter_=filter_, filter_type=filter_type)\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    async def get_config(\n        self,\n        source: str = \"running\",\n        filter_: Optional[str] = None,\n        filter_type: str = \"subtree\",\n        default_type: Optional[str] = None,\n    ) -&gt; NetconfResponse:\n\"\"\"\n        Netconf get-config operation\n\n        Args:\n            source: configuration source to get; typically one of running|startup|candidate\n            filter_: string of filter(s) to apply to configuration\n            filter_type: type of filter; subtree|xpath\n            default_type: string of with-default mode to apply when retrieving configuration\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_get_config(\n            source=source, filter_=filter_, filter_type=filter_type, default_type=default_type\n        )\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n\n        response.record_response(raw_response)\n        return response\n\n    async def edit_config(self, config: str, target: str = \"running\") -&gt; NetconfResponse:\n\"\"\"\n        Netconf get-config operation\n\n        Args:\n            config: configuration to send to device\n            target: configuration source to target; running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_edit_config(config=config, target=target)\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    async def delete_config(self, target: str = \"candidate\") -&gt; NetconfResponse:\n\"\"\"\n        Netconf delete-config operation\n\n        Args:\n            target: configuration source to target; startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_delete_config(target=target)\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    async def commit(\n        self,\n        confirmed: bool = False,\n        timeout: Optional[int] = None,\n        persist: Optional[Union[int, str]] = None,\n        persist_id: Optional[Union[int, str]] = None,\n    ) -&gt; NetconfResponse:\n\"\"\"\n        Netconf commit config operation\n\n        Args:\n            confirmed: whether this is a confirmed commit\n            timeout: specifies the confirm timeout in seconds\n            persist: make the confirmed commit survive a session termination, and set a token on\n                the ongoing confirmed commit\n            persist_id: value must be equal to the value given in the &lt;persist&gt; parameter to the\n                original &lt;commit&gt; operation.\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_commit(\n            confirmed=confirmed,\n            timeout=timeout,\n            persist=persist,\n            persist_id=persist_id,\n        )\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    async def discard(self) -&gt; NetconfResponse:\n\"\"\"\n        Netconf discard config operation\n\n        Args:\n            N/A\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_discard()\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    async def lock(self, target: str) -&gt; NetconfResponse:\n\"\"\"\n        Netconf lock operation\n\n        Args:\n            target: configuration source to target; running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_lock(target=target)\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    async def unlock(self, target: str) -&gt; NetconfResponse:\n\"\"\"\n        Netconf unlock operation\n\n        Args:\n            target: configuration source to target; running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_unlock(target=target)\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    async def rpc(self, filter_: Union[str, _Element]) -&gt; NetconfResponse:\n\"\"\"\n        Netconf \"rpc\" operation\n\n        Typically used with juniper devices or if you want to build/send your own payload in a more\n        manual fashion. You can provide a string that will be loaded as an lxml element, or you can\n        provide an lxml element yourself.\n\n        Args:\n            filter_: filter/rpc to execute\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_rpc(filter_=filter_)\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    async def validate(self, source: str) -&gt; NetconfResponse:\n\"\"\"\n        Netconf \"validate\" operation\n\n        Args:\n            source: configuration source to validate; typically one of running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_validate(source=source)\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    async def copy_config(self, source: str, target: str) -&gt; NetconfResponse:\n\"\"\"\n        Netconf \"copy-config\" operation\n\n        Args:\n            source: configuration, url, or datastore to copy into the target datastore\n            target: destination to copy the source to\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_copy_config(source=source, target=target)\n        raw_response = await self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.commit","title":"<code>commit(confirmed: bool = False, timeout: Optional[int] = None, persist: Optional[Union[int, str]] = None, persist_id: Optional[Union[int, str]] = None) -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf commit config operation</p> <p>Parameters:</p> Name Type Description Default <code>confirmed</code> <code>bool</code> <p>whether this is a confirmed commit</p> <code>False</code> <code>timeout</code> <code>Optional[int]</code> <p>specifies the confirm timeout in seconds</p> <code>None</code> <code>persist</code> <code>Optional[Union[int, str]]</code> <p>make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit</p> <code>None</code> <code>persist_id</code> <code>Optional[Union[int, str]]</code> <p>value must be equal to the value given in the  parameter to the original  operation. <code>None</code> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def commit(\n    self,\n    confirmed: bool = False,\n    timeout: Optional[int] = None,\n    persist: Optional[Union[int, str]] = None,\n    persist_id: Optional[Union[int, str]] = None,\n) -&gt; NetconfResponse:\n\"\"\"\n    Netconf commit config operation\n\n    Args:\n        confirmed: whether this is a confirmed commit\n        timeout: specifies the confirm timeout in seconds\n        persist: make the confirmed commit survive a session termination, and set a token on\n            the ongoing confirmed commit\n        persist_id: value must be equal to the value given in the &lt;persist&gt; parameter to the\n            original &lt;commit&gt; operation.\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_commit(\n        confirmed=confirmed,\n        timeout=timeout,\n        persist=persist,\n        persist_id=persist_id,\n    )\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.copy_config","title":"<code>copy_config(source: str, target: str) -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf \"copy-config\" operation</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>configuration, url, or datastore to copy into the target datastore</p> required <code>target</code> <code>str</code> <p>destination to copy the source to</p> required <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def copy_config(self, source: str, target: str) -&gt; NetconfResponse:\n\"\"\"\n    Netconf \"copy-config\" operation\n\n    Args:\n        source: configuration, url, or datastore to copy into the target datastore\n        target: destination to copy the source to\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_copy_config(source=source, target=target)\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.delete_config","title":"<code>delete_config(target: str = 'candidate') -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf delete-config operation</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>configuration source to target; startup|candidate</p> <code>'candidate'</code> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def delete_config(self, target: str = \"candidate\") -&gt; NetconfResponse:\n\"\"\"\n    Netconf delete-config operation\n\n    Args:\n        target: configuration source to target; startup|candidate\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_delete_config(target=target)\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.discard","title":"<code>discard() -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf discard config operation</p> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def discard(self) -&gt; NetconfResponse:\n\"\"\"\n    Netconf discard config operation\n\n    Args:\n        N/A\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_discard()\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.edit_config","title":"<code>edit_config(config: str, target: str = 'running') -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf get-config operation</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>str</code> <p>configuration to send to device</p> required <code>target</code> <code>str</code> <p>configuration source to target; running|startup|candidate</p> <code>'running'</code> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def edit_config(self, config: str, target: str = \"running\") -&gt; NetconfResponse:\n\"\"\"\n    Netconf get-config operation\n\n    Args:\n        config: configuration to send to device\n        target: configuration source to target; running|startup|candidate\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_edit_config(config=config, target=target)\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.get","title":"<code>get(filter_: str, filter_type: str = 'subtree') -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf get operation</p> <p>Parameters:</p> Name Type Description Default <code>filter_</code> <code>str</code> <p>string filter to apply to the get</p> required <code>filter_type</code> <code>str</code> <p>type of filter; subtree|xpath</p> <code>'subtree'</code> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def get(self, filter_: str, filter_type: str = \"subtree\") -&gt; NetconfResponse:\n\"\"\"\n    Netconf get operation\n\n    Args:\n        filter_: string filter to apply to the get\n        filter_type: type of filter; subtree|xpath\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_get(filter_=filter_, filter_type=filter_type)\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.get_config","title":"<code>get_config(source: str = 'running', filter_: Optional[str] = None, filter_type: str = 'subtree', default_type: Optional[str] = None) -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf get-config operation</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>configuration source to get; typically one of running|startup|candidate</p> <code>'running'</code> <code>filter_</code> <code>Optional[str]</code> <p>string of filter(s) to apply to configuration</p> <code>None</code> <code>filter_type</code> <code>str</code> <p>type of filter; subtree|xpath</p> <code>'subtree'</code> <code>default_type</code> <code>Optional[str]</code> <p>string of with-default mode to apply when retrieving configuration</p> <code>None</code> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def get_config(\n    self,\n    source: str = \"running\",\n    filter_: Optional[str] = None,\n    filter_type: str = \"subtree\",\n    default_type: Optional[str] = None,\n) -&gt; NetconfResponse:\n\"\"\"\n    Netconf get-config operation\n\n    Args:\n        source: configuration source to get; typically one of running|startup|candidate\n        filter_: string of filter(s) to apply to configuration\n        filter_type: type of filter; subtree|xpath\n        default_type: string of with-default mode to apply when retrieving configuration\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_get_config(\n        source=source, filter_=filter_, filter_type=filter_type, default_type=default_type\n    )\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.lock","title":"<code>lock(target: str) -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf lock operation</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>configuration source to target; running|startup|candidate</p> required <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def lock(self, target: str) -&gt; NetconfResponse:\n\"\"\"\n    Netconf lock operation\n\n    Args:\n        target: configuration source to target; running|startup|candidate\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_lock(target=target)\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.open","title":"<code>open() -&gt; None</code>  <code>async</code>","text":"<p>Open netconf connection to server</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def open(self) -&gt; None:\n\"\"\"\n    Open netconf connection to server\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self._pre_open_closing_log(closing=False)\n\n    await self.transport.open_netconf()\n    await self.channel.open_netconf()\n\n    self._build_readable_datastores()\n    self._build_writeable_datastores()\n\n    self._post_open_closing_log(closing=False)\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.rpc","title":"<code>rpc(filter_: Union[str, _Element]) -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf \"rpc\" operation</p> <p>Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself.</p> <p>Parameters:</p> Name Type Description Default <code>filter_</code> <code>Union[str, _Element]</code> <p>filter/rpc to execute</p> required <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def rpc(self, filter_: Union[str, _Element]) -&gt; NetconfResponse:\n\"\"\"\n    Netconf \"rpc\" operation\n\n    Typically used with juniper devices or if you want to build/send your own payload in a more\n    manual fashion. You can provide a string that will be loaded as an lxml element, or you can\n    provide an lxml element yourself.\n\n    Args:\n        filter_: filter/rpc to execute\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_rpc(filter_=filter_)\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.unlock","title":"<code>unlock(target: str) -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf unlock operation</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>configuration source to target; running|startup|candidate</p> required <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def unlock(self, target: str) -&gt; NetconfResponse:\n\"\"\"\n    Netconf unlock operation\n\n    Args:\n        target: configuration source to target; running|startup|candidate\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_unlock(target=target)\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.validate","title":"<code>validate(source: str) -&gt; NetconfResponse</code>  <code>async</code>","text":"<p>Netconf \"validate\" operation</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>configuration source to validate; typically one of running|startup|candidate</p> required <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/async_driver.py</code> <pre><code>async def validate(self, source: str) -&gt; NetconfResponse:\n\"\"\"\n    Netconf \"validate\" operation\n\n    Args:\n        source: configuration source to validate; typically one of running|startup|candidate\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_validate(source=source)\n    raw_response = await self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/base_driver/","title":"base_driver","text":"<p>scrapli_netconf.driver.base_driver</p>"},{"location":"reference/driver/base_driver/#driver.base_driver.NetconfBaseDriver","title":"<code>NetconfBaseDriver</code>","text":"<p>         Bases: <code>BaseDriver</code></p> Source code in <code>driver/base_driver.py</code> <pre><code>class NetconfBaseDriver(BaseDriver):\n    host: str\n    readable_datastores: List[str]\n    writeable_datastores: List[str]\n    strip_namespaces: bool\n    strict_datastores: bool\n    flatten_input: bool\n    _netconf_base_channel_args: NetconfBaseChannelArgs\n\n    @property\n    def netconf_version(self) -&gt; NetconfVersion:\n\"\"\"\n        Getter for 'netconf_version' attribute\n\n        Args:\n            N/A\n\n        Returns:\n            NetconfVersion: netconf_version enum\n\n        Raises:\n            N/A\n\n        \"\"\"\n        return self._netconf_base_channel_args.netconf_version\n\n    @netconf_version.setter\n    def netconf_version(self, value: NetconfVersion) -&gt; None:\n\"\"\"\n        Setter for 'netconf_version' attribute\n\n        Args:\n            value: NetconfVersion\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliTypeError: if value is not of type NetconfVersion\n\n        \"\"\"\n        if not isinstance(value, NetconfVersion):\n            raise ScrapliTypeError\n\n        self.logger.debug(f\"setting 'netconf_version' value to '{value.value}'\")\n\n        self._netconf_base_channel_args.netconf_version = value\n\n        if self._netconf_base_channel_args.netconf_version == NetconfVersion.VERSION_1_0:\n            self._base_channel_args.comms_prompt_pattern = \"]]&gt;]]&gt;\"\n        else:\n            self._base_channel_args.comms_prompt_pattern = r\"^##$\"\n\n    @property\n    def client_capabilities(self) -&gt; NetconfClientCapabilities:\n\"\"\"\n        Getter for 'client_capabilities' attribute\n\n        Args:\n            N/A\n\n        Returns:\n            NetconfClientCapabilities: netconf client capabilities enum\n\n        Raises:\n            N/A\n\n        \"\"\"\n        return self._netconf_base_channel_args.client_capabilities\n\n    @client_capabilities.setter\n    def client_capabilities(self, value: NetconfClientCapabilities) -&gt; None:\n\"\"\"\n        Setter for 'client_capabilities' attribute\n\n        Args:\n            value: NetconfClientCapabilities value for client_capabilities\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliTypeError: if value is not of type NetconfClientCapabilities\n\n        \"\"\"\n        if not isinstance(value, NetconfClientCapabilities):\n            raise ScrapliTypeError\n\n        self.logger.debug(f\"setting 'client_capabilities' value to '{value.value}'\")\n\n        self._netconf_base_channel_args.client_capabilities = value\n\n    @property\n    def server_capabilities(self) -&gt; List[str]:\n\"\"\"\n        Getter for 'server_capabilities' attribute\n\n        Args:\n            N/A\n\n        Returns:\n            list: list of strings of server capabilities\n\n        Raises:\n            N/A\n\n        \"\"\"\n        return self._netconf_base_channel_args.server_capabilities or []\n\n    @server_capabilities.setter\n    def server_capabilities(self, value: NetconfClientCapabilities) -&gt; None:\n\"\"\"\n        Setter for 'server_capabilities' attribute\n\n        Args:\n            value: list of strings of netconf server capabilities\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliTypeError: if value is not of type list\n\n        \"\"\"\n        if not isinstance(value, list):\n            raise ScrapliTypeError\n\n        self.logger.debug(f\"setting 'server_capabilities' value to '{value}'\")\n\n        self._netconf_base_channel_args.server_capabilities = value\n\n    @staticmethod\n    def _determine_preferred_netconf_version(\n        preferred_netconf_version: Optional[str],\n    ) -&gt; NetconfVersion:\n\"\"\"\n        Determine users preferred netconf version (if applicable)\n\n        Args:\n            preferred_netconf_version: optional string indicating users preferred netconf version\n\n        Returns:\n            NetconfVersion: users preferred netconf version\n\n        Raises:\n            ScrapliValueError: if preferred_netconf_version is not None or a valid option\n\n        \"\"\"\n        if preferred_netconf_version is None:\n            return NetconfVersion.UNKNOWN\n        if preferred_netconf_version == \"1.0\":\n            return NetconfVersion.VERSION_1_0\n        if preferred_netconf_version == \"1.1\":\n            return NetconfVersion.VERSION_1_1\n\n        raise ScrapliValueError(\n            \"'preferred_netconf_version' provided with invalid value, must be one of: \"\n            \"None, '1.0', or '1.1'\"\n        )\n\n    @staticmethod\n    def _determine_preferred_xml_parser(use_compressed_parser: bool) -&gt; XmlParserVersion:\n\"\"\"\n        Determine users preferred xml payload parser\n\n        Args:\n            use_compressed_parser: bool indicating use of compressed parser or not\n\n        Returns:\n            XmlParserVersion: users xml parser version\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if use_compressed_parser is True:\n            return XmlParserVersion.COMPRESSED_PARSER\n        return XmlParserVersion.STANDARD_PARSER\n\n    @property\n    def xml_parser(self) -&gt; etree.XMLParser:\n\"\"\"\n        Getter for 'xml_parser' attribute\n\n        Args:\n            N/A\n\n        Returns:\n            etree.XMLParser: parser to use for parsing xml documents\n\n        Raises:\n            N/A\n\n        \"\"\"\n        if self._netconf_base_channel_args.xml_parser == XmlParserVersion.COMPRESSED_PARSER:\n            return COMPRESSED_PARSER\n        return STANDARD_PARSER\n\n    @xml_parser.setter\n    def xml_parser(self, value: XmlParserVersion) -&gt; None:\n\"\"\"\n        Setter for 'xml_parser' attribute\n\n        Args:\n            value: enum indicating parser version to use\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliTypeError: if value is not of type XmlParserVersion\n\n        \"\"\"\n        if not isinstance(value, XmlParserVersion):\n            raise ScrapliTypeError\n\n        self._netconf_base_channel_args.xml_parser = value\n\n    def _transport_factory(self) -&gt; Tuple[Callable[..., Any], object]:\n\"\"\"\n        Determine proper transport class and necessary arguments to initialize that class\n\n        Args:\n            N/A\n\n        Returns:\n            Tuple[Callable[..., Any], object]: tuple of transport class and dataclass of transport\n                class specific arguments\n\n        Raises:\n            N/A\n\n        \"\"\"\n        transport_plugin_module = importlib.import_module(\n            f\"scrapli_netconf.transport.plugins.{self.transport_name}.transport\"\n        )\n\n        transport_class = getattr(\n            transport_plugin_module, f\"Netconf{self.transport_name.capitalize()}Transport\"\n        )\n        plugin_transport_args_class = getattr(transport_plugin_module, \"PluginTransportArgs\")\n\n        _plugin_transport_args = {\n            field.name: getattr(self, field.name) for field in fields(plugin_transport_args_class)\n        }\n\n        plugin_transport_args = plugin_transport_args_class(**_plugin_transport_args)\n\n        return transport_class, plugin_transport_args\n\n    def _build_readable_datastores(self) -&gt; None:\n\"\"\"\n        Build a list of readable datastores based on server's advertised capabilities\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.readable_datastores = []\n        self.readable_datastores.append(\"running\")\n        if \"urn:ietf:params:netconf:capability:candidate:1.0\" in self.server_capabilities:\n            self.readable_datastores.append(\"candidate\")\n        if \"urn:ietf:params:netconf:capability:startup:1.0\" in self.server_capabilities:\n            self.readable_datastores.append(\"startup\")\n\n    def _build_writeable_datastores(self) -&gt; None:\n\"\"\"\n        Build a list of writeable/editable datastores based on server's advertised capabilities\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.writeable_datastores = []\n        if \"urn:ietf:params:netconf:capability:writeable-running:1.0\" in self.server_capabilities:\n            self.writeable_datastores.append(\"running\")\n        if \"urn:ietf:params:netconf:capability:writable-running:1.0\" in self.server_capabilities:\n            # NOTE: iosxe shows \"writable\" (as of 2020.07.01) despite RFC being \"writeable\"\n            self.writeable_datastores.append(\"running\")\n        if \"urn:ietf:params:netconf:capability:candidate:1.0\" in self.server_capabilities:\n            self.writeable_datastores.append(\"candidate\")\n        if \"urn:ietf:params:netconf:capability:startup:1.0\" in self.server_capabilities:\n            self.writeable_datastores.append(\"startup\")\n\n    def _validate_get_config_target(self, source: str) -&gt; None:\n\"\"\"\n        Validate get-config source is acceptable\n\n        Args:\n            source: configuration source to get; typically one of running|startup|candidate\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliValueError: if an invalid source was selected and strict_datastores is True\n\n        \"\"\"\n        if source not in self.readable_datastores:\n            msg = f\"'source' should be one of {self.readable_datastores}, got '{source}'\"\n            self.logger.warning(msg)\n            if self.strict_datastores is True:\n                raise ScrapliValueError(msg)\n            user_warning(title=\"Invalid datastore source!\", message=msg)\n\n    def _validate_edit_config_target(self, target: str) -&gt; None:\n\"\"\"\n        Validate edit-config/lock/unlock target is acceptable\n\n        Args:\n            target: configuration source to edit/lock; typically one of running|startup|candidate\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliValueError: if an invalid source was selected\n\n        \"\"\"\n        if target not in self.writeable_datastores:\n            msg = f\"'target' should be one of {self.writeable_datastores}, got '{target}'\"\n            self.logger.warning(msg)\n            if self.strict_datastores is True:\n                raise ScrapliValueError(msg)\n            user_warning(title=\"Invalid datastore target!\", message=msg)\n\n    def _validate_delete_config_target(self, target: str) -&gt; None:\n\"\"\"\n        Validate delete-config/lock/unlock target is acceptable\n\n        Args:\n            target: configuration source to delete; typically one of startup|candidate\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliValueError: if an invalid target was selected\n\n        \"\"\"\n        if target == \"running\" or target not in self.writeable_datastores:\n            msg = f\"'target' should be one of {self.writeable_datastores}, got '{target}'\"\n            if target == \"running\":\n                msg = \"delete-config 'target' may not be 'running'\"\n            self.logger.warning(msg)\n            if self.strict_datastores is True:\n                raise ScrapliValueError(msg)\n            user_warning(title=\"Invalid datastore target!\", message=msg)\n\n    def _build_base_elem(self) -&gt; _Element:\n\"\"\"\n        Create base element for netconf operations\n\n        Args:\n            N/A\n\n        Returns:\n            _Element: lxml base element to use for netconf operation\n\n        Raises:\n            N/A\n\n        \"\"\"\n        # pylint did not seem to want to be ok with assigning this as a class attribute... and its\n        # only used here so... here we are\n        self.message_id: int  # pylint: disable=W0201\n        self.logger.debug(f\"Building base element for message id {self.message_id}\")\n        base_xml_str = NetconfBaseOperations.RPC.value.format(message_id=self.message_id)\n        self.message_id += 1\n        base_elem = etree.fromstring(text=base_xml_str)\n        return base_elem\n\n    def _build_filter(self, filter_: str, filter_type: str = \"subtree\") -&gt; _Element:\n\"\"\"\n        Create filter element for a given rpc\n\n        The `filter_` string may contain multiple xml elements at its \"root\" (subtree filters); we\n        will simply place the payload into a temporary \"tmp\" outer tag so that when we cast it to an\n        etree object the elements are all preserved; without this outer \"tmp\" tag, lxml will scoop\n        up only the first element provided as it appears to be the root of the document presumably.\n\n        An example valid (to scrapli netconf at least) xml filter would be:\n\n        ```\n        &lt;interface-configurations xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-ifmgr-cfg\"&gt;\n            &lt;interface-configuration&gt;\n                &lt;active&gt;act&lt;/active&gt;\n            &lt;/interface-configuration&gt;\n        &lt;/interface-configurations&gt;\n        &lt;netconf-yang xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-man-netconf-cfg\"&gt;\n        &lt;/netconf-yang&gt;\n        ```\n\n        Args:\n            filter_: strings of filters to build into a filter element or (for subtree) a full\n                filter string (in filter tags)\n            filter_type: type of filter; subtree|xpath\n\n        Returns:\n            _Element: lxml filter element to use for netconf operation\n\n        Raises:\n            CapabilityNotSupported: if xpath selected and not supported on server\n            ScrapliValueError: if filter_type is not one of subtree|xpath\n\n        \"\"\"\n        if filter_type == \"subtree\":\n            # tmp tags to place the users kinda not valid xml filter into\n            _filter_ = f\"&lt;tmp&gt;{filter_}&lt;/tmp&gt;\"\n            # \"validate\" subtree filter by forcing it into xml, parser \"flattens\" it as well\n            tmp_xml_filter_element = etree.fromstring(_filter_, parser=self.xml_parser)\n\n            if tmp_xml_filter_element.getchildren()[0].tag == \"filter\":\n                # if the user filter was already wrapped in filter tags we'll end up here, we will\n                # blindly reuse the users filter but we'll make sure that the filter \"type\" is set\n                xml_filter_elem = tmp_xml_filter_element.getchildren()[0]\n                xml_filter_elem.attrib[\"type\"] = \"subtree\"\n            else:\n                xml_filter_elem = etree.fromstring(\n                    NetconfBaseOperations.FILTER_SUBTREE.value.format(filter_type=filter_type),\n                )\n\n                # iterate through the children inside the tmp tags and insert *those* elements into\n                # the actual final filter payload\n                for xml_filter_element in tmp_xml_filter_element:\n                    # insert the subtree filter into the parent filter element\n                    xml_filter_elem.insert(1, xml_filter_element)\n\n        elif filter_type == \"xpath\":\n            if \"urn:ietf:params:netconf:capability:xpath:1.0\" not in self.server_capabilities:\n                msg = \"xpath filter requested, but is not supported by the server\"\n                self.logger.exception(msg)\n                raise CapabilityNotSupported(msg)\n            xml_filter_elem = etree.fromstring(\n                NetconfBaseOperations.FILTER_XPATH.value.format(\n                    filter_type=filter_type, xpath=filter_\n                ),\n                parser=self.xml_parser,\n            )\n        else:\n            raise ScrapliValueError(\n                f\"'filter_type' should be one of subtree|xpath, got '{filter_type}'\"\n            )\n        return xml_filter_elem\n\n    def _build_with_defaults(self, default_type: str = \"report-all\") -&gt; _Element:\n\"\"\"\n        Create with-defaults element for a given operation\n\n        Args:\n            default_type: enumeration of with-defaults; report-all|trim|explicit|report-all-tagged\n\n        Returns:\n            _Element: lxml with-defaults element to use for netconf operation\n\n        Raises:\n            CapabilityNotSupported: if default_type provided but not supported by device\n            ScrapliValueError: if default_type is not one of\n                report-all|trim|explicit|report-all-tagged\n\n        \"\"\"\n\n        if default_type in [\"report-all\", \"trim\", \"explicit\", \"report-all-tagged\"]:\n            if not any(\n                \"urn:ietf:params:netconf:capability:with-defaults:1.0\" in sc\n                for sc in self.server_capabilities\n            ):\n                msg = \"with-defaults requested, but is not supported by the server\"\n                self.logger.exception(msg)\n                raise CapabilityNotSupported(msg)\n            xml_with_defaults_element = etree.fromstring(\n                NetconfBaseOperations.WITH_DEFAULTS_SUBTREE.value.format(default_type=default_type),\n                parser=self.xml_parser,\n            )\n        else:\n            raise ScrapliValueError(\n                \"'default_type' should be one of report-all|trim|explicit|report-all-tagged, \"\n                f\"got '{default_type}'\"\n            )\n        return xml_with_defaults_element\n\n    def _finalize_channel_input(self, xml_request: _Element) -&gt; bytes:\n\"\"\"\n        Create finalized channel input (as bytes)\n\n        Args:\n            xml_request: finalized xml element to cast to bytes and add declaration to\n\n        Returns:\n            bytes: finalized bytes input -- with 1.0 delimiter or 1.1 encoding\n\n        Raises:\n            N/A\n\n        \"\"\"\n        channel_input: bytes = etree.tostring(\n            element_or_tree=xml_request, xml_declaration=True, encoding=\"utf-8\"\n        )\n\n        if self.netconf_version == NetconfVersion.VERSION_1_0:\n            channel_input = channel_input + b\"]]&gt;]]&gt;\"\n        else:\n            # format message for chunk (netconf 1.1) style message\n            channel_input = b\"#%b\\n\" % str(len(channel_input)).encode() + channel_input + b\"\\n##\"\n\n        return channel_input\n\n    def _pre_get(self, filter_: str, filter_type: str = \"subtree\") -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"get\" tasks for consistency between sync/async versions\n\n        *NOTE*\n        The channel input (filter_) is loaded up as an lxml etree element here, this is done with a\n        parser that removes whitespace. This has a somewhat undesirable effect of making any\n        \"pretty\" input not pretty, however... after we load the xml object (which we do to validate\n        that it is valid xml) we dump that xml object back to a string to be used as the actual\n        raw payload we send down the channel, which means we are sending \"flattened\" (not pretty/\n        indented xml) to the device. This is important it seems! Some devices seme to not mind\n        having the \"nicely\" formatted input (pretty xml). But! On devices that \"echo\" the inputs\n        back -- sometimes the device will respond to our rpc without \"finishing\" echoing our inputs\n        to the device, this breaks the core \"read until input\" processing that scrapli always does.\n        For whatever reason if there are no line breaks this does not seem to happen? /shrug. Note\n        that this comment applies to all of the \"pre\" methods that we parse a filter/payload!\n\n        Args:\n            filter_: string filter to apply to the get\n            filter_type: type of filter; subtree|xpath\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.logger.debug(\n            f\"Building payload for 'get' operation. filter_type: {filter_type}, filter_: {filter_}\"\n        )\n\n        # build base request and insert the get element\n        xml_request = self._build_base_elem()\n        xml_get_element = etree.fromstring(NetconfBaseOperations.GET.value)\n        xml_request.insert(0, xml_get_element)\n\n        # build filter element\n        xml_filter_elem = self._build_filter(filter_=filter_, filter_type=filter_type)\n\n        # insert filter element into parent get element\n        get_element = xml_request.find(\"get\")\n        get_element.insert(0, xml_filter_elem)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(f\"Built payload for 'get' operation. Payload: {channel_input.decode()}\")\n        return response\n\n    def _pre_get_config(\n        self,\n        source: str = \"running\",\n        filter_: Optional[str] = None,\n        filter_type: str = \"subtree\",\n        default_type: Optional[str] = None,\n    ) -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"get_config\" tasks for consistency between sync/async versions\n\n        Args:\n            source: configuration source to get; typically one of running|startup|candidate\n            filter_: string of filter(s) to apply to configuration\n            filter_type: type of filter; subtree|xpath\n            default_type: string of with-default mode to apply when retrieving configuration\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.logger.debug(\n            f\"Building payload for 'get-config' operation. source: {source}, filter_type: \"\n            f\"{filter_type}, filter: {filter_}, default_type: {default_type}\"\n        )\n        self._validate_get_config_target(source=source)\n\n        # build base request and insert the get-config element\n        xml_request = self._build_base_elem()\n        xml_get_config_element = etree.fromstring(\n            NetconfBaseOperations.GET_CONFIG.value.format(source=source), parser=self.xml_parser\n        )\n        xml_request.insert(0, xml_get_config_element)\n\n        if filter_ is not None:\n            xml_filter_elem = self._build_filter(filter_=filter_, filter_type=filter_type)\n            # insert filter element into parent get element\n            get_element = xml_request.find(\"get-config\")\n            # insert *after* source, otherwise juniper seems to gripe, maybe/probably others as well\n            get_element.insert(1, xml_filter_elem)\n\n        if default_type is not None:\n            xml_with_defaults_elem = self._build_with_defaults(default_type=default_type)\n            get_element = xml_request.find(\"get-config\")\n            get_element.insert(2, xml_with_defaults_elem)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(\n            f\"Built payload for 'get-config' operation. Payload: {channel_input.decode()}\"\n        )\n        return response\n\n    def _pre_edit_config(self, config: str, target: str = \"running\") -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"edit_config\" tasks for consistency between sync/async versions\n\n        Args:\n            config: configuration to send to device\n            target: configuration source to target; running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.logger.debug(\n            f\"Building payload for 'edit-config' operation. target: {target}, config: {config}\"\n        )\n        self._validate_edit_config_target(target=target)\n\n        xml_config = etree.fromstring(config, parser=self.xml_parser)\n\n        # build base request and insert the edit-config element\n        xml_request = self._build_base_elem()\n        xml_edit_config_element = etree.fromstring(\n            NetconfBaseOperations.EDIT_CONFIG.value.format(target=target)\n        )\n        xml_request.insert(0, xml_edit_config_element)\n\n        # insert parent filter element to first position so that target stays first just for nice\n        # output/readability\n        edit_config_element = xml_request.find(\"edit-config\")\n        edit_config_element.insert(1, xml_config)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(\n            f\"Built payload for 'edit-config' operation. Payload: {channel_input.decode()}\"\n        )\n        return response\n\n    def _pre_delete_config(self, target: str = \"running\") -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"edit_config\" tasks for consistency between sync/async versions\n\n        Args:\n            target: configuration source to target; startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.logger.debug(f\"Building payload for 'delete-config' operation. target: {target}\")\n        self._validate_delete_config_target(target=target)\n\n        xml_request = self._build_base_elem()\n        xml_validate_element = etree.fromstring(\n            NetconfBaseOperations.DELETE_CONFIG.value.format(target=target), parser=self.xml_parser\n        )\n        xml_request.insert(0, xml_validate_element)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(\n            f\"Built payload for 'delete-config' operation. Payload: {channel_input.decode()}\"\n        )\n        return response\n\n    def _pre_commit(\n        self,\n        confirmed: bool = False,\n        timeout: Optional[int] = None,\n        persist: Optional[Union[int, str]] = None,\n        persist_id: Optional[Union[int, str]] = None,\n    ) -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"commit\" tasks for consistency between sync/async versions\n\n        Args:\n            confirmed: whether this is a confirmed commit\n            timeout: specifies the confirm timeout in seconds\n            persist: make the confirmed commit survive a session termination, and set a token on\n                the ongoing confirmed commit\n            persist_id: value must be equal to the value given in the &lt;persist&gt; parameter to the\n                original &lt;commit&gt; operation.\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            ScrapliValueError: if persist and persist_id are provided (cannot combine)\n            ScrapliValueError: if confirmed and persist_id are provided (cannot combine)\n            CapabilityNotSupported: if device does not have confirmed-commit capability\n\n        \"\"\"\n        self.logger.debug(\"Building payload for 'commit' operation\")\n        xml_request = self._build_base_elem()\n        xml_commit_element = etree.fromstring(\n            NetconfBaseOperations.COMMIT.value, parser=self.xml_parser\n        )\n\n        if persist and persist_id:\n            raise ScrapliValueError(\n                \"Invalid combination - 'persist' cannot be present with 'persist-id'\"\n            )\n        if confirmed and persist_id:\n            raise ScrapliValueError(\n                \"Invalid combination - 'confirmed' cannot be present with 'persist-id'\"\n            )\n\n        if confirmed or persist_id:\n            if not any(\n                cap in self.server_capabilities\n                for cap in (\n                    \"urn:ietf:params:netconf:capability:confirmed-commit:1.0\",\n                    \"urn:ietf:params:netconf:capability:confirmed-commit:1.1\",\n                )\n            ):\n                msg = \"confirmed-commit requested, but is not supported by the server\"\n                self.logger.exception(msg)\n                raise CapabilityNotSupported(msg)\n\n        if confirmed:\n            xml_confirmed_element = etree.fromstring(\n                NetconfBaseOperations.COMMIT_CONFIRMED.value, parser=self.xml_parser\n            )\n            xml_commit_element.append(xml_confirmed_element)\n\n            if timeout is not None:\n                xml_timeout_element = etree.fromstring(\n                    NetconfBaseOperations.COMMIT_CONFIRMED_TIMEOUT.value.format(timeout=timeout),\n                    parser=self.xml_parser,\n                )\n                xml_commit_element.append(xml_timeout_element)\n\n            if persist is not None:\n                xml_persist_element = etree.fromstring(\n                    NetconfBaseOperations.COMMIT_CONFIRMED_PERSIST.value.format(persist=persist),\n                    parser=self.xml_parser,\n                )\n                xml_commit_element.append(xml_persist_element)\n\n        if persist_id is not None:\n            xml_persist_id_element = etree.fromstring(\n                NetconfBaseOperations.COMMIT_PERSIST_ID.value.format(persist_id=persist_id),\n                parser=self.xml_parser,\n            )\n            xml_commit_element.append(xml_persist_id_element)\n\n        xml_request.insert(0, xml_commit_element)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(\n            f\"Built payload for 'commit' operation. Payload: {channel_input.decode()}\"\n        )\n        return response\n\n    def _pre_discard(self) -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"discard\" tasks for consistency between sync/async versions\n\n        Args:\n            N/A\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.logger.debug(\"Building payload for 'discard' operation.\")\n        xml_request = self._build_base_elem()\n        xml_commit_element = etree.fromstring(\n            NetconfBaseOperations.DISCARD.value, parser=self.xml_parser\n        )\n        xml_request.insert(0, xml_commit_element)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(\n            f\"Built payload for 'discard' operation. Payload: {channel_input.decode()}\"\n        )\n        return response\n\n    def _pre_lock(self, target: str) -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"lock\" tasks for consistency between sync/async versions\n\n        Args:\n            target: configuration source to target; running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.logger.debug(\"Building payload for 'lock' operation.\")\n        self._validate_edit_config_target(target=target)\n\n        xml_request = self._build_base_elem()\n        xml_lock_element = etree.fromstring(\n            NetconfBaseOperations.LOCK.value.format(target=target), parser=self.xml_parser\n        )\n        xml_request.insert(0, xml_lock_element)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(f\"Built payload for 'lock' operation. Payload: {channel_input.decode()}\")\n        return response\n\n    def _pre_unlock(self, target: str) -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"unlock\" tasks for consistency between sync/async versions\n\n        Args:\n            target: configuration source to target; running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.logger.debug(\"Building payload for 'unlock' operation.\")\n        self._validate_edit_config_target(target=target)\n\n        xml_request = self._build_base_elem()\n        xml_lock_element = etree.fromstring(\n            NetconfBaseOperations.UNLOCK.value.format(target=target), parser=self.xml_parser\n        )\n        xml_request.insert(0, xml_lock_element)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(\n            f\"Built payload for 'unlock' operation. Payload: {channel_input.decode()}\"\n        )\n        return response\n\n    def _pre_rpc(self, filter_: Union[str, _Element]) -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"rpc\" tasks for consistency between sync/async versions\n\n        Args:\n            filter_: filter/rpc to execute\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.logger.debug(\"Building payload for 'rpc' operation.\")\n        xml_request = self._build_base_elem()\n\n        # build filter element\n        if isinstance(filter_, str):\n            xml_filter_elem = etree.fromstring(filter_, parser=self.xml_parser)\n        else:\n            xml_filter_elem = filter_\n\n        # insert filter element\n        xml_request.insert(0, xml_filter_elem)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(f\"Built payload for 'rpc' operation. Payload: {channel_input.decode()}\")\n        return response\n\n    def _pre_validate(self, source: str) -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"validate\" tasks for consistency between sync/async versions\n\n        Args:\n            source: configuration source to validate; typically one of running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            CapabilityNotSupported: if 'validate' capability does not exist\n\n        \"\"\"\n        self.logger.debug(\"Building payload for 'validate' operation.\")\n\n        if not any(\n            cap in self.server_capabilities\n            for cap in (\n                \"urn:ietf:params:netconf:capability:validate:1.0\",\n                \"urn:ietf:params:netconf:capability:validate:1.1\",\n            )\n        ):\n            msg = \"validate requested, but is not supported by the server\"\n            self.logger.exception(msg)\n            raise CapabilityNotSupported(msg)\n\n        self._validate_edit_config_target(target=source)\n\n        xml_request = self._build_base_elem()\n        xml_validate_element = etree.fromstring(\n            NetconfBaseOperations.VALIDATE.value.format(source=source), parser=self.xml_parser\n        )\n        xml_request.insert(0, xml_validate_element)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(\n            f\"Built payload for 'validate' operation. Payload: {channel_input.decode()}\"\n        )\n        return response\n\n    def _pre_copy_config(self, source: str, target: str) -&gt; NetconfResponse:\n\"\"\"\n        Handle pre \"copy_config\" tasks for consistency between sync/async versions\n\n        Note that source is not validated/checked since it could be a url or a full configuration\n        element itself.\n\n        Args:\n            source: configuration, url, or datastore to copy into the target datastore\n            target: copy config destination/target; typically one of running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary\n                channel inputs (string and xml)\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.logger.debug(\"Building payload for 'copy_config' operation.\")\n\n        self._validate_edit_config_target(target=target)\n\n        xml_request = self._build_base_elem()\n        xml_validate_element = etree.fromstring(\n            NetconfBaseOperations.COPY_CONFIG.value.format(source=source, target=target),\n            parser=self.xml_parser,\n        )\n        xml_request.insert(0, xml_validate_element)\n\n        channel_input = self._finalize_channel_input(xml_request=xml_request)\n\n        response = NetconfResponse(\n            host=self.host,\n            channel_input=channel_input.decode(),\n            xml_input=xml_request,\n            netconf_version=self.netconf_version,\n            strip_namespaces=self.strip_namespaces,\n        )\n        self.logger.debug(\n            f\"Built payload for 'copy-config' operation. Payload: {channel_input.decode()}\"\n        )\n        return response\n</code></pre>"},{"location":"reference/driver/base_driver/#driver.base_driver.NetconfBaseDriver.client_capabilities","title":"<code>client_capabilities() -&gt; NetconfClientCapabilities</code>  <code>property</code> <code>writable</code>","text":"<p>Getter for 'client_capabilities' attribute</p> <p>Returns:</p> Name Type Description <code>NetconfClientCapabilities</code> <code>NetconfClientCapabilities</code> <p>netconf client capabilities enum</p> Source code in <code>driver/base_driver.py</code> <pre><code>@property\ndef client_capabilities(self) -&gt; NetconfClientCapabilities:\n\"\"\"\n    Getter for 'client_capabilities' attribute\n\n    Args:\n        N/A\n\n    Returns:\n        NetconfClientCapabilities: netconf client capabilities enum\n\n    Raises:\n        N/A\n\n    \"\"\"\n    return self._netconf_base_channel_args.client_capabilities\n</code></pre>"},{"location":"reference/driver/base_driver/#driver.base_driver.NetconfBaseDriver.netconf_version","title":"<code>netconf_version() -&gt; NetconfVersion</code>  <code>property</code> <code>writable</code>","text":"<p>Getter for 'netconf_version' attribute</p> <p>Returns:</p> Name Type Description <code>NetconfVersion</code> <code>NetconfVersion</code> <p>netconf_version enum</p> Source code in <code>driver/base_driver.py</code> <pre><code>@property\ndef netconf_version(self) -&gt; NetconfVersion:\n\"\"\"\n    Getter for 'netconf_version' attribute\n\n    Args:\n        N/A\n\n    Returns:\n        NetconfVersion: netconf_version enum\n\n    Raises:\n        N/A\n\n    \"\"\"\n    return self._netconf_base_channel_args.netconf_version\n</code></pre>"},{"location":"reference/driver/base_driver/#driver.base_driver.NetconfBaseDriver.server_capabilities","title":"<code>server_capabilities() -&gt; List[str]</code>  <code>property</code> <code>writable</code>","text":"<p>Getter for 'server_capabilities' attribute</p> <p>Returns:</p> Name Type Description <code>list</code> <code>List[str]</code> <p>list of strings of server capabilities</p> Source code in <code>driver/base_driver.py</code> <pre><code>@property\ndef server_capabilities(self) -&gt; List[str]:\n\"\"\"\n    Getter for 'server_capabilities' attribute\n\n    Args:\n        N/A\n\n    Returns:\n        list: list of strings of server capabilities\n\n    Raises:\n        N/A\n\n    \"\"\"\n    return self._netconf_base_channel_args.server_capabilities or []\n</code></pre>"},{"location":"reference/driver/base_driver/#driver.base_driver.NetconfBaseDriver.xml_parser","title":"<code>xml_parser() -&gt; etree.XMLParser</code>  <code>property</code> <code>writable</code>","text":"<p>Getter for 'xml_parser' attribute</p> <p>Returns:</p> Type Description <code>etree.XMLParser</code> <p>etree.XMLParser: parser to use for parsing xml documents</p> Source code in <code>driver/base_driver.py</code> <pre><code>@property\ndef xml_parser(self) -&gt; etree.XMLParser:\n\"\"\"\n    Getter for 'xml_parser' attribute\n\n    Args:\n        N/A\n\n    Returns:\n        etree.XMLParser: parser to use for parsing xml documents\n\n    Raises:\n        N/A\n\n    \"\"\"\n    if self._netconf_base_channel_args.xml_parser == XmlParserVersion.COMPRESSED_PARSER:\n        return COMPRESSED_PARSER\n    return STANDARD_PARSER\n</code></pre>"},{"location":"reference/driver/sync_driver/","title":"sync_driver","text":"<p>scrapli_netconf.driver.sync_driver</p>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver","title":"<code>NetconfDriver</code>","text":"<p>         Bases: <code>Driver</code>, <code>NetconfBaseDriver</code></p> Source code in <code>driver/sync_driver.py</code> <pre><code>class NetconfDriver(Driver, NetconfBaseDriver):\n    # kinda hate this but need to tell mypy that channel in netconf land is in fact a channel of\n    # type `NetconfChannel`\n    channel: NetconfChannel\n\n    def __init__(\n        self,\n        host: str,\n        port: int = 830,\n        strip_namespaces: bool = False,\n        strict_datastores: bool = False,\n        auth_username: str = \"\",\n        auth_password: str = \"\",\n        auth_private_key: str = \"\",\n        auth_private_key_passphrase: str = \"\",\n        auth_strict_key: bool = True,\n        auth_bypass: bool = False,\n        timeout_socket: float = 15.0,\n        timeout_transport: float = 30.0,\n        timeout_ops: float = 30.0,\n        comms_prompt_pattern: str = r\"^[a-z0-9.\\-@()/:]{1,48}[#&gt;$]\\s*$\",\n        comms_return_char: str = \"\\n\",\n        ssh_config_file: Union[str, bool] = False,\n        ssh_known_hosts_file: Union[str, bool] = False,\n        on_init: Optional[Callable[..., Any]] = None,\n        on_open: Optional[Callable[..., Any]] = None,\n        on_close: Optional[Callable[..., Any]] = None,\n        transport: str = \"system\",\n        transport_options: Optional[Dict[str, Any]] = None,\n        channel_log: Union[str, bool] = False,\n        channel_lock: bool = False,\n        preferred_netconf_version: Optional[str] = None,\n        use_compressed_parser: bool = True,\n    ) -&gt; None:\n        super().__init__(\n            host=host,\n            port=port,\n            auth_username=auth_username,\n            auth_password=auth_password,\n            auth_private_key=auth_private_key,\n            auth_private_key_passphrase=auth_private_key_passphrase,\n            auth_strict_key=auth_strict_key,\n            auth_bypass=auth_bypass,\n            timeout_socket=timeout_socket,\n            timeout_transport=timeout_transport,\n            timeout_ops=timeout_ops,\n            comms_prompt_pattern=comms_prompt_pattern,\n            comms_return_char=comms_return_char,\n            ssh_config_file=ssh_config_file,\n            ssh_known_hosts_file=ssh_known_hosts_file,\n            on_init=on_init,\n            on_open=on_open,\n            on_close=on_close,\n            transport=transport,\n            transport_options=transport_options,\n            channel_log=channel_log,\n            channel_lock=channel_lock,\n        )\n\n        _preferred_netconf_version = self._determine_preferred_netconf_version(\n            preferred_netconf_version=preferred_netconf_version\n        )\n        _preferred_xml_parser = self._determine_preferred_xml_parser(\n            use_compressed_parser=use_compressed_parser\n        )\n        self._netconf_base_channel_args = NetconfBaseChannelArgs(\n            netconf_version=_preferred_netconf_version, xml_parser=_preferred_xml_parser\n        )\n\n        self.channel = NetconfChannel(\n            transport=self.transport,\n            base_channel_args=self._base_channel_args,\n            netconf_base_channel_args=self._netconf_base_channel_args,\n        )\n\n        self.strip_namespaces = strip_namespaces\n        self.strict_datastores = strict_datastores\n        self.server_capabilities: List[str] = []\n        self.readable_datastores: List[str] = []\n        self.writeable_datastores: List[str] = []\n        self.message_id = 101\n\n    def open(self) -&gt; None:\n\"\"\"\n        Open netconf connection to server\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self._pre_open_closing_log(closing=False)\n\n        self.transport.open_netconf()\n\n        # in the future this and scrapli core should just have a class attribute of the transports\n        # that require this \"in channel\" auth so we can dynamically figure that out rather than\n        # just look at the name of the transport\n        if \"system\" in self.transport_name:\n            self.channel.channel_authenticate_netconf(\n                auth_password=self.auth_password,\n                auth_private_key_passphrase=self.auth_private_key_passphrase,\n            )\n\n        self.channel.open_netconf()\n\n        self._build_readable_datastores()\n        self._build_writeable_datastores()\n\n        self._post_open_closing_log(closing=False)\n\n    def get(self, filter_: str, filter_type: str = \"subtree\") -&gt; NetconfResponse:\n\"\"\"\n        Netconf get operation\n\n        Args:\n            filter_: filter to apply to the get\n            filter_type: type of filter; subtree|xpath\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_get(filter_=filter_, filter_type=filter_type)\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    def get_config(\n        self,\n        source: str = \"running\",\n        filter_: Optional[str] = None,\n        filter_type: str = \"subtree\",\n        default_type: Optional[str] = None,\n    ) -&gt; NetconfResponse:\n\"\"\"\n        Netconf get-config operation\n\n        Args:\n            source: configuration source to get; typically one of running|startup|candidate\n            filter_: string of filter(s) to apply to configuration\n            filter_type: type of filter; subtree|xpath\n            default_type: string of with-default mode to apply when retrieving configuration\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_get_config(\n            source=source, filter_=filter_, filter_type=filter_type, default_type=default_type\n        )\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n\n        response.record_response(raw_response)\n        return response\n\n    def edit_config(self, config: str, target: str = \"running\") -&gt; NetconfResponse:\n\"\"\"\n        Netconf get-config operation\n\n        Args:\n            config: configuration to send to device\n            target: configuration source to target; running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_edit_config(config=config, target=target)\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    def delete_config(self, target: str = \"candidate\") -&gt; NetconfResponse:\n\"\"\"\n        Netconf delete-config operation\n\n        Args:\n            target: configuration source to target; startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_delete_config(target=target)\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    def commit(\n        self,\n        confirmed: bool = False,\n        timeout: Optional[int] = None,\n        persist: Optional[Union[int, str]] = None,\n        persist_id: Optional[Union[int, str]] = None,\n    ) -&gt; NetconfResponse:\n\"\"\"\n        Netconf commit config operation\n\n        Args:\n            confirmed: whether this is a confirmed commit\n            timeout: specifies the confirm timeout in seconds\n            persist: make the confirmed commit survive a session termination, and set a token on\n                the ongoing confirmed commit\n            persist_id: value must be equal to the value given in the &lt;persist&gt; parameter to the\n                original &lt;commit&gt; operation.\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_commit(\n            confirmed=confirmed,\n            timeout=timeout,\n            persist=persist,\n            persist_id=persist_id,\n        )\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    def discard(self) -&gt; NetconfResponse:\n\"\"\"\n        Netconf discard config operation\n\n        Args:\n            N/A\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_discard()\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    def lock(self, target: str) -&gt; NetconfResponse:\n\"\"\"\n        Netconf lock operation\n\n        Args:\n            target: configuration source to target; running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_lock(target=target)\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    def unlock(self, target: str) -&gt; NetconfResponse:\n\"\"\"\n        Netconf unlock operation\n\n        Args:\n            target: configuration source to target; running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_unlock(target=target)\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    def rpc(self, filter_: Union[str, _Element]) -&gt; NetconfResponse:\n\"\"\"\n        Netconf \"rpc\" operation\n\n        Typically used with juniper devices or if you want to build/send your own payload in a more\n        manual fashion. You can provide a string that will be loaded as an lxml element, or you can\n        provide an lxml element yourself.\n\n        Args:\n            filter_: filter/rpc to execute\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_rpc(filter_=filter_)\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    def validate(self, source: str) -&gt; NetconfResponse:\n\"\"\"\n        Netconf \"validate\" operation\n\n        Args:\n            source: configuration source to validate; typically one of running|startup|candidate\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_validate(source=source)\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n\n    def copy_config(self, source: str, target: str) -&gt; NetconfResponse:\n\"\"\"\n        Netconf \"copy-config\" operation\n\n        Args:\n            source: configuration, url, or datastore to copy into the target datastore\n            target: destination to copy the source to\n\n        Returns:\n            NetconfResponse: scrapli_netconf NetconfResponse object\n\n        Raises:\n            N/A\n\n        \"\"\"\n        response = self._pre_copy_config(source=source, target=target)\n        raw_response = self.channel.send_input_netconf(response.channel_input)\n        response.record_response(raw_response)\n        return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.commit","title":"<code>commit(confirmed: bool = False, timeout: Optional[int] = None, persist: Optional[Union[int, str]] = None, persist_id: Optional[Union[int, str]] = None) -&gt; NetconfResponse</code>","text":"<p>Netconf commit config operation</p> <p>Parameters:</p> Name Type Description Default <code>confirmed</code> <code>bool</code> <p>whether this is a confirmed commit</p> <code>False</code> <code>timeout</code> <code>Optional[int]</code> <p>specifies the confirm timeout in seconds</p> <code>None</code> <code>persist</code> <code>Optional[Union[int, str]]</code> <p>make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit</p> <code>None</code> <code>persist_id</code> <code>Optional[Union[int, str]]</code> <p>value must be equal to the value given in the  parameter to the original  operation. <code>None</code> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def commit(\n    self,\n    confirmed: bool = False,\n    timeout: Optional[int] = None,\n    persist: Optional[Union[int, str]] = None,\n    persist_id: Optional[Union[int, str]] = None,\n) -&gt; NetconfResponse:\n\"\"\"\n    Netconf commit config operation\n\n    Args:\n        confirmed: whether this is a confirmed commit\n        timeout: specifies the confirm timeout in seconds\n        persist: make the confirmed commit survive a session termination, and set a token on\n            the ongoing confirmed commit\n        persist_id: value must be equal to the value given in the &lt;persist&gt; parameter to the\n            original &lt;commit&gt; operation.\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_commit(\n        confirmed=confirmed,\n        timeout=timeout,\n        persist=persist,\n        persist_id=persist_id,\n    )\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.copy_config","title":"<code>copy_config(source: str, target: str) -&gt; NetconfResponse</code>","text":"<p>Netconf \"copy-config\" operation</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>configuration, url, or datastore to copy into the target datastore</p> required <code>target</code> <code>str</code> <p>destination to copy the source to</p> required <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def copy_config(self, source: str, target: str) -&gt; NetconfResponse:\n\"\"\"\n    Netconf \"copy-config\" operation\n\n    Args:\n        source: configuration, url, or datastore to copy into the target datastore\n        target: destination to copy the source to\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_copy_config(source=source, target=target)\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.delete_config","title":"<code>delete_config(target: str = 'candidate') -&gt; NetconfResponse</code>","text":"<p>Netconf delete-config operation</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>configuration source to target; startup|candidate</p> <code>'candidate'</code> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def delete_config(self, target: str = \"candidate\") -&gt; NetconfResponse:\n\"\"\"\n    Netconf delete-config operation\n\n    Args:\n        target: configuration source to target; startup|candidate\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_delete_config(target=target)\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.discard","title":"<code>discard() -&gt; NetconfResponse</code>","text":"<p>Netconf discard config operation</p> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def discard(self) -&gt; NetconfResponse:\n\"\"\"\n    Netconf discard config operation\n\n    Args:\n        N/A\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_discard()\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.edit_config","title":"<code>edit_config(config: str, target: str = 'running') -&gt; NetconfResponse</code>","text":"<p>Netconf get-config operation</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>str</code> <p>configuration to send to device</p> required <code>target</code> <code>str</code> <p>configuration source to target; running|startup|candidate</p> <code>'running'</code> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def edit_config(self, config: str, target: str = \"running\") -&gt; NetconfResponse:\n\"\"\"\n    Netconf get-config operation\n\n    Args:\n        config: configuration to send to device\n        target: configuration source to target; running|startup|candidate\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_edit_config(config=config, target=target)\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.get","title":"<code>get(filter_: str, filter_type: str = 'subtree') -&gt; NetconfResponse</code>","text":"<p>Netconf get operation</p> <p>Parameters:</p> Name Type Description Default <code>filter_</code> <code>str</code> <p>filter to apply to the get</p> required <code>filter_type</code> <code>str</code> <p>type of filter; subtree|xpath</p> <code>'subtree'</code> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def get(self, filter_: str, filter_type: str = \"subtree\") -&gt; NetconfResponse:\n\"\"\"\n    Netconf get operation\n\n    Args:\n        filter_: filter to apply to the get\n        filter_type: type of filter; subtree|xpath\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_get(filter_=filter_, filter_type=filter_type)\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.get_config","title":"<code>get_config(source: str = 'running', filter_: Optional[str] = None, filter_type: str = 'subtree', default_type: Optional[str] = None) -&gt; NetconfResponse</code>","text":"<p>Netconf get-config operation</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>configuration source to get; typically one of running|startup|candidate</p> <code>'running'</code> <code>filter_</code> <code>Optional[str]</code> <p>string of filter(s) to apply to configuration</p> <code>None</code> <code>filter_type</code> <code>str</code> <p>type of filter; subtree|xpath</p> <code>'subtree'</code> <code>default_type</code> <code>Optional[str]</code> <p>string of with-default mode to apply when retrieving configuration</p> <code>None</code> <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def get_config(\n    self,\n    source: str = \"running\",\n    filter_: Optional[str] = None,\n    filter_type: str = \"subtree\",\n    default_type: Optional[str] = None,\n) -&gt; NetconfResponse:\n\"\"\"\n    Netconf get-config operation\n\n    Args:\n        source: configuration source to get; typically one of running|startup|candidate\n        filter_: string of filter(s) to apply to configuration\n        filter_type: type of filter; subtree|xpath\n        default_type: string of with-default mode to apply when retrieving configuration\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_get_config(\n        source=source, filter_=filter_, filter_type=filter_type, default_type=default_type\n    )\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.lock","title":"<code>lock(target: str) -&gt; NetconfResponse</code>","text":"<p>Netconf lock operation</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>configuration source to target; running|startup|candidate</p> required <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def lock(self, target: str) -&gt; NetconfResponse:\n\"\"\"\n    Netconf lock operation\n\n    Args:\n        target: configuration source to target; running|startup|candidate\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_lock(target=target)\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.open","title":"<code>open() -&gt; None</code>","text":"<p>Open netconf connection to server</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def open(self) -&gt; None:\n\"\"\"\n    Open netconf connection to server\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self._pre_open_closing_log(closing=False)\n\n    self.transport.open_netconf()\n\n    # in the future this and scrapli core should just have a class attribute of the transports\n    # that require this \"in channel\" auth so we can dynamically figure that out rather than\n    # just look at the name of the transport\n    if \"system\" in self.transport_name:\n        self.channel.channel_authenticate_netconf(\n            auth_password=self.auth_password,\n            auth_private_key_passphrase=self.auth_private_key_passphrase,\n        )\n\n    self.channel.open_netconf()\n\n    self._build_readable_datastores()\n    self._build_writeable_datastores()\n\n    self._post_open_closing_log(closing=False)\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.rpc","title":"<code>rpc(filter_: Union[str, _Element]) -&gt; NetconfResponse</code>","text":"<p>Netconf \"rpc\" operation</p> <p>Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself.</p> <p>Parameters:</p> Name Type Description Default <code>filter_</code> <code>Union[str, _Element]</code> <p>filter/rpc to execute</p> required <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def rpc(self, filter_: Union[str, _Element]) -&gt; NetconfResponse:\n\"\"\"\n    Netconf \"rpc\" operation\n\n    Typically used with juniper devices or if you want to build/send your own payload in a more\n    manual fashion. You can provide a string that will be loaded as an lxml element, or you can\n    provide an lxml element yourself.\n\n    Args:\n        filter_: filter/rpc to execute\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_rpc(filter_=filter_)\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.unlock","title":"<code>unlock(target: str) -&gt; NetconfResponse</code>","text":"<p>Netconf unlock operation</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>configuration source to target; running|startup|candidate</p> required <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def unlock(self, target: str) -&gt; NetconfResponse:\n\"\"\"\n    Netconf unlock operation\n\n    Args:\n        target: configuration source to target; running|startup|candidate\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_unlock(target=target)\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.validate","title":"<code>validate(source: str) -&gt; NetconfResponse</code>","text":"<p>Netconf \"validate\" operation</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>configuration source to validate; typically one of running|startup|candidate</p> required <p>Returns:</p> Name Type Description <code>NetconfResponse</code> <code>NetconfResponse</code> <p>scrapli_netconf NetconfResponse object</p> Source code in <code>driver/sync_driver.py</code> <pre><code>def validate(self, source: str) -&gt; NetconfResponse:\n\"\"\"\n    Netconf \"validate\" operation\n\n    Args:\n        source: configuration source to validate; typically one of running|startup|candidate\n\n    Returns:\n        NetconfResponse: scrapli_netconf NetconfResponse object\n\n    Raises:\n        N/A\n\n    \"\"\"\n    response = self._pre_validate(source=source)\n    raw_response = self.channel.send_input_netconf(response.channel_input)\n    response.record_response(raw_response)\n    return response\n</code></pre>"},{"location":"reference/transport/","title":"transport","text":"<p>scrapli_netconf.transport</p>"},{"location":"reference/transport/plugins/","title":"plugins","text":"<p>scrapli_netconf.transport.plugins</p>"},{"location":"reference/transport/plugins/asyncssh/","title":"asyncssh","text":"<p>scrapli_netconf.transport.plugins.asyncssh</p>"},{"location":"reference/transport/plugins/asyncssh/transport/","title":"transport","text":"<p>scrapli_netconf.transport.plugins.asyncssh.transport</p>"},{"location":"reference/transport/plugins/asyncssh/transport/#transport.plugins.asyncssh.transport.NetconfAsyncsshTransport","title":"<code>NetconfAsyncsshTransport</code>","text":"<p>         Bases: <code>AsyncsshTransport</code></p> Source code in <code>transport/plugins/asyncssh/transport.py</code> <pre><code>class NetconfAsyncsshTransport(AsyncsshTransport):\n    async def open_netconf(self) -&gt; None:\n\"\"\"\n        Netconf open method\n\n        Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliAuthenticationFailed: if auth fails\n            ScrapliConnectionNotOpened: if connection cant be opened (but is not an auth failure)\n\n        \"\"\"\n        if self.plugin_transport_args.auth_strict_key:\n            self.logger.debug(\n                f\"Attempting to validate {self._base_transport_args.host} public key is in known \"\n                f\"hosts\"\n            )\n            self._verify_key()\n\n        # we already fetched host/port/user from the user input and/or the ssh config file, so we\n        # want to use those explicitly. likewise we pass config file we already found. set known\n        # hosts and agent to None so we can not have an agent and deal w/ known hosts ourselves\n        common_args = {\n            \"host\": self._base_transport_args.host,\n            \"port\": self._base_transport_args.port,\n            \"username\": self.plugin_transport_args.auth_username,\n            \"known_hosts\": None,\n            \"agent_path\": None,\n            \"config\": self.plugin_transport_args.ssh_config_file,\n        }\n\n        try:\n            self.session: SSHClientConnection = await asyncio.wait_for(\n                connect(\n                    client_keys=self.plugin_transport_args.auth_private_key,\n                    password=self.plugin_transport_args.auth_password,\n                    preferred_auth=(\n                        \"publickey\",\n                        \"keyboard-interactive\",\n                        \"password\",\n                    ),\n                    **common_args,\n                ),\n                timeout=self._base_transport_args.timeout_socket,\n            )\n        except PermissionDenied as exc:\n            msg = \"all authentication methods failed\"\n            self.logger.critical(msg)\n            raise ScrapliAuthenticationFailed(msg) from exc\n        except asyncio.TimeoutError as exc:\n            msg = \"timed out opening connection to device\"\n            self.logger.critical(msg)\n            raise ScrapliAuthenticationFailed(msg) from exc\n\n        # it seems we must pass a terminal type to force a pty(?) which i think we want in like...\n        # every case?? https://invisible-island.net/ncurses/ncurses.faq.html#xterm_color\n        # set encoding to None so we get bytes for consistency w/ other scrapli transports\n        # request_pty seems to be safe to set to \"false\" but leaving it at auto which seems closer\n        # to the default behavior. With this omitted (as was previously) connecting to junos devices\n        # on port 830 worked w/ system transport but *not* asyncssh because the pty request failed\n        try:\n            self.stdin, self.stdout, _ = await self.session.open_session(\n                term_type=\"xterm\", encoding=None, subsystem=\"netconf\", request_pty=\"auto\"\n            )\n        except ChannelOpenError as exc:\n            msg = (\n                \"Failed to open Channel -- do you have the right port? Most often the netconf \"\n                \"port is 22 or 830!\"\n            )\n            self.logger.critical(msg)\n            raise ScrapliConnectionNotOpened(msg) from exc\n\n        if not self.session:\n            raise ScrapliConnectionNotOpened\n\n        if self.plugin_transport_args.auth_strict_key:\n            self.logger.debug(\n                f\"Attempting to validate {self._base_transport_args.host} public key is in known \"\n                f\"hosts and is valid\"\n            )\n            self._verify_key_value()\n</code></pre>"},{"location":"reference/transport/plugins/asyncssh/transport/#transport.plugins.asyncssh.transport.NetconfAsyncsshTransport.open_netconf","title":"<code>open_netconf() -&gt; None</code>  <code>async</code>","text":"<p>Netconf open method</p> <p>Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Type Description <code>ScrapliAuthenticationFailed</code> <p>if auth fails</p> <code>ScrapliConnectionNotOpened</code> <p>if connection cant be opened (but is not an auth failure)</p> Source code in <code>transport/plugins/asyncssh/transport.py</code> <pre><code>async def open_netconf(self) -&gt; None:\n\"\"\"\n    Netconf open method\n\n    Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        ScrapliAuthenticationFailed: if auth fails\n        ScrapliConnectionNotOpened: if connection cant be opened (but is not an auth failure)\n\n    \"\"\"\n    if self.plugin_transport_args.auth_strict_key:\n        self.logger.debug(\n            f\"Attempting to validate {self._base_transport_args.host} public key is in known \"\n            f\"hosts\"\n        )\n        self._verify_key()\n\n    # we already fetched host/port/user from the user input and/or the ssh config file, so we\n    # want to use those explicitly. likewise we pass config file we already found. set known\n    # hosts and agent to None so we can not have an agent and deal w/ known hosts ourselves\n    common_args = {\n        \"host\": self._base_transport_args.host,\n        \"port\": self._base_transport_args.port,\n        \"username\": self.plugin_transport_args.auth_username,\n        \"known_hosts\": None,\n        \"agent_path\": None,\n        \"config\": self.plugin_transport_args.ssh_config_file,\n    }\n\n    try:\n        self.session: SSHClientConnection = await asyncio.wait_for(\n            connect(\n                client_keys=self.plugin_transport_args.auth_private_key,\n                password=self.plugin_transport_args.auth_password,\n                preferred_auth=(\n                    \"publickey\",\n                    \"keyboard-interactive\",\n                    \"password\",\n                ),\n                **common_args,\n            ),\n            timeout=self._base_transport_args.timeout_socket,\n        )\n    except PermissionDenied as exc:\n        msg = \"all authentication methods failed\"\n        self.logger.critical(msg)\n        raise ScrapliAuthenticationFailed(msg) from exc\n    except asyncio.TimeoutError as exc:\n        msg = \"timed out opening connection to device\"\n        self.logger.critical(msg)\n        raise ScrapliAuthenticationFailed(msg) from exc\n\n    # it seems we must pass a terminal type to force a pty(?) which i think we want in like...\n    # every case?? https://invisible-island.net/ncurses/ncurses.faq.html#xterm_color\n    # set encoding to None so we get bytes for consistency w/ other scrapli transports\n    # request_pty seems to be safe to set to \"false\" but leaving it at auto which seems closer\n    # to the default behavior. With this omitted (as was previously) connecting to junos devices\n    # on port 830 worked w/ system transport but *not* asyncssh because the pty request failed\n    try:\n        self.stdin, self.stdout, _ = await self.session.open_session(\n            term_type=\"xterm\", encoding=None, subsystem=\"netconf\", request_pty=\"auto\"\n        )\n    except ChannelOpenError as exc:\n        msg = (\n            \"Failed to open Channel -- do you have the right port? Most often the netconf \"\n            \"port is 22 or 830!\"\n        )\n        self.logger.critical(msg)\n        raise ScrapliConnectionNotOpened(msg) from exc\n\n    if not self.session:\n        raise ScrapliConnectionNotOpened\n\n    if self.plugin_transport_args.auth_strict_key:\n        self.logger.debug(\n            f\"Attempting to validate {self._base_transport_args.host} public key is in known \"\n            f\"hosts and is valid\"\n        )\n        self._verify_key_value()\n</code></pre>"},{"location":"reference/transport/plugins/paramiko/","title":"paramiko","text":"<p>scrapli_netconf.transport.plugins.paramiko</p>"},{"location":"reference/transport/plugins/paramiko/transport/","title":"transport","text":"<p>scrapli_netconf.transport.plugins.paramiko.transport</p>"},{"location":"reference/transport/plugins/paramiko/transport/#transport.plugins.paramiko.transport.NetconfParamikoTransport","title":"<code>NetconfParamikoTransport</code>","text":"<p>         Bases: <code>ParamikoTransport</code></p> Source code in <code>transport/plugins/paramiko/transport.py</code> <pre><code>class NetconfParamikoTransport(ParamikoTransport):\n    def open_netconf(self) -&gt; None:\n\"\"\"\n        Netconf open method\n\n        Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        super().open()\n\n    def _open_channel(self) -&gt; None:\n\"\"\"\n        Overriding the base open_channel to invoke netconf subsystem\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliConnectionNotOpened: if session is unopened/None\n\n        \"\"\"\n        if not self.session:\n            raise ScrapliConnectionNotOpened\n\n        self.session_channel = self.session.open_session()\n        self._set_timeout(self._base_transport_args.timeout_transport)\n        self.session_channel.invoke_subsystem(\"netconf\")\n</code></pre>"},{"location":"reference/transport/plugins/paramiko/transport/#transport.plugins.paramiko.transport.NetconfParamikoTransport.open_netconf","title":"<code>open_netconf() -&gt; None</code>","text":"<p>Netconf open method</p> <p>Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>transport/plugins/paramiko/transport.py</code> <pre><code>def open_netconf(self) -&gt; None:\n\"\"\"\n    Netconf open method\n\n    Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    super().open()\n</code></pre>"},{"location":"reference/transport/plugins/ssh2/","title":"ssh2","text":"<p>scrapli_netconf.transport.plugins.ssh2</p>"},{"location":"reference/transport/plugins/ssh2/transport/","title":"transport","text":"<p>scrapli_netconf.transport.plugins.ssh2.transport</p>"},{"location":"reference/transport/plugins/ssh2/transport/#transport.plugins.ssh2.transport.NetconfSsh2Transport","title":"<code>NetconfSsh2Transport</code>","text":"<p>         Bases: <code>Ssh2Transport</code></p> Source code in <code>transport/plugins/ssh2/transport.py</code> <pre><code>class NetconfSsh2Transport(Ssh2Transport):\n    def open_netconf(self) -&gt; bytes:\n\"\"\"\n        Netconf open method\n\n        Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        super().open()\n\n        return b\"\"\n\n    def _open_channel(self) -&gt; None:\n\"\"\"\n        Overriding the base open_channel to invoke netconf subsystem\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            ScrapliConnectionNotOpened: if session is unopened/None\n\n        \"\"\"\n        if not self.session:\n            raise ScrapliConnectionNotOpened\n\n        self.session_channel = self.session.open_session()\n        self.session_channel.subsystem(\"netconf\")\n</code></pre>"},{"location":"reference/transport/plugins/ssh2/transport/#transport.plugins.ssh2.transport.NetconfSsh2Transport.open_netconf","title":"<code>open_netconf() -&gt; bytes</code>","text":"<p>Netconf open method</p> <p>Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity</p> <p>Returns:</p> Type Description <code>bytes</code> <p>None</p> Source code in <code>transport/plugins/ssh2/transport.py</code> <pre><code>def open_netconf(self) -&gt; bytes:\n\"\"\"\n    Netconf open method\n\n    Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    super().open()\n\n    return b\"\"\n</code></pre>"},{"location":"reference/transport/plugins/system/","title":"system","text":"<p>scrapli_netconf.transport.plugins.system</p>"},{"location":"reference/transport/plugins/system/transport/","title":"transport","text":"<p>scrapli_netconf.transport.plugins.system.transport</p>"},{"location":"reference/transport/plugins/system/transport/#transport.plugins.system.transport.NetconfSystemTransport","title":"<code>NetconfSystemTransport</code>","text":"<p>         Bases: <code>SystemTransport</code></p> Source code in <code>transport/plugins/system/transport.py</code> <pre><code>class NetconfSystemTransport(SystemTransport):\n    def __init__(\n        self, base_transport_args: BaseTransportArgs, plugin_transport_args: PluginTransportArgs\n    ):\n        self.write_chunk_size = 65535\n        super().__init__(\n            base_transport_args=base_transport_args, plugin_transport_args=plugin_transport_args\n        )\n\n    def _build_open_cmd(self) -&gt; None:\n        super()._build_open_cmd()\n\n        # JunOS devices do not allocate pty on port 830 on some (all?) platforms, users can cause\n        # system transport to *not* force the pty (forcing pty is *default behavior*) by setting the\n        # transport arg `netconf_force_pty` to `False`. This defaults to `True` (forcing a pty) as\n        # that has been the default behavior for a while and seems to work in almost all cases,\n        # additionally without this -- in pytest (only in pytest for some reason?) output seems to\n        # come from devices out of order causing all the echo check logic to break... with this pty\n        # being forced that seems to never occur. Worth digging into more at some point...\n        if self._base_transport_args.transport_options.get(\"netconf_force_pty\", True) is True:\n            self.open_cmd.append(\"-tt\")\n\n        self.open_cmd.extend([\"-s\", \"netconf\"])\n        self.logger.debug(f\"final open_cmd: {self.open_cmd}\")\n\n    def open_netconf(self) -&gt; None:\n\"\"\"\n        Netconf open method\n\n        Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity\n\n        Args:\n            N/A\n\n        Returns:\n            None\n\n        Raises:\n            N/A\n\n        \"\"\"\n        self.open()\n\n    def write(self, channel_input: bytes) -&gt; None:\n        if not self.session:\n            raise ScrapliConnectionNotOpened\n\n        if self.write_chunk_size &lt;= 0:\n            self.session.write(channel_input)\n        else:\n            bytes_to_send_len = len(channel_input)\n            bytes_to_send = BytesIO(channel_input)\n            bytes_sent = 0\n\n            while bytes_sent &lt; bytes_to_send_len:\n                self.session.write(bytes_to_send.read(self.write_chunk_size))\n                bytes_sent += self.write_chunk_size\n</code></pre>"},{"location":"reference/transport/plugins/system/transport/#transport.plugins.system.transport.NetconfSystemTransport.open_netconf","title":"<code>open_netconf() -&gt; None</code>","text":"<p>Netconf open method</p> <p>Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>transport/plugins/system/transport.py</code> <pre><code>def open_netconf(self) -&gt; None:\n\"\"\"\n    Netconf open method\n\n    Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity\n\n    Args:\n        N/A\n\n    Returns:\n        None\n\n    Raises:\n        N/A\n\n    \"\"\"\n    self.open()\n</code></pre>"},{"location":"user_guide/advanced_usage/","title":"Advanced Usage","text":""},{"location":"user_guide/advanced_usage/#capabilities","title":"Capabilities","text":"<p>Netconf capabilities are exchanged when the session is opened. scrapli_netconf stores the server's capabilities in  the aptly named <code>server_capabilities</code> attribute of the driver.</p> <pre><code>&gt;&gt;&gt; from scrapli_netconf.driver import NetconfDriver\n&gt;&gt;&gt; \n&gt;&gt;&gt; my_device = {\n...     \"host\": \"172.18.0.13\",\n...     \"auth_username\": \"vrnetlab\",\n...     \"auth_password\": \"VR-netlab9\",\n...     \"auth_strict_key\": False,\n...     \"port\": 830\n... }\n&gt;&gt;&gt; conn = NetconfDriver(**my_device)\n&gt;&gt;&gt; conn.open()\n&gt;&gt;&gt; conn.server_capabilities\n['urn:ietf:params:netconf:base:1.1', 'urn:ietf:params:netconf:capability:candidate:1.0']\n</code></pre> <p>Capabilities truncated for readability</p> <p>As for capabilities that scrapli_netconf sends to the server, that depends on the capabilities advertised from the  server! If netconf base 1.1 is in the advertised capabilities then scrapli_netconf will advertise netconf 1.1   capabilities, otherwise it will advertise 1.0 capabilities.</p>"},{"location":"user_guide/advanced_usage/#datastores","title":"Datastores","text":"<p>scrapli_netconf drives contain an option <code>strict_datastores</code> which defaults to <code>False</code>. If this option is set to  <code>True</code> scrapli will raise a <code>ValueError</code> when attempting to perform an operation against a datastore that has not   been advertised as a capability by the server. With this option left to the default value of <code>False</code>, scrapli_netconf will simply issue a user warning.</p>"},{"location":"user_guide/advanced_usage/#using-a-different-transport","title":"Using a Different Transport","text":"<p>Just like scrapli \"core\" -- scrapli-netconf supports using different libraries for \"transport\" -- or the actual SSH  communication piece. By default, and like scrapli \"core\", scrapli-netconf uses the \"system\" transport. This \"system  \" transport means that scrapli-netconf has no external dependencies (other than <code>lxml</code>!) as it just relies on what is   available on the machine running the scrapli script. If you wish to swap this out, scrapli-netconf also supports    the <code>paramiko</code>, <code>ssh2</code>, and <code>asyncssh</code> scrapli transport plugins.</p> <p>Like scrapli \"core\", transport selection can be made when instantiating the scrapli connection object by passing in  <code>paramiko</code>, <code>ssh2</code>, <code>asyncssh</code>\" to force scrapli to use the corresponding transport mechanism. If you are using the   <code>asyncssh</code> transport you must use the <code>AsyncNetconfScrape</code> driver!</p> <p>While it will be a goal to ensure that these other transport mechanisms are supported and useful, the focus of  scrapli development will be on the \"system\" SSH transport.</p> <p>Example using <code>ssh2</code> as the transport:</p> <pre><code>from scrapli_netconf import NetconfDriver\n\nmy_device = {\n    \"host\": \"172.18.0.11\",\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_strict_key\": False,\n    \"transport\": \"ssh2\"\n}\n\nwith NetconfDriver(**my_device) as conn:\n    print(conn.get_config())\n</code></pre>"},{"location":"user_guide/advanced_usage/#a-note-about-filters","title":"A Note about Filters","text":"<p>The <code>filter_</code> string value for the <code>get</code> and <code>get_config</code> methods may contain multiple xml elements at its \"root\"  (for subtree filters) -- when cast to an lxml etree object this would normally result in the first filter being the  only element in the resulting object. This is because <code>etree.fromstring</code> assumes (rather correctly) that this is the  root of the document, and it ignores the remaining filter elements. In example, given the following string data:</p> <pre><code>&lt;interface-configurations xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-ifmgr-cfg\"&gt;\n    &lt;interface-configuration&gt;\n        &lt;active&gt;act&lt;/active&gt;\n    &lt;/interface-configuration&gt;\n&lt;/interface-configurations&gt;\n&lt;netconf-yang xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-man-netconf-cfg\"&gt;\n&lt;/netconf-yang&gt;\n</code></pre> <p>The resulting lxml object (when re-dumped back to string) would look like this:</p> <pre><code>&lt;interface-configurations xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-ifmgr-cfg\"&gt;\n    &lt;interface-configuration&gt;\n        &lt;active&gt;act&lt;/active&gt;\n    &lt;/interface-configuration&gt;\n&lt;/interface-configurations&gt;\n</code></pre> <p>This is.... shall we say not ideal if we want to pass in a string like the previous section to filter for multiple  things in our config. To cope with this scrapli_netconf will wrap the user provided string filter in a \"tmp\" tag,  which allows us to load up the filter with all element(s) intact; we then simply ditch the outer temp tag when  placing the filter element(s) into the final filter payload, allowing users to simply provide a big string  containing as many or few filters as they want.</p> <p>If you preferred to craft your payloads more... \"correctly\" shall we say, then you are welcome to do so, and  provide the valid lxml object to the <code>rpc</code> method. The <code>rpc</code> method does nothing but wrap the provided element in  the outer-most xml tags needed for a NETCONF payload, so your provided element would need to contain the  get/filter/edit/etc. tags as appropriate!</p>"},{"location":"user_guide/basic_usage/","title":"Basic Usage","text":""},{"location":"user_guide/basic_usage/#picking-the-right-driver","title":"Picking the right Driver","text":"<p>Because netconf is a standard we don't need to deal with \"platform\" type drivers for scrapli_netconf! Instead, there  are only two options -- <code>NetconfDriver</code> or <code>AsyncNetconfDriver</code>, these can be imported from <code>scrapli_netconf.driver</code> like so:</p> <pre><code>from scrapli_netconf.driver import NetconfDriver\nfrom scrapli_netconf.driver import AsyncNetconfDriver\n</code></pre> <p>Note: if you are using async you must set the transport to <code>asyncssh</code> -- this is the only async transport supported  at this time!</p>"},{"location":"user_guide/basic_usage/#basic-driver-arguments","title":"Basic Driver Arguments","text":"<p>The drivers of course need some information about the device you are trying to connect to. The most common arguments  to provide to the driver are outlined below:</p> Argument Purpose/Value host name/ip of host to connect to port port of host to connect to (defaults to port 830) auth_username username for authentication auth_password password for authentication auth_secondary password for secondary authentication (enable password) auth_private_key private key for authentication auth_strict_key strict key checking -- TRUE by default! ssh_config_file True/False or path to ssh config file to use strip_namespaces True/False strip namespaces from returned XML (default False) <p>These arguments may be passed as keyword arguments to the driver of your choice, or, commonly are passed via  dictionary unpacking as show below:</p> <pre><code>from scrapli_netconf.driver import NetconfDriver\n\nmy_device = {\n    \"host\": \"172.18.0.11\",\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_strict_key\": False,\n}\n\nconn = NetconfDriver(**my_device)\nconn.open()\n</code></pre> <p>NOTE that scrapli enables strict host key checking by default!</p>"},{"location":"user_guide/basic_usage/#opening-and-closing-a-connection","title":"Opening and Closing a Connection","text":"<p>scrapli_netconf does not open the connection for you when creating your scrapli connection object in normal operations , you must manually call the <code>open</code> method prior to sending any commands to the device as shown below.</p> <p>```python from scrapli_netconf.driver import NetconfDriver</p> <p>my_device = {     \"host\": \"172.18.0.11\",     \"auth_username\": \"vrnetlab\",     \"auth_password\": \"VR-netlab9\",     \"auth_strict_key\": False, }</p> <p>conn = NetconfDriver(**my_device) conn.open() response = conn.get_config(source=\"running\") <pre><code>Connections can be closed by calling the `close` method:\n\n```python\nconn.close()\n</code></pre></p>"},{"location":"user_guide/basic_usage/#get-config","title":"Get Config","text":"<p>Configurations can be retrieved from datastores on a netconf device using the <code>get-config</code> netconf method. The  <code>get_config</code> method accepts a <code>source</code> argument which must refer to an available datastore on the device -- options   for this would be one of:</p> <ul> <li>running</li> <li>startup</li> <li>candidate</li> </ul> <pre><code>from scrapli_netconf.driver import NetconfDriver\n\nmy_device = {\n    \"host\": \"172.18.0.13\",\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_strict_key\": False,\n    \"port\": 830\n}\n\nconn = NetconfDriver(**my_device)\nconn.open()\nresponse = conn.get_config(source=\"running\")\nprint(response.result)\n</code></pre>"},{"location":"user_guide/basic_usage/#get","title":"Get","text":"<p>Much like <code>get-config</code>, the <code>get</code> method can be used to get data from the device, generally \"operational\" or \"show \" type data. The <code>get</code> method requires a \"filter\" to be applied in order to identify the data to get -- this filter  can be one of two types -- \"subtree\" (default) or \"xpath\". In the context of network devices it seems that not many   devices support \"xpath\" filters (only IOSXE with netconf 1.1 of the tested platforms supports xpath for example).</p> <pre><code>from scrapli_netconf.driver import NetconfDriver\n\nmy_device = {\n    \"host\": \"172.18.0.13\",\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_strict_key\": False,\n    \"port\": 830\n}\n\nfilter_ = \"\"\"\n&lt;components xmlns=\"http://openconfig.net/yang/platform\"&gt;\n    &lt;component&gt;\n        &lt;state&gt;\n        &lt;/state&gt;\n    &lt;/component&gt;\n&lt;/components&gt;\"\"\"\n\nconn = NetconfDriver(**my_device)\nconn.open()\nresponse = conn.get(filter_=filter_, filter_type=\"subtree\")\nprint(response.result)\n</code></pre>"},{"location":"user_guide/basic_usage/#lock-and-unlock","title":"Lock and Unlock","text":"<p>Netconf provides the ability to lock a configuration datastore. Much like <code>get-config</code> a target datastore must be  provided, and is dependent on the capabilities of the platform you are interacting with.</p> <pre><code>from scrapli_netconf.driver import NetconfDriver\n\nmy_device = {\n    \"host\": \"172.18.0.13\",\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_strict_key\": False,\n    \"port\": 830\n}\n\nconn = NetconfDriver(**my_device)\nconn.open()\nresponse = conn.lock(target=\"candidate\")\nprint(response.result)\nresponse = conn.unlock(target=\"candidate\")\nprint(response.result)\n</code></pre>"},{"location":"user_guide/basic_usage/#commit-and-discard","title":"Commit and Discard","text":"<p>If your platform supports commit operations (IOS-XR and Junos in the context of scrapli_netconf tested platforms ), any changes created using the <code>edit-config</code> method will need to be committed (or discarded).</p> <pre><code>from scrapli_netconf.driver import NetconfDriver\n\nmy_device = {\n    \"host\": \"172.18.0.13\",\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_strict_key\": False,\n    \"port\": 830\n}\n\nconn = NetconfDriver(**my_device)\nconn.open()\nresponse = conn.commit()\nprint(response.result)\nresponse = conn.discard()\nprint(response.result)\n</code></pre>"},{"location":"user_guide/basic_usage/#edit-config","title":"Edit Config","text":"<p>To edit configs, simply use the <code>edit_config</code> method with an appropriate config payload and target.</p> <pre><code>from scrapli_netconf.driver import NetconfDriver\n\nmy_device = {\n    \"host\": \"172.18.0.13\",\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_strict_key\": False,\n    \"port\": 830\n}\n\ncdp_config = \"\"\"\n&lt;config&gt;\n    &lt;cdp xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-cdp-cfg\"&gt;\n        &lt;timer&gt;80&lt;/timer&gt;\n        &lt;enable&gt;true&lt;/enable&gt;\n        &lt;log-adjacency&gt;&lt;/log-adjacency&gt;\n        &lt;hold-time&gt;200&lt;/hold-time&gt;\n        &lt;advertise-v1-only&gt;&lt;/advertise-v1-only&gt;\n    &lt;/cdp&gt;\n&lt;/config&gt;\n\"\"\"\n\nconn = NetconfDriver(**my_device)\nconn.open()\nresult = conn.edit_config(config=cdp_config, target=\"candidate\")\nprint(result.result)\n</code></pre>"},{"location":"user_guide/basic_usage/#delete-config","title":"Delete Config","text":"<p>Some devices may allow you to delete a candidate/startup configuration. You can do so with the <code>delete_config</code> method ; note that this is only currently tested on Junos as the test environment IOSXR version does not support this method . Per the RFC, \"running\" is never a valid target; <code>scrapli_netconf</code> will produce a warning indicating this if  \"running\" is set as the target; if <code>strict_datastores</code> is set to <code>True</code> an exception will be raised.</p> <pre><code>from scrapli_netconf.driver import NetconfDriver\n\nmy_device = {\n    \"host\": \"172.18.0.13\",\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_strict_key\": False,\n    \"port\": 830\n}\n\nconn = NetconfDriver(**my_device)\nconn.open()\nresult = conn.delete_config(target=\"candidate\")\nprint(result.result)\n</code></pre>"},{"location":"user_guide/basic_usage/#rpc","title":"RPC","text":"<p>The <code>rpc</code> method is a \"bare-bones\" rpc call which does not apply any formatting/standardization beyond the outer most  rpc tag. Generally this is used for Juniper devices and the \"bare rpc\" type calls supported on junos devices not   supporting/using models (YANG/IETF/etc.), but can of course be used to send any kind of custom crafted rpc you'd like!</p> <pre><code>from scrapli_netconf.driver import NetconfDriver\n\nmy_device = {\n    \"host\": \"172.18.0.15\",\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_strict_key\": False,\n    \"port\": 22\n}\n\ncommit_filter = \"\"\"\n&lt;get-commit-revision-information&gt;\n    &lt;level&gt;detail&lt;/level&gt;\n&lt;/get-commit-revision-information&gt;\n\"\"\"\n\nconn = NetconfDriver(**my_device)\nconn.open()\nresult = conn.rpc(filter_=commit_filter)\nprint(result.result)\n</code></pre>"},{"location":"user_guide/faq/","title":"FAQ","text":"<ul> <li>Question: Why build this? ncclient exists?<ul> <li>Answer: After building scrapli it was apparent that it could be fairly easily extended to handle netconf    connections, at the time dayjob$ had lots of netconf-y things with ncclient happening. I'm not a big fan of ncclient as I find it rather obtuse/hard to understand whats going on, and the dependency on paramiko is not  super great. I figured I could support enough netconf things with system transport so... I did. Then it was   fairly trivial to add asyncssh to support netconf with asyncio!</li> </ul> </li> <li>Question: Is this better than ncclient?<ul> <li>Answer: Nope! Supporting asyncio may be a killer use case for some, but otherwise ncclient and scrapli_netconf    accomplish much of the same things -- probably with ncclient having a wider/deeper range of netconf rfc support    . Net/net though is they are just different! Use whichever you prefer! </li> </ul> </li> <li>Question: Is this easy to use?<ul> <li>Answer: Biased, but I think so! A big part of the goal of all of this was to have a consistent feel across ssh    and netconf both with sync and async support, and (again, biased) I think that has been achieved.</li> </ul> </li> <li>Other questions? Ask away!</li> </ul>"},{"location":"user_guide/installation/","title":"Installation","text":""},{"location":"user_guide/installation/#standard-installation","title":"Standard Installation","text":"<p>As outlined in the quick start, you should be able to pip install scrapli_netconf \"normally\":</p> <pre><code>pip install scrapli_netconf\n</code></pre>"},{"location":"user_guide/installation/#installing-current-master-branch","title":"Installing current master branch","text":"<p>To install from the source repositories master branch:</p> <pre><code>pip install git+https://github.com/scrapli/scrapli_netconf\n</code></pre>"},{"location":"user_guide/installation/#installing-current-develop-branch","title":"Installing current develop branch","text":"<p>To install from this repositories develop branch:</p> <pre><code>pip install -e git+https://github.com/scrapli/scrapli_netconf.git@develop#egg=scrapli_netconf\n</code></pre>"},{"location":"user_guide/installation/#installation-from-source","title":"Installation from Source","text":"<p>To install from source:</p> <pre><code>git clone https://github.com/scrapli/scrapli_netconf\ncd scrapli_netconf\npython setup.py install\n</code></pre>"},{"location":"user_guide/installation/#optional-extras","title":"Optional Extras","text":"<p>Just like scrapli \"core\" scrapli_netconf tries to have as few dependencies as possible. scrapli_netconf requires  scrapli (of course!) and <code>lxml</code>. If you would like to use any of the transport plugins that are not part of the  standard library you can install those as optional extras via pip:</p> <pre><code>pip install scrapli_netconf[paramiko]\n</code></pre> <p>The available optional installation extras options are:</p> <ul> <li>paramiko</li> <li>ssh2</li> <li>asyncssh</li> </ul>"},{"location":"user_guide/installation/#supported-platforms","title":"Supported Platforms","text":"<p>As for platforms to run scrapli on -- it has and will be tested on MacOS and Ubuntu regularly and should work on  any POSIX system. Windows at one point was being tested very minimally via GitHub Actions builds, however this is no  longer the case as it is just not worth the effort. While scrapli/scrapli_netconf should work on Windows when  using the paramiko or ssh2-python transport drivers, it is not \"officially\" supported. It is strongly  recommended/preferred for folks to use WSL/Cygwin instead of Windows.</p>"},{"location":"user_guide/project_details/","title":"Project Details","text":""},{"location":"user_guide/project_details/#what-is-scrapli_netconf","title":"What is scrapli_netconf","text":"<p>scrapli_netconf is a library to help send or receive netconf messages to devices, specifically routers (though could  be anything speaking netconf in theory). </p> <p>Netconf is an IETF network management protocol that uses XML for message encoding, and SSH (or TLS, which is not  supported by scrapli_netconf) for transport of messages. scrapli_netconf is simply an extension of the scrapli   \"screen scraping\" library that adds proper message creation, framing, and validation to allow for scrapli to be    used as a netconf client.</p> <p>scrapli_netconf adds new drivers (<code>NetconfScrape</code> and <code>AsyncNetconfScrape</code>), new transports (<code>NetconfTransport</code> and <code>AsyncNetconfTransport</code>), and new channels (<code>NetconfChannel</code> and <code>AsyncNetconfChannel</code>) all of which inherit from , and build on, the core scrapli components. scrapli_netconf also includes an extension of the <code>Response</code> object  -- aptly named <code>NetconfResponse</code> that adds netconf-specific data to the existing object.</p> <p>A great question to ask right now is: \"why\"! The primary driver is to get <code>ncclient</code> like functionality without  needing <code>paramiko</code> for the transport so that we can take full advantage of \"normal\" OpenSSH options, as well as have   fewer dependencies (only absolute required dependency is lxml!). Additionally, as scrapli_netconf is just an    extension of scrapli, this means that automation of devices over telnet, SSH, and netconf (over SSH) can be done     all with an extremely consistent look and feel. Realistically this should cover most modes of present day network      automation other than HTTP based APIs (which would likely have a pretty different look and feel anyway). Finally      , but still quite important -- with the <code>asyncssh</code> transport plugin, scrapli_netconf provides asyncio support       for netconf operations.</p>"},{"location":"user_guide/project_details/#supported-platforms","title":"Supported Platforms","text":"<p>At this time scrapli_netconf is a base implementation of netconf 1.0 and netconf 1.1 (note that scrapli is not 100 % RFC compliant in that it currently does not support all methods/options). It should work on anything that runs  those versions of netconf, but has only been tested against the following platforms/versions:</p> <ul> <li>Cisco IOS-XE (tested on: 16.12.03) with Netconf 1.0 and 1.1</li> <li>Cisco IOS-XR (tested on: 6.5.3) with Netconf 1.1</li> <li>Juniper JunOS (tested on: 17.3R2.10) with Netconf 1.0</li> </ul> <p>In addition to the above devices, there has been testing on various versions of Juniper SRX, QFX, and MX platforms on  ~18ish+ code, as well as Cisco NCS devices on 6.6.2+ code, and finally there has been limited testing on Nokia devices.</p>"},{"location":"user_guide/quickstart/","title":"Quick Start Guide","text":""},{"location":"user_guide/quickstart/#installation","title":"Installation","text":"<p>In most cases installation via pip is the simplest and best way to install scrapli_netconf. See here for advanced installation details.</p> <pre><code>pip install scrapli-netconf\n</code></pre>"},{"location":"user_guide/quickstart/#a-simple-example","title":"A Simple Example","text":"<pre><code>from scrapli_netconf.driver import NetconfDriver\n\nmy_device = {\n    \"host\": \"172.18.0.13\",\n    \"auth_username\": \"vrnetlab\",\n    \"auth_password\": \"VR-netlab9\",\n    \"auth_strict_key\": False,\n    \"port\": 830\n}\n\nconn = NetconfDriver(**my_device)\nconn.open()\nresponse = conn.get_config(source=\"running\")\nprint(response.result)\n</code></pre> <pre><code>$ python my_scrapli_script.py\n&lt;rpc-reply message-id=\"101\"&gt;\n &lt;data&gt;\n  &lt;ssh&gt;\n   &lt;server&gt;\n    &lt;v2/&gt;\n    &lt;netconf&gt;830&lt;/netconf&gt;\n    &lt;netconf-vrf-table&gt;\n     &lt;vrf&gt;\n      &lt;vrf-name&gt;default&lt;/vrf-name&gt;\n      &lt;enable/&gt;\n     &lt;/vrf&gt;\n    &lt;/netconf-vrf-table&gt;\n   &lt;/server&gt;\n  &lt;/ssh&gt;\n  &lt;interface-configurations&gt;\n   &lt;interface-configuration&gt;\n    &lt;active&gt;act&lt;/active&gt;\n    &lt;interface-name&gt;MgmtEth0/RP0/CPU0/0&lt;/interface-name&gt;\n&lt;SNIP&gt;\n &lt;/data&gt;\n&lt;/rpc-reply&gt;\n</code></pre>"},{"location":"user_guide/quickstart/#more-examples","title":"More Examples","text":"<ul> <li>Basic Operations IOS-XR</li> <li>Basic Operations Junos</li> <li>Edit Config IOS-XR</li> <li>Asyncio Edit Config IOS-XR</li> </ul>"},{"location":"user_guide/versioning/","title":"Versioning","text":"<p>Just like scrapli, scrapli_netconf uses the CalVer versioning standard. All release versions  follow the format <code>YYYY.MM.DD</code>, however PyPi will shorten/standardize this to remove leading zeros.</p> <p>The reason for choosing CalVer is simply to make it very clear how old a given release of scrapli is. While there are  clearly some potential challenges around indicating when a \"breaking\" change occurs due to there not being the   concept of a \"major\" version, this is hopefully not too big a deal for scrapli, and thus far the \"core\" API has    been very stable -- there are only so many things you can/need to do over SSH after all!</p> <p>Please also note that the CHANGELOG contains notes about each version (and is updated in develop branch  while updates are happening).</p> <p>A final note regarding versioning: scrapli updates are released as often as necessary/there are things to update . This means you should ALWAYS PIN YOUR REQUIREMENTS when using scrapli!! As stated, the \"core\" API has been very  stable, but things will change over time -- always pin your requirements, and keep an eye on the changelog/api docs   -- you can \"watch\" this repository to ensure you are notified of any releases.</p>"}]}