{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"scrapli_netconf \u00b6 scrapli_netconf is a netconf driver built on top of scrapli . The purpose of scrapli_netconf is to provide a fast, flexible, thoroughly tested, well typed, well documented, simple API that supports both synchronous and asynchronous usage. Working together scrapli and scrapli_netconf aim to provide a consistent (as is practical) look and feel when automating devices over telnet, SSH, or netconf (over SSH). scrapli_netconf aims to be fully RFC compliant at some point, but at the moment does not implement all netconf features/methods.","title":"Scrapli Netconf"},{"location":"#scrapli_netconf","text":"scrapli_netconf is a netconf driver built on top of scrapli . The purpose of scrapli_netconf is to provide a fast, flexible, thoroughly tested, well typed, well documented, simple API that supports both synchronous and asynchronous usage. Working together scrapli and scrapli_netconf aim to provide a consistent (as is practical) look and feel when automating devices over telnet, SSH, or netconf (over SSH). scrapli_netconf aims to be fully RFC compliant at some point, but at the moment does not implement all netconf features/methods.","title":"scrapli_netconf"},{"location":"changelog/","text":"CHANGELOG \u00b6 2022.01.30 \u00b6 Removed deprecated filters argument Removed deprecated NetconfScrape and AsyncNetconfScrape Improved raise_for_status exception messages, see #92 and #90 Dropped Python3.6 support as it is now EOL! Of course, scrapli probably still works just fine with 3.6 (if you install the old 3.6 requirements), but we won't test/support it anymore. 2021.07.30 \u00b6 Force system transport ssh connections to allocate a tty (-tt); fixes issue that would prevent system transport from sending any command > 1024 chars. Added use_compressed_parser argument to the driver constructor -- defaults to True which means we \"squish\" all the whitespace out of any input we get from the user before sending it to the netconf server, generally this is no problem, but some devices (looking at you NX-OS!) lock up and stop reading at some character counts (4096 in NX-OS it seems) causing the connection to timeout and die. By not \"squishing\" whitespace out this does not happen. Fixed some typing issues and pinned to scrapli pre-release to take advantage of updated typing/packaging setup Deprecate filters argument on get_config -- will be supported (by decorator) until 2022.01.30 (and pre-releases). This was done to make the arguments consistent for get , get_config , and rpc . Better handling of multiple filter elements in a filter string Smarter message building -- previously most of the final bytes payload that we send to the servers got built in the base driver class, and then some more (1.1 encoding) got added in the channel base class -- silly! Fixed this, so it is all done in the driver which eliminated a bunch of duplication (yay!). Deprecating comms_ansi -- see also scrapli changelog for this release (2021.07.30) for more details. This was never used here in scrapli_netconf so should be a non issue, but will not be fully deprecated until 2022.01.30. Re-fix #10 ... see #68 -- now there is a test with a comment so I don't break this again :) Added copy_config method, thanks to Roman Dodin for adding this in scrapligo first! Added handling/warning about use_compressed_parser if we catch a timeout exception when looking for prompt after writing inputs -- since I don't know (can't know?) which platforms may require this flag set to False this seems like a reasonable way to let users know and point them in the right direction to get things working! Reswizzled the echo check to be like the scrapligo version -- much simpler/less moving parts, so should be good! 2021.01.30 \u00b6 Big overhaul in line with the scrapli core overhaul... mostly this was about reconciliation of the channel and transport things and putting stuff where it should have been in the first place... see the changelog at scrapli core for much more details FUTURE BREAKING CHANGE -- NetconfScrape and AsyncNetconfScrape have been renamed to NetconfDriver and AsyncNetconfDriver -- there are alias classes so you can continue to use NetconfScrape and AsyncNetconfScrape but there is a warning, and these will be removed at some point in the future! 2021.01.17 \u00b6 Support for future \"vrouter\" setup for testing Flatten all channel inputs (no pretty printed xml) -- seems to behave much more nicely across the board! Updated test to match some recent scrapli core updates (multipl easync transports) 2020.11.15 \u00b6 Support namespaces in hello messages -- primarily to support \"rfc-compliant\" mode in JunOS -- thank you Gary Napier for finding this and coming up with the fix! Another fixup to chunk checker -- think that the itty bitty chunk issues have now been solved :) 2020.10.24 \u00b6 Improve the \"echo\" checker -- and add this for sync as well, because... SSH2 and Paramiko are now supported transports! As part of the \"improved echo checker\" sync channel now also overrides the read_until_input method like the async channel does -- again, for the same reasons. All transports minus system are now optional extras -- this means that asyncssh is no longer an install requirement As expected with above point -- added optional extras install options in setup.py as well as a \"full\" option just like scrapli core MAYBE BREAKING CHANGE: shouldn't be an issue for 99.9999% of people, however, the asyncssh transport is no longer imported and available in the transport package Add error_messages attribute to response object -- initialized as an empty list and the text of any rpc-error/error -message fields are placed into this list if there are any in the response from the server Improve netconf 1.1 chunk matching regex to not ignore/chop off Nokia error messages that contained # symbols 2020.10.10 \u00b6 Handle netconf 1.1 devices that have chunk sizes of 1 Ensure results are \"pretty printed\" Above two items were worked out with thanks to Hugo Tinoco! PS - this has been tested on Nokia devices now too! Hopefully improved asyncssh \"echo checker\" (see _check_echo) method in async_channel for details Update CI to use 3.9 instead of 3.9-dev (and update deprecated set-env) Remove transport session locks 2020.09.23 \u00b6 Strip server capabilities so we don't save capabilities with newlines/whitespace Add validate and delete_config methods 2020.09.18 \u00b6 Fix some pins for dev requirements Add 3.9-dev to actions Fix scrapli-asycnssh not in setup.py install_requires Retest everything! In general, just get this updated/ready for nornir-scrapli ! 2020.07.26 \u00b6 Update to match scrapli core -- moved to updated timeout decorator, fixed a test to match a better exception message 2020.07.12 \u00b6 Minor improvements to response recording (should be a tick faster) Update decorators for async things to use the improved async_operation_timeout in scrapli 2020.07.12 Set strip_namespaces to False for AsyncNetconfScrape for consistency/sanity Update a few dev pins, update required pins to ensure no major lxml updates break things 2020.07.04 \u00b6 First real release??? :) 2020.04.19 \u00b6 Initial pypi release... very beta still","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"CHANGELOG"},{"location":"changelog/#20220130","text":"Removed deprecated filters argument Removed deprecated NetconfScrape and AsyncNetconfScrape Improved raise_for_status exception messages, see #92 and #90 Dropped Python3.6 support as it is now EOL! Of course, scrapli probably still works just fine with 3.6 (if you install the old 3.6 requirements), but we won't test/support it anymore.","title":"2022.01.30"},{"location":"changelog/#20210730","text":"Force system transport ssh connections to allocate a tty (-tt); fixes issue that would prevent system transport from sending any command > 1024 chars. Added use_compressed_parser argument to the driver constructor -- defaults to True which means we \"squish\" all the whitespace out of any input we get from the user before sending it to the netconf server, generally this is no problem, but some devices (looking at you NX-OS!) lock up and stop reading at some character counts (4096 in NX-OS it seems) causing the connection to timeout and die. By not \"squishing\" whitespace out this does not happen. Fixed some typing issues and pinned to scrapli pre-release to take advantage of updated typing/packaging setup Deprecate filters argument on get_config -- will be supported (by decorator) until 2022.01.30 (and pre-releases). This was done to make the arguments consistent for get , get_config , and rpc . Better handling of multiple filter elements in a filter string Smarter message building -- previously most of the final bytes payload that we send to the servers got built in the base driver class, and then some more (1.1 encoding) got added in the channel base class -- silly! Fixed this, so it is all done in the driver which eliminated a bunch of duplication (yay!). Deprecating comms_ansi -- see also scrapli changelog for this release (2021.07.30) for more details. This was never used here in scrapli_netconf so should be a non issue, but will not be fully deprecated until 2022.01.30. Re-fix #10 ... see #68 -- now there is a test with a comment so I don't break this again :) Added copy_config method, thanks to Roman Dodin for adding this in scrapligo first! Added handling/warning about use_compressed_parser if we catch a timeout exception when looking for prompt after writing inputs -- since I don't know (can't know?) which platforms may require this flag set to False this seems like a reasonable way to let users know and point them in the right direction to get things working! Reswizzled the echo check to be like the scrapligo version -- much simpler/less moving parts, so should be good!","title":"2021.07.30"},{"location":"changelog/#20210130","text":"Big overhaul in line with the scrapli core overhaul... mostly this was about reconciliation of the channel and transport things and putting stuff where it should have been in the first place... see the changelog at scrapli core for much more details FUTURE BREAKING CHANGE -- NetconfScrape and AsyncNetconfScrape have been renamed to NetconfDriver and AsyncNetconfDriver -- there are alias classes so you can continue to use NetconfScrape and AsyncNetconfScrape but there is a warning, and these will be removed at some point in the future!","title":"2021.01.30"},{"location":"changelog/#20210117","text":"Support for future \"vrouter\" setup for testing Flatten all channel inputs (no pretty printed xml) -- seems to behave much more nicely across the board! Updated test to match some recent scrapli core updates (multipl easync transports)","title":"2021.01.17"},{"location":"changelog/#20201115","text":"Support namespaces in hello messages -- primarily to support \"rfc-compliant\" mode in JunOS -- thank you Gary Napier for finding this and coming up with the fix! Another fixup to chunk checker -- think that the itty bitty chunk issues have now been solved :)","title":"2020.11.15"},{"location":"changelog/#20201024","text":"Improve the \"echo\" checker -- and add this for sync as well, because... SSH2 and Paramiko are now supported transports! As part of the \"improved echo checker\" sync channel now also overrides the read_until_input method like the async channel does -- again, for the same reasons. All transports minus system are now optional extras -- this means that asyncssh is no longer an install requirement As expected with above point -- added optional extras install options in setup.py as well as a \"full\" option just like scrapli core MAYBE BREAKING CHANGE: shouldn't be an issue for 99.9999% of people, however, the asyncssh transport is no longer imported and available in the transport package Add error_messages attribute to response object -- initialized as an empty list and the text of any rpc-error/error -message fields are placed into this list if there are any in the response from the server Improve netconf 1.1 chunk matching regex to not ignore/chop off Nokia error messages that contained # symbols","title":"2020.10.24"},{"location":"changelog/#20201010","text":"Handle netconf 1.1 devices that have chunk sizes of 1 Ensure results are \"pretty printed\" Above two items were worked out with thanks to Hugo Tinoco! PS - this has been tested on Nokia devices now too! Hopefully improved asyncssh \"echo checker\" (see _check_echo) method in async_channel for details Update CI to use 3.9 instead of 3.9-dev (and update deprecated set-env) Remove transport session locks","title":"2020.10.10"},{"location":"changelog/#20200923","text":"Strip server capabilities so we don't save capabilities with newlines/whitespace Add validate and delete_config methods","title":"2020.09.23"},{"location":"changelog/#20200918","text":"Fix some pins for dev requirements Add 3.9-dev to actions Fix scrapli-asycnssh not in setup.py install_requires Retest everything! In general, just get this updated/ready for nornir-scrapli !","title":"2020.09.18"},{"location":"changelog/#20200726","text":"Update to match scrapli core -- moved to updated timeout decorator, fixed a test to match a better exception message","title":"2020.07.26"},{"location":"changelog/#20200712","text":"Minor improvements to response recording (should be a tick faster) Update decorators for async things to use the improved async_operation_timeout in scrapli 2020.07.12 Set strip_namespaces to False for AsyncNetconfScrape for consistency/sanity Update a few dev pins, update required pins to ensure no major lxml updates break things","title":"2020.07.12"},{"location":"changelog/#20200704","text":"First real release??? :)","title":"2020.07.04"},{"location":"changelog/#20200419","text":"Initial pypi release... very beta still","title":"2020.04.19"},{"location":"about/code_of_conduct/","text":"Code of Conduct \u00b6 Be excellent to each other!","title":"Code of Conduct"},{"location":"about/code_of_conduct/#code-of-conduct","text":"Be excellent to each other!","title":"Code of Conduct"},{"location":"about/contributing/","text":"Contributing \u00b6 Thanks for thinking about contributing! Contributions are not expected, but are quite welcome. Contributions of all kinds are welcomed -- typos, doc updates, adding examples, bug fixes, and feature adds. Some notes on contributing: Please open a GitHub discussion topic for any potential feature adds/changes to discuss them prior to opening a PR, this way everyone has a chance to chime in and make sure we're all on the same page! Please open an issue to discuss any bugs/bug fixes prior to opening a PR. Once we all have discussed any adds/changes, pull requests are very much welcome and appreciated! All PRs should pass tests/CI linting -- checkout the Makefile for some shortcuts for linting and testing. Please include tests! Even simple/basic tests are better than nothing -- it helps make sure changes in the future don't break functionality or make things act in unexpected ways!","title":"Contributing"},{"location":"about/contributing/#contributing","text":"Thanks for thinking about contributing! Contributions are not expected, but are quite welcome. Contributions of all kinds are welcomed -- typos, doc updates, adding examples, bug fixes, and feature adds. Some notes on contributing: Please open a GitHub discussion topic for any potential feature adds/changes to discuss them prior to opening a PR, this way everyone has a chance to chime in and make sure we're all on the same page! Please open an issue to discuss any bugs/bug fixes prior to opening a PR. Once we all have discussed any adds/changes, pull requests are very much welcome and appreciated! All PRs should pass tests/CI linting -- checkout the Makefile for some shortcuts for linting and testing. Please include tests! Even simple/basic tests are better than nothing -- it helps make sure changes in the future don't break functionality or make things act in unexpected ways!","title":"Contributing"},{"location":"more_scrapli/nornir_scrapli/","text":"Nornir scrapli \u00b6 If you want to use scrapli, but don't want to deal with handling concurrency yourself, there is great news! The nornir_scrapli plugin allows you to use scrapli (and scrapli netconf and scrapli cfg) within the Nornir framework!","title":"Nornir Scrapli"},{"location":"more_scrapli/nornir_scrapli/#nornir-scrapli","text":"If you want to use scrapli, but don't want to deal with handling concurrency yourself, there is great news! The nornir_scrapli plugin allows you to use scrapli (and scrapli netconf and scrapli cfg) within the Nornir framework!","title":"Nornir scrapli"},{"location":"more_scrapli/scrapli/","text":"Scrapli \u00b6 scrapli ( docs ) is the \"parent\" scrapli library. Check it out if you need to connect to devices with telnet or ssh!","title":"Scrapli"},{"location":"more_scrapli/scrapli/#scrapli","text":"scrapli ( docs ) is the \"parent\" scrapli library. Check it out if you need to connect to devices with telnet or ssh!","title":"Scrapli"},{"location":"more_scrapli/scrapli_cfg/","text":"Scrapli Cfg \u00b6 scrapli_cfg ( docs ) is utility that accepts a scrapli Telnet or SSH connection and provides configuration management capabilities. scrapli_cfg allows you to load candidate configurations for merge or replace operations, generate diffs of the current vs candidate, and of course commit or abort the candidate configuration.","title":"Scrapli Cfg"},{"location":"more_scrapli/scrapli_cfg/#scrapli-cfg","text":"scrapli_cfg ( docs ) is utility that accepts a scrapli Telnet or SSH connection and provides configuration management capabilities. scrapli_cfg allows you to load candidate configurations for merge or replace operations, generate diffs of the current vs candidate, and of course commit or abort the candidate configuration.","title":"Scrapli Cfg"},{"location":"more_scrapli/scrapli_community/","text":"Scrapli Community \u00b6 If you would like to use scrapli, but the platform(s) that you work with are not supported in the \"core\" scrapli platforms, you should check out scrapli_community ! This is the place for users to share \"non-core\" scrapli platforms.","title":"Scrapli Community"},{"location":"more_scrapli/scrapli_community/#scrapli-community","text":"If you would like to use scrapli, but the platform(s) that you work with are not supported in the \"core\" scrapli platforms, you should check out scrapli_community ! This is the place for users to share \"non-core\" scrapli platforms.","title":"Scrapli Community"},{"location":"more_scrapli/scrapli_replay/","text":"Scrapli Replay \u00b6 scrapli_replay ( docs ) is a set of tools used to help test scrapli programs. scrapli_replay includes a utility to capture command input/output from real life servers and replay them in a semi-interactive fashion, as well as a pytest plugin that patches and records and replays session data (like vcr.py ) for scrapli connections.","title":"Scrapli Replay"},{"location":"more_scrapli/scrapli_replay/#scrapli-replay","text":"scrapli_replay ( docs ) is a set of tools used to help test scrapli programs. scrapli_replay includes a utility to capture command input/output from real life servers and replay them in a semi-interactive fashion, as well as a pytest plugin that patches and records and replays session data (like vcr.py ) for scrapli connections.","title":"Scrapli Replay"},{"location":"reference/SUMMARY/","text":"channel async_channel base_channel sync_channel constants driver async_driver base_driver sync_driver exceptions helper response transport plugins asyncssh transport paramiko transport ssh2 transport system transport","title":"SUMMARY"},{"location":"reference/constants/","text":"scrapli_netconf.constants","title":"constants"},{"location":"reference/exceptions/","text":"scrapli_netconf.exceptions CapabilityNotSupported \u00b6 Bases: ScrapliException Exception for unsupported capabilities Source code in scrapli_netconf/exceptions.py 9 10 class CapabilityNotSupported ( ScrapliException ): \"\"\"Exception for unsupported capabilities\"\"\" CouldNotExchangeCapabilities \u00b6 Bases: ScrapliException Exception for failure of capabilities exchange Source code in scrapli_netconf/exceptions.py 5 6 class CouldNotExchangeCapabilities ( ScrapliException ): \"\"\"Exception for failure of capabilities exchange\"\"\"","title":"exceptions"},{"location":"reference/exceptions/#exceptions.CapabilityNotSupported","text":"Bases: ScrapliException Exception for unsupported capabilities Source code in scrapli_netconf/exceptions.py 9 10 class CapabilityNotSupported ( ScrapliException ): \"\"\"Exception for unsupported capabilities\"\"\"","title":"CapabilityNotSupported"},{"location":"reference/exceptions/#exceptions.CouldNotExchangeCapabilities","text":"Bases: ScrapliException Exception for failure of capabilities exchange Source code in scrapli_netconf/exceptions.py 5 6 class CouldNotExchangeCapabilities ( ScrapliException ): \"\"\"Exception for failure of capabilities exchange\"\"\"","title":"CouldNotExchangeCapabilities"},{"location":"reference/helper/","text":"scrapli_netconf.helper remove_namespaces ( tree : Element ) -> Element \u00b6 Remove all namespace tags from Element object Replace element tags like: {http://cisco.com/ns/yang/Cisco-IOS-XR-ipv4-bgp-oper}connection-state With: connection-state Parameters: Name Type Description Default tree Element lxml Element required Returns: Name Type Description Element Element lxml Element with namespaces stripped out Source code in scrapli_netconf/helper.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def remove_namespaces ( tree : Element ) -> Element : \"\"\" Remove all namespace tags from Element object Replace element tags like: {http://cisco.com/ns/yang/Cisco-IOS-XR-ipv4-bgp-oper}connection-state With: connection-state Args: tree: lxml Element Returns: Element: lxml Element with namespaces stripped out Raises: N/A \"\"\" for el in tree . getiterator (): if not hasattr ( el . tag , \"find\" ): continue el . tag = re . sub ( r \"^{.*}\" , \"\" , el . tag ) objectify . deannotate ( tree , cleanup_namespaces = True ) return tree","title":"helper"},{"location":"reference/helper/#helper.remove_namespaces","text":"Remove all namespace tags from Element object Replace element tags like: {http://cisco.com/ns/yang/Cisco-IOS-XR-ipv4-bgp-oper}connection-state With: connection-state Parameters: Name Type Description Default tree Element lxml Element required Returns: Name Type Description Element Element lxml Element with namespaces stripped out Source code in scrapli_netconf/helper.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def remove_namespaces ( tree : Element ) -> Element : \"\"\" Remove all namespace tags from Element object Replace element tags like: {http://cisco.com/ns/yang/Cisco-IOS-XR-ipv4-bgp-oper}connection-state With: connection-state Args: tree: lxml Element Returns: Element: lxml Element with namespaces stripped out Raises: N/A \"\"\" for el in tree . getiterator (): if not hasattr ( el . tag , \"find\" ): continue el . tag = re . sub ( r \"^{.*}\" , \"\" , el . tag ) objectify . deannotate ( tree , cleanup_namespaces = True ) return tree","title":"remove_namespaces()"},{"location":"reference/response/","text":"scrapli_netconf.response NetconfResponse \u00b6 Bases: Response Source code in scrapli_netconf/response.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 class NetconfResponse ( Response ): # intentionally overriding base class' list of strings for failed when contains failed_when_contains : List [ bytes ] # type: ignore[assignment] def __init__ ( self , netconf_version : NetconfVersion , xml_input : Element , strip_namespaces : bool = True , failed_when_contains : Optional [ Union [ bytes , List [ bytes ]]] = None , ** kwargs : Any , ): \"\"\" Scrapli Netconf NetconfResponse Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Args: netconf_version: string of netconf version; `1.0`|`1.1` xml_input: lxml Element of input to be sent to device strip_namespaces: strip out all namespaces if True, otherwise ignore them failed_when_contains: list of bytes that, if present in final output, represent a failed command/interaction -- should generally be left alone for netconf. Note that this differs from the base scrapli Response object as we want to be parsing/checking for these strings in raw byte strings we get back from the device kwargs: kwargs for instantiation of scrapli Response object supertype Returns: N/A # noqa: DAR202 Raises: ValueError: if invalid netconf_version string \"\"\" if netconf_version not in ( NetconfVersion . VERSION_1_0 , NetconfVersion . VERSION_1_1 ): raise ValueError ( f \"`netconf_version` should be one of 1.0|1.1, got ` { netconf_version } `\" ) self . netconf_version = netconf_version self . xml_input = xml_input self . strip_namespaces = strip_namespaces self . xml_result : Element super () . __init__ ( ** kwargs ) if failed_when_contains is None : # match on both opening and closing tags too so we never have to think about/compare # things with namespaces (the closing tags wont have namespaces) failed_when_contains = [ b \"</rpc-error>\" , b \"</rpc-errors>\" , b \"<rpc-error>\" , b \"<rpc-errors>\" , ] if isinstance ( failed_when_contains , bytes ): failed_when_contains = [ failed_when_contains ] self . failed_when_contains = failed_when_contains self . error_messages : List [ str ] = [] def record_response ( self , result : bytes ) -> None : \"\"\" Record channel_input results and elapsed time of channel input/reading output Args: result: bytes result of channel_input Returns: N/A Raises: N/A \"\"\" self . finish_time = datetime . now () self . elapsed_time = ( self . finish_time - self . start_time ) . total_seconds () self . raw_result = result if not self . failed_when_contains : self . failed = False elif not any ( err in self . raw_result for err in self . failed_when_contains ): self . failed = False if self . netconf_version == NetconfVersion . VERSION_1_0 : self . _record_response_netconf_1_0 () else : self . _record_response_netconf_1_1 () if self . failed : self . _fetch_error_messages () def _record_response_netconf_1_0 ( self ) -> None : \"\"\" Record response for netconf version 1.0 Args: N/A Returns: N/A # noqa: DAR202 Raises: N/A \"\"\" # remove the message end characters and xml document header see: # https://github.com/scrapli/scrapli_netconf/issues/1 self . xml_result = etree . fromstring ( self . raw_result . replace ( b \"]]>]]>\" , b \"\" ) . replace ( b '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' , b \"\" ), parser = PARSER , ) if self . strip_namespaces : self . xml_result = remove_namespaces ( self . xml_result ) self . result = etree . tostring ( self . xml_result , pretty_print = True ) . decode () else : self . result = etree . tostring ( self . xml_result , pretty_print = True ) . decode () def _validate_chunk_size_netconf_1_1 ( self , result : Tuple [ int , bytes ]) -> None : \"\"\" Validate individual chunk size; handle parsing trailing new lines for chunk sizes It seems that some platforms behave slightly differently than others (looking at you IOSXE) in the way they count chunk sizes with respect to trailing whitespace. Per my reading of the RFC, the response for a netconf 1.1 response should look like this: ``` ##XYZ <somexml> ## ``` Where \"XYZ\" is an integer number of the count of chars in the following chunk (the chars up to the next \"##\" symbols), then the actual XML response, then a new line(!!!!) and a pair of hash symbols to indicate the chunk is complete. IOSXE seems to *not* want to see the newline between the XML payload and the double hash symbols... instead when it sees that newline it immediately returns the response. This breaks the core behavior of scrapli in that scrapli always writes the input, then reads the written inputs off the channel *before* sending a return character. This ensures that we never have to deal with stripping out the inputs and such because it has already been read. With IOSXE Behaving this way, we have to instead use `send_input` with the `eager` flag set -- this means that we do *not* read the inputs, we simply send a return. We then have to do a little extra parsing to strip out the inputs, but thats no big deal... Where this finally gets to \"spacing\" -- IOSXE seems to include trailing newlines *sometimes* but not other times, whereas IOSXR (for example) *always* counts a single trailing newline (after the XML). SO.... long story long... (the above chunk stuff doesn't necessarily matter for this, but felt like as good a place to document it as any...) this method deals w/ newline counts -- we check the expected chunk length against the actual char count, the char count with all trailing whitespace stripped, and the count of the chunk + a *single* trailing newline character... FIN Args: result: Tuple from re.findall parsing the full response object Returns: N/A Raises: N/A \"\"\" expected_len , result_value = result actual_len = len ( result_value ) rstripped_len = len ( result_value . rstrip ()) trailing_newline_count = actual_len - rstripped_len if trailing_newline_count > 1 : extraneous_trailing_newline_count = trailing_newline_count - 1 else : extraneous_trailing_newline_count = 1 trimmed_newline_len = actual_len - extraneous_trailing_newline_count if rstripped_len == 0 : # at least nokia tends to have itty bitty chunks of one element, and/or chunks that have # *only* whitespace and our regex ignores this, so if there was/is nothing in the result # section we can assume it was just whitespace and move on w/our lives actual_len = expected_len if expected_len == actual_len : return if expected_len == rstripped_len : return if expected_len == trimmed_newline_len : return LOG . critical ( f \"Return element length invalid, expected { expected_len } got { actual_len } for \" f \"element: { repr ( result_value ) } \" ) self . failed = True def _record_response_netconf_1_1 ( self ) -> None : \"\"\" Record response for netconf version 1.1 Args: N/A Returns: N/A Raises: N/A \"\"\" chunk_sizes = re . finditer ( pattern = CHUNK_MATCH_1_1 , string = self . raw_result ) result_sections : List [ Tuple [ int , bytes ]] = [] for chunk_match in chunk_sizes : chunk_size = int ( chunk_match . groupdict () . get ( \"size\" , 0 )) chunk_end_pos = chunk_match . span ()[ 1 ] result_sections . append ( ( chunk_size , self . raw_result [ chunk_end_pos : chunk_end_pos + chunk_size ]) # noqa ) # validate all received data for result in result_sections : self . _validate_chunk_size_netconf_1_1 ( result = result ) self . xml_result = etree . fromstring ( b \" \\n \" . join ( [ # remove the message end characters and xml document header see: # https://github.com/scrapli/scrapli_netconf/issues/1 result [ 1 ] . replace ( b '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' , b \"\" ) for result in result_sections ] ), parser = PARSER , ) if self . strip_namespaces : self . xml_result = remove_namespaces ( self . xml_result ) self . result = etree . tostring ( self . xml_result , pretty_print = True ) . decode () else : self . result = etree . tostring ( self . xml_result , pretty_print = True ) . decode () def _fetch_error_messages ( self ) -> None : \"\"\" Fetch all error messages (if any) RFC states that there MAY be more than one rpc-error so we just xpath for all \"error-message\" tags and pull out the text of those elements. The strip is just to remove leading/trailing white space to make things look a bit nicer. Args: N/A Returns: N/A Raises: N/A \"\"\" err_messages = self . xml_result . xpath ( \"//rpc-error/error-message\" ) self . error_messages = [ err . text . strip () for err in err_messages ] def get_xml_elements ( self ) -> Dict [ str , Element ]: \"\"\" Parse each section under \"data\" into a dict of {tag: Element} for easy viewing/parsing Args: N/A Returns: xml_elements: dictionary of tag: Element Raises: N/A \"\"\" xml_elements = {} data_element = self . xml_result . find ( \"data\" , namespaces = self . xml_result . nsmap ) # juniper doesn't return data in a \"data\" element for bare rpc calls, guard against that # breaking the iterchildren() if data_element is not None : for child in data_element . iterchildren (): _tag = etree . QName ( child . tag ) . localname xml_elements [ _tag ] = child return xml_elements def textfsm_parse_output ( self , template : Union [ str , TextIO , None ] = None , to_dict : bool = True ) -> Union [ Dict [ str , Any ], List [ Any ]]: \"\"\" Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Args: template: string path to textfsm template or opened textfsm template file to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: structured_result: empty list or parsed data from textfsm Raises: NotImplementedError: always! \"\"\" raise NotImplementedError ( \"No textfsm parsing for netconf output!\" ) def genie_parse_output ( self ) -> Union [ Dict [ str , Any ], List [ Any ]]: \"\"\" Override scrapli Response `genie_parse_output` method; not applicable for netconf Args: N/A Returns: N/A Raises: NotImplementedError: always \"\"\" raise NotImplementedError ( \"No genie parsing for netconf output!\" ) def raise_for_status ( self ) -> None : \"\"\" Raise a `ScrapliCommandFailure` if any elements are failed Overrides scrapli core Response.raise_for_status to include rpc error message(s). Args: N/A Returns: None Raises: ScrapliCommandFailure: if any elements are failed \"\"\" if self . failed : raise ScrapliCommandFailure ( f \"operation failed, reported rpc errors: { self . error_messages } \" ) __init__ ( netconf_version : NetconfVersion , xml_input : Element , strip_namespaces : bool = True , failed_when_contains : Optional [ Union [ bytes , List [ bytes ]]] = None , ** kwargs : Any ) \u00b6 Scrapli Netconf NetconfResponse Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Parameters: Name Type Description Default netconf_version NetconfVersion string of netconf version; 1.0 | 1.1 required xml_input Element lxml Element of input to be sent to device required strip_namespaces bool strip out all namespaces if True, otherwise ignore them True failed_when_contains Optional [ Union [ bytes , List [ bytes ]]] list of bytes that, if present in final output, represent a failed command/interaction -- should generally be left alone for netconf. Note that this differs from the base scrapli Response object as we want to be parsing/checking for these strings in raw byte strings we get back from the device None kwargs kwargs for instantiation of scrapli Response object supertype required Returns: Type Description N/A # noqa: DAR202 Raises: Type Description ValueError if invalid netconf_version string Source code in scrapli_netconf/response.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def __init__ ( self , netconf_version : NetconfVersion , xml_input : Element , strip_namespaces : bool = True , failed_when_contains : Optional [ Union [ bytes , List [ bytes ]]] = None , ** kwargs : Any , ): \"\"\" Scrapli Netconf NetconfResponse Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Args: netconf_version: string of netconf version; `1.0`|`1.1` xml_input: lxml Element of input to be sent to device strip_namespaces: strip out all namespaces if True, otherwise ignore them failed_when_contains: list of bytes that, if present in final output, represent a failed command/interaction -- should generally be left alone for netconf. Note that this differs from the base scrapli Response object as we want to be parsing/checking for these strings in raw byte strings we get back from the device kwargs: kwargs for instantiation of scrapli Response object supertype Returns: N/A # noqa: DAR202 Raises: ValueError: if invalid netconf_version string \"\"\" if netconf_version not in ( NetconfVersion . VERSION_1_0 , NetconfVersion . VERSION_1_1 ): raise ValueError ( f \"`netconf_version` should be one of 1.0|1.1, got ` { netconf_version } `\" ) self . netconf_version = netconf_version self . xml_input = xml_input self . strip_namespaces = strip_namespaces self . xml_result : Element super () . __init__ ( ** kwargs ) if failed_when_contains is None : # match on both opening and closing tags too so we never have to think about/compare # things with namespaces (the closing tags wont have namespaces) failed_when_contains = [ b \"</rpc-error>\" , b \"</rpc-errors>\" , b \"<rpc-error>\" , b \"<rpc-errors>\" , ] if isinstance ( failed_when_contains , bytes ): failed_when_contains = [ failed_when_contains ] self . failed_when_contains = failed_when_contains self . error_messages : List [ str ] = [] genie_parse_output () -> Union [ Dict [ str , Any ], List [ Any ]] \u00b6 Override scrapli Response genie_parse_output method; not applicable for netconf Returns: Type Description Union [ Dict [ str , Any ], List [ Any ]] N/A Raises: Type Description NotImplementedError always Source code in scrapli_netconf/response.py 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 def genie_parse_output ( self ) -> Union [ Dict [ str , Any ], List [ Any ]]: \"\"\" Override scrapli Response `genie_parse_output` method; not applicable for netconf Args: N/A Returns: N/A Raises: NotImplementedError: always \"\"\" raise NotImplementedError ( \"No genie parsing for netconf output!\" ) get_xml_elements () -> Dict [ str , Element ] \u00b6 Parse each section under \"data\" into a dict of {tag: Element} for easy viewing/parsing Returns: Name Type Description xml_elements Dict [ str , Element ] dictionary of tag: Element Source code in scrapli_netconf/response.py 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 def get_xml_elements ( self ) -> Dict [ str , Element ]: \"\"\" Parse each section under \"data\" into a dict of {tag: Element} for easy viewing/parsing Args: N/A Returns: xml_elements: dictionary of tag: Element Raises: N/A \"\"\" xml_elements = {} data_element = self . xml_result . find ( \"data\" , namespaces = self . xml_result . nsmap ) # juniper doesn't return data in a \"data\" element for bare rpc calls, guard against that # breaking the iterchildren() if data_element is not None : for child in data_element . iterchildren (): _tag = etree . QName ( child . tag ) . localname xml_elements [ _tag ] = child return xml_elements raise_for_status () -> None \u00b6 Raise a ScrapliCommandFailure if any elements are failed Overrides scrapli core Response.raise_for_status to include rpc error message(s). Returns: Type Description None None Raises: Type Description ScrapliCommandFailure if any elements are failed Source code in scrapli_netconf/response.py 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 def raise_for_status ( self ) -> None : \"\"\" Raise a `ScrapliCommandFailure` if any elements are failed Overrides scrapli core Response.raise_for_status to include rpc error message(s). Args: N/A Returns: None Raises: ScrapliCommandFailure: if any elements are failed \"\"\" if self . failed : raise ScrapliCommandFailure ( f \"operation failed, reported rpc errors: { self . error_messages } \" ) record_response ( result : bytes ) -> None \u00b6 Record channel_input results and elapsed time of channel input/reading output Parameters: Name Type Description Default result bytes bytes result of channel_input required Returns: Type Description None N/A Source code in scrapli_netconf/response.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 def record_response ( self , result : bytes ) -> None : \"\"\" Record channel_input results and elapsed time of channel input/reading output Args: result: bytes result of channel_input Returns: N/A Raises: N/A \"\"\" self . finish_time = datetime . now () self . elapsed_time = ( self . finish_time - self . start_time ) . total_seconds () self . raw_result = result if not self . failed_when_contains : self . failed = False elif not any ( err in self . raw_result for err in self . failed_when_contains ): self . failed = False if self . netconf_version == NetconfVersion . VERSION_1_0 : self . _record_response_netconf_1_0 () else : self . _record_response_netconf_1_1 () if self . failed : self . _fetch_error_messages () textfsm_parse_output ( template : Union [ str , TextIO , None ] = None , to_dict : bool = True ) -> Union [ Dict [ str , Any ], List [ Any ]] \u00b6 Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Parameters: Name Type Description Default template Union [ str , TextIO , None] string path to textfsm template or opened textfsm template file None to_dict bool convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output True Returns: Name Type Description structured_result Union [ Dict [ str , Any ], List [ Any ]] empty list or parsed data from textfsm Raises: Type Description NotImplementedError always! Source code in scrapli_netconf/response.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 def textfsm_parse_output ( self , template : Union [ str , TextIO , None ] = None , to_dict : bool = True ) -> Union [ Dict [ str , Any ], List [ Any ]]: \"\"\" Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Args: template: string path to textfsm template or opened textfsm template file to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: structured_result: empty list or parsed data from textfsm Raises: NotImplementedError: always! \"\"\" raise NotImplementedError ( \"No textfsm parsing for netconf output!\" )","title":"response"},{"location":"reference/response/#response.NetconfResponse","text":"Bases: Response Source code in scrapli_netconf/response.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 class NetconfResponse ( Response ): # intentionally overriding base class' list of strings for failed when contains failed_when_contains : List [ bytes ] # type: ignore[assignment] def __init__ ( self , netconf_version : NetconfVersion , xml_input : Element , strip_namespaces : bool = True , failed_when_contains : Optional [ Union [ bytes , List [ bytes ]]] = None , ** kwargs : Any , ): \"\"\" Scrapli Netconf NetconfResponse Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Args: netconf_version: string of netconf version; `1.0`|`1.1` xml_input: lxml Element of input to be sent to device strip_namespaces: strip out all namespaces if True, otherwise ignore them failed_when_contains: list of bytes that, if present in final output, represent a failed command/interaction -- should generally be left alone for netconf. Note that this differs from the base scrapli Response object as we want to be parsing/checking for these strings in raw byte strings we get back from the device kwargs: kwargs for instantiation of scrapli Response object supertype Returns: N/A # noqa: DAR202 Raises: ValueError: if invalid netconf_version string \"\"\" if netconf_version not in ( NetconfVersion . VERSION_1_0 , NetconfVersion . VERSION_1_1 ): raise ValueError ( f \"`netconf_version` should be one of 1.0|1.1, got ` { netconf_version } `\" ) self . netconf_version = netconf_version self . xml_input = xml_input self . strip_namespaces = strip_namespaces self . xml_result : Element super () . __init__ ( ** kwargs ) if failed_when_contains is None : # match on both opening and closing tags too so we never have to think about/compare # things with namespaces (the closing tags wont have namespaces) failed_when_contains = [ b \"</rpc-error>\" , b \"</rpc-errors>\" , b \"<rpc-error>\" , b \"<rpc-errors>\" , ] if isinstance ( failed_when_contains , bytes ): failed_when_contains = [ failed_when_contains ] self . failed_when_contains = failed_when_contains self . error_messages : List [ str ] = [] def record_response ( self , result : bytes ) -> None : \"\"\" Record channel_input results and elapsed time of channel input/reading output Args: result: bytes result of channel_input Returns: N/A Raises: N/A \"\"\" self . finish_time = datetime . now () self . elapsed_time = ( self . finish_time - self . start_time ) . total_seconds () self . raw_result = result if not self . failed_when_contains : self . failed = False elif not any ( err in self . raw_result for err in self . failed_when_contains ): self . failed = False if self . netconf_version == NetconfVersion . VERSION_1_0 : self . _record_response_netconf_1_0 () else : self . _record_response_netconf_1_1 () if self . failed : self . _fetch_error_messages () def _record_response_netconf_1_0 ( self ) -> None : \"\"\" Record response for netconf version 1.0 Args: N/A Returns: N/A # noqa: DAR202 Raises: N/A \"\"\" # remove the message end characters and xml document header see: # https://github.com/scrapli/scrapli_netconf/issues/1 self . xml_result = etree . fromstring ( self . raw_result . replace ( b \"]]>]]>\" , b \"\" ) . replace ( b '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' , b \"\" ), parser = PARSER , ) if self . strip_namespaces : self . xml_result = remove_namespaces ( self . xml_result ) self . result = etree . tostring ( self . xml_result , pretty_print = True ) . decode () else : self . result = etree . tostring ( self . xml_result , pretty_print = True ) . decode () def _validate_chunk_size_netconf_1_1 ( self , result : Tuple [ int , bytes ]) -> None : \"\"\" Validate individual chunk size; handle parsing trailing new lines for chunk sizes It seems that some platforms behave slightly differently than others (looking at you IOSXE) in the way they count chunk sizes with respect to trailing whitespace. Per my reading of the RFC, the response for a netconf 1.1 response should look like this: ``` ##XYZ <somexml> ## ``` Where \"XYZ\" is an integer number of the count of chars in the following chunk (the chars up to the next \"##\" symbols), then the actual XML response, then a new line(!!!!) and a pair of hash symbols to indicate the chunk is complete. IOSXE seems to *not* want to see the newline between the XML payload and the double hash symbols... instead when it sees that newline it immediately returns the response. This breaks the core behavior of scrapli in that scrapli always writes the input, then reads the written inputs off the channel *before* sending a return character. This ensures that we never have to deal with stripping out the inputs and such because it has already been read. With IOSXE Behaving this way, we have to instead use `send_input` with the `eager` flag set -- this means that we do *not* read the inputs, we simply send a return. We then have to do a little extra parsing to strip out the inputs, but thats no big deal... Where this finally gets to \"spacing\" -- IOSXE seems to include trailing newlines *sometimes* but not other times, whereas IOSXR (for example) *always* counts a single trailing newline (after the XML). SO.... long story long... (the above chunk stuff doesn't necessarily matter for this, but felt like as good a place to document it as any...) this method deals w/ newline counts -- we check the expected chunk length against the actual char count, the char count with all trailing whitespace stripped, and the count of the chunk + a *single* trailing newline character... FIN Args: result: Tuple from re.findall parsing the full response object Returns: N/A Raises: N/A \"\"\" expected_len , result_value = result actual_len = len ( result_value ) rstripped_len = len ( result_value . rstrip ()) trailing_newline_count = actual_len - rstripped_len if trailing_newline_count > 1 : extraneous_trailing_newline_count = trailing_newline_count - 1 else : extraneous_trailing_newline_count = 1 trimmed_newline_len = actual_len - extraneous_trailing_newline_count if rstripped_len == 0 : # at least nokia tends to have itty bitty chunks of one element, and/or chunks that have # *only* whitespace and our regex ignores this, so if there was/is nothing in the result # section we can assume it was just whitespace and move on w/our lives actual_len = expected_len if expected_len == actual_len : return if expected_len == rstripped_len : return if expected_len == trimmed_newline_len : return LOG . critical ( f \"Return element length invalid, expected { expected_len } got { actual_len } for \" f \"element: { repr ( result_value ) } \" ) self . failed = True def _record_response_netconf_1_1 ( self ) -> None : \"\"\" Record response for netconf version 1.1 Args: N/A Returns: N/A Raises: N/A \"\"\" chunk_sizes = re . finditer ( pattern = CHUNK_MATCH_1_1 , string = self . raw_result ) result_sections : List [ Tuple [ int , bytes ]] = [] for chunk_match in chunk_sizes : chunk_size = int ( chunk_match . groupdict () . get ( \"size\" , 0 )) chunk_end_pos = chunk_match . span ()[ 1 ] result_sections . append ( ( chunk_size , self . raw_result [ chunk_end_pos : chunk_end_pos + chunk_size ]) # noqa ) # validate all received data for result in result_sections : self . _validate_chunk_size_netconf_1_1 ( result = result ) self . xml_result = etree . fromstring ( b \" \\n \" . join ( [ # remove the message end characters and xml document header see: # https://github.com/scrapli/scrapli_netconf/issues/1 result [ 1 ] . replace ( b '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' , b \"\" ) for result in result_sections ] ), parser = PARSER , ) if self . strip_namespaces : self . xml_result = remove_namespaces ( self . xml_result ) self . result = etree . tostring ( self . xml_result , pretty_print = True ) . decode () else : self . result = etree . tostring ( self . xml_result , pretty_print = True ) . decode () def _fetch_error_messages ( self ) -> None : \"\"\" Fetch all error messages (if any) RFC states that there MAY be more than one rpc-error so we just xpath for all \"error-message\" tags and pull out the text of those elements. The strip is just to remove leading/trailing white space to make things look a bit nicer. Args: N/A Returns: N/A Raises: N/A \"\"\" err_messages = self . xml_result . xpath ( \"//rpc-error/error-message\" ) self . error_messages = [ err . text . strip () for err in err_messages ] def get_xml_elements ( self ) -> Dict [ str , Element ]: \"\"\" Parse each section under \"data\" into a dict of {tag: Element} for easy viewing/parsing Args: N/A Returns: xml_elements: dictionary of tag: Element Raises: N/A \"\"\" xml_elements = {} data_element = self . xml_result . find ( \"data\" , namespaces = self . xml_result . nsmap ) # juniper doesn't return data in a \"data\" element for bare rpc calls, guard against that # breaking the iterchildren() if data_element is not None : for child in data_element . iterchildren (): _tag = etree . QName ( child . tag ) . localname xml_elements [ _tag ] = child return xml_elements def textfsm_parse_output ( self , template : Union [ str , TextIO , None ] = None , to_dict : bool = True ) -> Union [ Dict [ str , Any ], List [ Any ]]: \"\"\" Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Args: template: string path to textfsm template or opened textfsm template file to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: structured_result: empty list or parsed data from textfsm Raises: NotImplementedError: always! \"\"\" raise NotImplementedError ( \"No textfsm parsing for netconf output!\" ) def genie_parse_output ( self ) -> Union [ Dict [ str , Any ], List [ Any ]]: \"\"\" Override scrapli Response `genie_parse_output` method; not applicable for netconf Args: N/A Returns: N/A Raises: NotImplementedError: always \"\"\" raise NotImplementedError ( \"No genie parsing for netconf output!\" ) def raise_for_status ( self ) -> None : \"\"\" Raise a `ScrapliCommandFailure` if any elements are failed Overrides scrapli core Response.raise_for_status to include rpc error message(s). Args: N/A Returns: None Raises: ScrapliCommandFailure: if any elements are failed \"\"\" if self . failed : raise ScrapliCommandFailure ( f \"operation failed, reported rpc errors: { self . error_messages } \" )","title":"NetconfResponse"},{"location":"reference/response/#response.NetconfResponse.__init__","text":"Scrapli Netconf NetconfResponse Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Parameters: Name Type Description Default netconf_version NetconfVersion string of netconf version; 1.0 | 1.1 required xml_input Element lxml Element of input to be sent to device required strip_namespaces bool strip out all namespaces if True, otherwise ignore them True failed_when_contains Optional [ Union [ bytes , List [ bytes ]]] list of bytes that, if present in final output, represent a failed command/interaction -- should generally be left alone for netconf. Note that this differs from the base scrapli Response object as we want to be parsing/checking for these strings in raw byte strings we get back from the device None kwargs kwargs for instantiation of scrapli Response object supertype required Returns: Type Description N/A # noqa: DAR202 Raises: Type Description ValueError if invalid netconf_version string Source code in scrapli_netconf/response.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def __init__ ( self , netconf_version : NetconfVersion , xml_input : Element , strip_namespaces : bool = True , failed_when_contains : Optional [ Union [ bytes , List [ bytes ]]] = None , ** kwargs : Any , ): \"\"\" Scrapli Netconf NetconfResponse Store channel_input, resulting output, and start/end/elapsed time information. Attempt to determine if command was successful or not and reflect that in a failed attribute. Args: netconf_version: string of netconf version; `1.0`|`1.1` xml_input: lxml Element of input to be sent to device strip_namespaces: strip out all namespaces if True, otherwise ignore them failed_when_contains: list of bytes that, if present in final output, represent a failed command/interaction -- should generally be left alone for netconf. Note that this differs from the base scrapli Response object as we want to be parsing/checking for these strings in raw byte strings we get back from the device kwargs: kwargs for instantiation of scrapli Response object supertype Returns: N/A # noqa: DAR202 Raises: ValueError: if invalid netconf_version string \"\"\" if netconf_version not in ( NetconfVersion . VERSION_1_0 , NetconfVersion . VERSION_1_1 ): raise ValueError ( f \"`netconf_version` should be one of 1.0|1.1, got ` { netconf_version } `\" ) self . netconf_version = netconf_version self . xml_input = xml_input self . strip_namespaces = strip_namespaces self . xml_result : Element super () . __init__ ( ** kwargs ) if failed_when_contains is None : # match on both opening and closing tags too so we never have to think about/compare # things with namespaces (the closing tags wont have namespaces) failed_when_contains = [ b \"</rpc-error>\" , b \"</rpc-errors>\" , b \"<rpc-error>\" , b \"<rpc-errors>\" , ] if isinstance ( failed_when_contains , bytes ): failed_when_contains = [ failed_when_contains ] self . failed_when_contains = failed_when_contains self . error_messages : List [ str ] = []","title":"__init__()"},{"location":"reference/response/#response.NetconfResponse.genie_parse_output","text":"Override scrapli Response genie_parse_output method; not applicable for netconf Returns: Type Description Union [ Dict [ str , Any ], List [ Any ]] N/A Raises: Type Description NotImplementedError always Source code in scrapli_netconf/response.py 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 def genie_parse_output ( self ) -> Union [ Dict [ str , Any ], List [ Any ]]: \"\"\" Override scrapli Response `genie_parse_output` method; not applicable for netconf Args: N/A Returns: N/A Raises: NotImplementedError: always \"\"\" raise NotImplementedError ( \"No genie parsing for netconf output!\" )","title":"genie_parse_output()"},{"location":"reference/response/#response.NetconfResponse.get_xml_elements","text":"Parse each section under \"data\" into a dict of {tag: Element} for easy viewing/parsing Returns: Name Type Description xml_elements Dict [ str , Element ] dictionary of tag: Element Source code in scrapli_netconf/response.py 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 def get_xml_elements ( self ) -> Dict [ str , Element ]: \"\"\" Parse each section under \"data\" into a dict of {tag: Element} for easy viewing/parsing Args: N/A Returns: xml_elements: dictionary of tag: Element Raises: N/A \"\"\" xml_elements = {} data_element = self . xml_result . find ( \"data\" , namespaces = self . xml_result . nsmap ) # juniper doesn't return data in a \"data\" element for bare rpc calls, guard against that # breaking the iterchildren() if data_element is not None : for child in data_element . iterchildren (): _tag = etree . QName ( child . tag ) . localname xml_elements [ _tag ] = child return xml_elements","title":"get_xml_elements()"},{"location":"reference/response/#response.NetconfResponse.raise_for_status","text":"Raise a ScrapliCommandFailure if any elements are failed Overrides scrapli core Response.raise_for_status to include rpc error message(s). Returns: Type Description None None Raises: Type Description ScrapliCommandFailure if any elements are failed Source code in scrapli_netconf/response.py 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 def raise_for_status ( self ) -> None : \"\"\" Raise a `ScrapliCommandFailure` if any elements are failed Overrides scrapli core Response.raise_for_status to include rpc error message(s). Args: N/A Returns: None Raises: ScrapliCommandFailure: if any elements are failed \"\"\" if self . failed : raise ScrapliCommandFailure ( f \"operation failed, reported rpc errors: { self . error_messages } \" )","title":"raise_for_status()"},{"location":"reference/response/#response.NetconfResponse.record_response","text":"Record channel_input results and elapsed time of channel input/reading output Parameters: Name Type Description Default result bytes bytes result of channel_input required Returns: Type Description None N/A Source code in scrapli_netconf/response.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 def record_response ( self , result : bytes ) -> None : \"\"\" Record channel_input results and elapsed time of channel input/reading output Args: result: bytes result of channel_input Returns: N/A Raises: N/A \"\"\" self . finish_time = datetime . now () self . elapsed_time = ( self . finish_time - self . start_time ) . total_seconds () self . raw_result = result if not self . failed_when_contains : self . failed = False elif not any ( err in self . raw_result for err in self . failed_when_contains ): self . failed = False if self . netconf_version == NetconfVersion . VERSION_1_0 : self . _record_response_netconf_1_0 () else : self . _record_response_netconf_1_1 () if self . failed : self . _fetch_error_messages ()","title":"record_response()"},{"location":"reference/response/#response.NetconfResponse.textfsm_parse_output","text":"Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Parameters: Name Type Description Default template Union [ str , TextIO , None] string path to textfsm template or opened textfsm template file None to_dict bool convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output True Returns: Name Type Description structured_result Union [ Dict [ str , Any ], List [ Any ]] empty list or parsed data from textfsm Raises: Type Description NotImplementedError always! Source code in scrapli_netconf/response.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 def textfsm_parse_output ( self , template : Union [ str , TextIO , None ] = None , to_dict : bool = True ) -> Union [ Dict [ str , Any ], List [ Any ]]: \"\"\" Parse results with textfsm, always return structured data Returns an empty list if parsing fails! Args: template: string path to textfsm template or opened textfsm template file to_dict: convert textfsm output from list of lists to list of dicts -- basically create dict from header and row data so it is easier to read/parse the output Returns: structured_result: empty list or parsed data from textfsm Raises: NotImplementedError: always! \"\"\" raise NotImplementedError ( \"No textfsm parsing for netconf output!\" )","title":"textfsm_parse_output()"},{"location":"reference/channel/","text":"scrapli_netconf.channel","title":"channel"},{"location":"reference/channel/async_channel/","text":"scrapli_netconf.channel.async_channel AsyncNetconfChannel \u00b6 Bases: AsyncChannel , BaseNetconfChannel Source code in channel/async_channel.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 class AsyncNetconfChannel ( AsyncChannel , BaseNetconfChannel ): def __init__ ( self , transport : AsyncTransport , base_channel_args : BaseChannelArgs , netconf_base_channel_args : NetconfBaseChannelArgs , ): super () . __init__ ( transport = transport , base_channel_args = base_channel_args ) self . _netconf_base_channel_args = netconf_base_channel_args # always use `]]>]]>` as the initial prompt to match self . _base_channel_args . comms_prompt_pattern = \"]]>]]>\" self . _server_echo = False self . _capabilities_buf = b \"\" async def open_netconf ( self ) -> None : \"\"\" Open the netconf channel Args: N/A Returns: None Raises: N/A \"\"\" # open in scrapli core is where we open channel log (if applicable), do that self . open () raw_server_capabilities = await self . _get_server_capabilities () self . _process_capabilities_exchange ( raw_server_capabilities = raw_server_capabilities ) await self . _send_client_capabilities () @timeout_wrapper async def _get_server_capabilities ( self ) -> bytes : \"\"\" Read until all server capabilities have been sent by server Args: N/A Returns: bytes: raw bytes containing server capabilities Raises: N/A \"\"\" capabilities_buf = self . _capabilities_buf # reset this to empty to avoid any confusion now that we are moving on self . _capabilities_buf = b \"\" async with self . _channel_lock (): while b \"]]>]]>\" not in capabilities_buf : capabilities_buf += await self . read () self . logger . debug ( f \"received raw server capabilities: { repr ( capabilities_buf ) } \" ) return capabilities_buf @timeout_wrapper async def _send_client_capabilities ( self , ) -> None : \"\"\" Send client capabilities to the netconf server Args: N/A Returns: None Raises: N/A \"\"\" async with self . _channel_lock (): _ = self . _pre_send_client_capabilities ( client_capabilities = self . _netconf_base_channel_args . client_capabilities ) self . send_return () async def _read_until_input ( self , channel_input : bytes ) -> bytes : \"\"\" Async read until all input has been entered. Args: channel_input: string to write to channel Returns: bytes: output read from channel Raises: N/A \"\"\" output = b \"\" if self . _server_echo is None or self . _server_echo is False : # if server_echo is `None` we dont know if the server echoes yet, so just return nothing # if its False we know it doesnt echo and we can return empty byte string anyway return output if not channel_input : self . logger . info ( f \"Read: { repr ( output ) } \" ) return output while True : output += await self . read () # if we have all the input *or* we see the closing rpc tag we know we are done here if channel_input in output or b \"rpc>\" in output : break self . logger . info ( f \"Read: { repr ( output ) } \" ) return output async def send_input_netconf ( self , channel_input : str ) -> bytes : \"\"\" Send inputs to netconf server Args: channel_input: string of the base xml message to send to netconf server Returns: bytes: bytes result of message sent to netconf server Raises: N/A \"\"\" bytes_final_channel_input = channel_input . encode () buf : bytes buf , _ = await super () . send_input ( channel_input = channel_input , strip_prompt = False , eager = True ) if bytes_final_channel_input in buf : buf = buf . split ( bytes_final_channel_input )[ 1 ] buf = await self . _read_until_prompt ( buf = buf ) if self . _server_echo is None : # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT # echo the input commands back to the client. In the case of \"normal\" scrapli netconf # with the system transport this happens anyway because we combine the stdin and stdout # fds into a single pty, however for other transports we have an actual stdin and # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems # to want to echo inputs back onto to the stdout for the channel. This is totally ok # and we can deal with it, we just need to *know* that it is happening, so while the # _server_echo attribute is still `None`, we can go ahead and see if the input we sent # is in the output we read off the channel. If it is *not* we know the server does *not* # echo and we can move on. If it *is* in the output, we know the server echoes, and we # also have one additional step in that we need to read \"until prompt\" again in order to # capture the reply to our rpc. # # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\") self . logger . debug ( \"server echo is unset, determining if server echoes inputs now\" ) if bytes_final_channel_input in buf : self . logger . debug ( \"server echoes inputs, setting _server_echo to 'true'\" ) self . _server_echo = True # since echo is True and we only read until our input (because our inputs always end # with a \"prompt\" that we read until) we need to once again read until prompt, this # read will read all the way up through the *reply* to the prompt at end of the # reply message buf = await self . _read_until_prompt ( buf = b \"\" ) else : self . logger . debug ( \"server does *not* echo inputs, setting _server_echo to 'false'\" ) self . _server_echo = False if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_1 : # netconf 1.1 with \"chunking\" style message format needs an extra return char here self . send_return () return buf open_netconf () -> None async \u00b6 Open the netconf channel Returns: Type Description None None Source code in channel/async_channel.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 async def open_netconf ( self ) -> None : \"\"\" Open the netconf channel Args: N/A Returns: None Raises: N/A \"\"\" # open in scrapli core is where we open channel log (if applicable), do that self . open () raw_server_capabilities = await self . _get_server_capabilities () self . _process_capabilities_exchange ( raw_server_capabilities = raw_server_capabilities ) await self . _send_client_capabilities () send_input_netconf ( channel_input : str ) -> bytes async \u00b6 Send inputs to netconf server Parameters: Name Type Description Default channel_input str string of the base xml message to send to netconf server required Returns: Name Type Description bytes bytes bytes result of message sent to netconf server Source code in channel/async_channel.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 async def send_input_netconf ( self , channel_input : str ) -> bytes : \"\"\" Send inputs to netconf server Args: channel_input: string of the base xml message to send to netconf server Returns: bytes: bytes result of message sent to netconf server Raises: N/A \"\"\" bytes_final_channel_input = channel_input . encode () buf : bytes buf , _ = await super () . send_input ( channel_input = channel_input , strip_prompt = False , eager = True ) if bytes_final_channel_input in buf : buf = buf . split ( bytes_final_channel_input )[ 1 ] buf = await self . _read_until_prompt ( buf = buf ) if self . _server_echo is None : # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT # echo the input commands back to the client. In the case of \"normal\" scrapli netconf # with the system transport this happens anyway because we combine the stdin and stdout # fds into a single pty, however for other transports we have an actual stdin and # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems # to want to echo inputs back onto to the stdout for the channel. This is totally ok # and we can deal with it, we just need to *know* that it is happening, so while the # _server_echo attribute is still `None`, we can go ahead and see if the input we sent # is in the output we read off the channel. If it is *not* we know the server does *not* # echo and we can move on. If it *is* in the output, we know the server echoes, and we # also have one additional step in that we need to read \"until prompt\" again in order to # capture the reply to our rpc. # # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\") self . logger . debug ( \"server echo is unset, determining if server echoes inputs now\" ) if bytes_final_channel_input in buf : self . logger . debug ( \"server echoes inputs, setting _server_echo to 'true'\" ) self . _server_echo = True # since echo is True and we only read until our input (because our inputs always end # with a \"prompt\" that we read until) we need to once again read until prompt, this # read will read all the way up through the *reply* to the prompt at end of the # reply message buf = await self . _read_until_prompt ( buf = b \"\" ) else : self . logger . debug ( \"server does *not* echo inputs, setting _server_echo to 'false'\" ) self . _server_echo = False if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_1 : # netconf 1.1 with \"chunking\" style message format needs an extra return char here self . send_return () return buf","title":"async_channel"},{"location":"reference/channel/async_channel/#channel.async_channel.AsyncNetconfChannel","text":"Bases: AsyncChannel , BaseNetconfChannel Source code in channel/async_channel.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 class AsyncNetconfChannel ( AsyncChannel , BaseNetconfChannel ): def __init__ ( self , transport : AsyncTransport , base_channel_args : BaseChannelArgs , netconf_base_channel_args : NetconfBaseChannelArgs , ): super () . __init__ ( transport = transport , base_channel_args = base_channel_args ) self . _netconf_base_channel_args = netconf_base_channel_args # always use `]]>]]>` as the initial prompt to match self . _base_channel_args . comms_prompt_pattern = \"]]>]]>\" self . _server_echo = False self . _capabilities_buf = b \"\" async def open_netconf ( self ) -> None : \"\"\" Open the netconf channel Args: N/A Returns: None Raises: N/A \"\"\" # open in scrapli core is where we open channel log (if applicable), do that self . open () raw_server_capabilities = await self . _get_server_capabilities () self . _process_capabilities_exchange ( raw_server_capabilities = raw_server_capabilities ) await self . _send_client_capabilities () @timeout_wrapper async def _get_server_capabilities ( self ) -> bytes : \"\"\" Read until all server capabilities have been sent by server Args: N/A Returns: bytes: raw bytes containing server capabilities Raises: N/A \"\"\" capabilities_buf = self . _capabilities_buf # reset this to empty to avoid any confusion now that we are moving on self . _capabilities_buf = b \"\" async with self . _channel_lock (): while b \"]]>]]>\" not in capabilities_buf : capabilities_buf += await self . read () self . logger . debug ( f \"received raw server capabilities: { repr ( capabilities_buf ) } \" ) return capabilities_buf @timeout_wrapper async def _send_client_capabilities ( self , ) -> None : \"\"\" Send client capabilities to the netconf server Args: N/A Returns: None Raises: N/A \"\"\" async with self . _channel_lock (): _ = self . _pre_send_client_capabilities ( client_capabilities = self . _netconf_base_channel_args . client_capabilities ) self . send_return () async def _read_until_input ( self , channel_input : bytes ) -> bytes : \"\"\" Async read until all input has been entered. Args: channel_input: string to write to channel Returns: bytes: output read from channel Raises: N/A \"\"\" output = b \"\" if self . _server_echo is None or self . _server_echo is False : # if server_echo is `None` we dont know if the server echoes yet, so just return nothing # if its False we know it doesnt echo and we can return empty byte string anyway return output if not channel_input : self . logger . info ( f \"Read: { repr ( output ) } \" ) return output while True : output += await self . read () # if we have all the input *or* we see the closing rpc tag we know we are done here if channel_input in output or b \"rpc>\" in output : break self . logger . info ( f \"Read: { repr ( output ) } \" ) return output async def send_input_netconf ( self , channel_input : str ) -> bytes : \"\"\" Send inputs to netconf server Args: channel_input: string of the base xml message to send to netconf server Returns: bytes: bytes result of message sent to netconf server Raises: N/A \"\"\" bytes_final_channel_input = channel_input . encode () buf : bytes buf , _ = await super () . send_input ( channel_input = channel_input , strip_prompt = False , eager = True ) if bytes_final_channel_input in buf : buf = buf . split ( bytes_final_channel_input )[ 1 ] buf = await self . _read_until_prompt ( buf = buf ) if self . _server_echo is None : # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT # echo the input commands back to the client. In the case of \"normal\" scrapli netconf # with the system transport this happens anyway because we combine the stdin and stdout # fds into a single pty, however for other transports we have an actual stdin and # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems # to want to echo inputs back onto to the stdout for the channel. This is totally ok # and we can deal with it, we just need to *know* that it is happening, so while the # _server_echo attribute is still `None`, we can go ahead and see if the input we sent # is in the output we read off the channel. If it is *not* we know the server does *not* # echo and we can move on. If it *is* in the output, we know the server echoes, and we # also have one additional step in that we need to read \"until prompt\" again in order to # capture the reply to our rpc. # # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\") self . logger . debug ( \"server echo is unset, determining if server echoes inputs now\" ) if bytes_final_channel_input in buf : self . logger . debug ( \"server echoes inputs, setting _server_echo to 'true'\" ) self . _server_echo = True # since echo is True and we only read until our input (because our inputs always end # with a \"prompt\" that we read until) we need to once again read until prompt, this # read will read all the way up through the *reply* to the prompt at end of the # reply message buf = await self . _read_until_prompt ( buf = b \"\" ) else : self . logger . debug ( \"server does *not* echo inputs, setting _server_echo to 'false'\" ) self . _server_echo = False if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_1 : # netconf 1.1 with \"chunking\" style message format needs an extra return char here self . send_return () return buf","title":"AsyncNetconfChannel"},{"location":"reference/channel/async_channel/#channel.async_channel.AsyncNetconfChannel.open_netconf","text":"Open the netconf channel Returns: Type Description None None Source code in channel/async_channel.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 async def open_netconf ( self ) -> None : \"\"\" Open the netconf channel Args: N/A Returns: None Raises: N/A \"\"\" # open in scrapli core is where we open channel log (if applicable), do that self . open () raw_server_capabilities = await self . _get_server_capabilities () self . _process_capabilities_exchange ( raw_server_capabilities = raw_server_capabilities ) await self . _send_client_capabilities ()","title":"open_netconf()"},{"location":"reference/channel/async_channel/#channel.async_channel.AsyncNetconfChannel.send_input_netconf","text":"Send inputs to netconf server Parameters: Name Type Description Default channel_input str string of the base xml message to send to netconf server required Returns: Name Type Description bytes bytes bytes result of message sent to netconf server Source code in channel/async_channel.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 async def send_input_netconf ( self , channel_input : str ) -> bytes : \"\"\" Send inputs to netconf server Args: channel_input: string of the base xml message to send to netconf server Returns: bytes: bytes result of message sent to netconf server Raises: N/A \"\"\" bytes_final_channel_input = channel_input . encode () buf : bytes buf , _ = await super () . send_input ( channel_input = channel_input , strip_prompt = False , eager = True ) if bytes_final_channel_input in buf : buf = buf . split ( bytes_final_channel_input )[ 1 ] buf = await self . _read_until_prompt ( buf = buf ) if self . _server_echo is None : # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT # echo the input commands back to the client. In the case of \"normal\" scrapli netconf # with the system transport this happens anyway because we combine the stdin and stdout # fds into a single pty, however for other transports we have an actual stdin and # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems # to want to echo inputs back onto to the stdout for the channel. This is totally ok # and we can deal with it, we just need to *know* that it is happening, so while the # _server_echo attribute is still `None`, we can go ahead and see if the input we sent # is in the output we read off the channel. If it is *not* we know the server does *not* # echo and we can move on. If it *is* in the output, we know the server echoes, and we # also have one additional step in that we need to read \"until prompt\" again in order to # capture the reply to our rpc. # # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\") self . logger . debug ( \"server echo is unset, determining if server echoes inputs now\" ) if bytes_final_channel_input in buf : self . logger . debug ( \"server echoes inputs, setting _server_echo to 'true'\" ) self . _server_echo = True # since echo is True and we only read until our input (because our inputs always end # with a \"prompt\" that we read until) we need to once again read until prompt, this # read will read all the way up through the *reply* to the prompt at end of the # reply message buf = await self . _read_until_prompt ( buf = b \"\" ) else : self . logger . debug ( \"server does *not* echo inputs, setting _server_echo to 'false'\" ) self . _server_echo = False if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_1 : # netconf 1.1 with \"chunking\" style message format needs an extra return char here self . send_return () return buf","title":"send_input_netconf()"},{"location":"reference/channel/base_channel/","text":"scrapli_netconf.channel.base_channel BaseNetconfChannel \u00b6 Bases: BaseChannel Source code in channel/base_channel.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 class BaseNetconfChannel ( BaseChannel ): _netconf_base_channel_args : NetconfBaseChannelArgs def _process_capabilities_exchange ( self , raw_server_capabilities : bytes ) -> None : \"\"\" Process received capabilities; return client capabilities Args: raw_server_capabilities: raw bytes containing server capabilities Returns: None Raises: CapabilityNotSupported: if user has provided a preferred netconf version but it is not available in servers offered capabilities \"\"\" server_capabilities = self . _parse_server_capabilities ( raw_server_capabilities = raw_server_capabilities ) self . _netconf_base_channel_args . server_capabilities = server_capabilities if \"urn:ietf:params:netconf:base:1.1\" in server_capabilities : final_channel_version = NetconfVersion . VERSION_1_1 else : final_channel_version = NetconfVersion . VERSION_1_0 if self . _netconf_base_channel_args . netconf_version != NetconfVersion . UNKNOWN : if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_0 : if \"urn:ietf:params:netconf:base:1.0\" not in server_capabilities : raise CapabilityNotSupported ( \"user requested netconf version 1.0 but capability not offered\" ) final_channel_version = NetconfVersion . VERSION_1_0 elif self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_1 : if \"urn:ietf:params:netconf:base:1.1\" not in server_capabilities : raise CapabilityNotSupported ( \"user requested netconf version 1.1 but capability not offered\" ) final_channel_version = NetconfVersion . VERSION_1_1 if final_channel_version == NetconfVersion . VERSION_1_0 : self . _netconf_base_channel_args . netconf_version = NetconfVersion . VERSION_1_0 self . _base_channel_args . comms_prompt_pattern = \"]]>]]>\" self . _netconf_base_channel_args . client_capabilities = ( NetconfClientCapabilities . CAPABILITIES_1_0 ) else : self . _netconf_base_channel_args . netconf_version = NetconfVersion . VERSION_1_1 self . _base_channel_args . comms_prompt_pattern = r \"^##$\" self . _netconf_base_channel_args . client_capabilities = ( NetconfClientCapabilities . CAPABILITIES_1_1 ) def _parse_server_capabilities ( self , raw_server_capabilities : bytes ) -> List [ str ]: \"\"\" Parse netconf server capabilities Args: raw_server_capabilities: raw bytes containing server capabilities Returns: N/A # noqa: DAR202 Raises: CouldNotExchangeCapabilities: if server capabilities cannot be parsed \"\"\" server_capabilities = [] # matches hello with or without namespace filtered_raw_server_capabilities = re . search ( pattern = rb \"(<(\\w+\\:){0,1}hello.*<\\/(\\w+\\:){0,1}hello>)\" , string = raw_server_capabilities , flags = re . I | re . S , ) if filtered_raw_server_capabilities is None : msg = \"failed to parse server capabilities\" raise CouldNotExchangeCapabilities ( msg ) server_capabilities_xml = etree . fromstring ( filtered_raw_server_capabilities . groups ()[ 0 ]) for elem in server_capabilities_xml . iter (): if \"capability\" not in elem . tag : continue server_capabilities . append ( elem . text . strip ()) self . logger . info ( f \"server capabilities received and parsed: { server_capabilities } \" ) return server_capabilities def _process_output ( self , buf : bytes , strip_prompt : bool ) -> bytes : \"\"\" Override scrapli _process_output as this is unnecessary for scrapli_netconf Args: buf: bytes output from the device strip_prompt: ignored in this base class; for LSP reasons for subclasses Returns: bytes: output of joined output lines optionally with prompt removed Raises: N/A \"\"\" _ = strip_prompt return buf def _pre_send_client_capabilities ( self , client_capabilities : NetconfClientCapabilities ) -> bytes : \"\"\" Handle pre \"_send_client_capabilities\" tasks for consistency between sync/async versions Args: client_capabilities: string of client netconf capabilities to send to server Returns: bytes: bytes of client capabilities to send to the channel Raises: N/A \"\"\" self . logger . info ( \"sending client capabilities\" ) bytes_client_capabilities : bytes = client_capabilities . value . encode () . strip () self . logger . debug ( f \"attempting to send capabilities: { client_capabilities } \" ) self . write ( client_capabilities . value ) return bytes_client_capabilities","title":"base_channel"},{"location":"reference/channel/base_channel/#channel.base_channel.BaseNetconfChannel","text":"Bases: BaseChannel Source code in channel/base_channel.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 class BaseNetconfChannel ( BaseChannel ): _netconf_base_channel_args : NetconfBaseChannelArgs def _process_capabilities_exchange ( self , raw_server_capabilities : bytes ) -> None : \"\"\" Process received capabilities; return client capabilities Args: raw_server_capabilities: raw bytes containing server capabilities Returns: None Raises: CapabilityNotSupported: if user has provided a preferred netconf version but it is not available in servers offered capabilities \"\"\" server_capabilities = self . _parse_server_capabilities ( raw_server_capabilities = raw_server_capabilities ) self . _netconf_base_channel_args . server_capabilities = server_capabilities if \"urn:ietf:params:netconf:base:1.1\" in server_capabilities : final_channel_version = NetconfVersion . VERSION_1_1 else : final_channel_version = NetconfVersion . VERSION_1_0 if self . _netconf_base_channel_args . netconf_version != NetconfVersion . UNKNOWN : if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_0 : if \"urn:ietf:params:netconf:base:1.0\" not in server_capabilities : raise CapabilityNotSupported ( \"user requested netconf version 1.0 but capability not offered\" ) final_channel_version = NetconfVersion . VERSION_1_0 elif self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_1 : if \"urn:ietf:params:netconf:base:1.1\" not in server_capabilities : raise CapabilityNotSupported ( \"user requested netconf version 1.1 but capability not offered\" ) final_channel_version = NetconfVersion . VERSION_1_1 if final_channel_version == NetconfVersion . VERSION_1_0 : self . _netconf_base_channel_args . netconf_version = NetconfVersion . VERSION_1_0 self . _base_channel_args . comms_prompt_pattern = \"]]>]]>\" self . _netconf_base_channel_args . client_capabilities = ( NetconfClientCapabilities . CAPABILITIES_1_0 ) else : self . _netconf_base_channel_args . netconf_version = NetconfVersion . VERSION_1_1 self . _base_channel_args . comms_prompt_pattern = r \"^##$\" self . _netconf_base_channel_args . client_capabilities = ( NetconfClientCapabilities . CAPABILITIES_1_1 ) def _parse_server_capabilities ( self , raw_server_capabilities : bytes ) -> List [ str ]: \"\"\" Parse netconf server capabilities Args: raw_server_capabilities: raw bytes containing server capabilities Returns: N/A # noqa: DAR202 Raises: CouldNotExchangeCapabilities: if server capabilities cannot be parsed \"\"\" server_capabilities = [] # matches hello with or without namespace filtered_raw_server_capabilities = re . search ( pattern = rb \"(<(\\w+\\:){0,1}hello.*<\\/(\\w+\\:){0,1}hello>)\" , string = raw_server_capabilities , flags = re . I | re . S , ) if filtered_raw_server_capabilities is None : msg = \"failed to parse server capabilities\" raise CouldNotExchangeCapabilities ( msg ) server_capabilities_xml = etree . fromstring ( filtered_raw_server_capabilities . groups ()[ 0 ]) for elem in server_capabilities_xml . iter (): if \"capability\" not in elem . tag : continue server_capabilities . append ( elem . text . strip ()) self . logger . info ( f \"server capabilities received and parsed: { server_capabilities } \" ) return server_capabilities def _process_output ( self , buf : bytes , strip_prompt : bool ) -> bytes : \"\"\" Override scrapli _process_output as this is unnecessary for scrapli_netconf Args: buf: bytes output from the device strip_prompt: ignored in this base class; for LSP reasons for subclasses Returns: bytes: output of joined output lines optionally with prompt removed Raises: N/A \"\"\" _ = strip_prompt return buf def _pre_send_client_capabilities ( self , client_capabilities : NetconfClientCapabilities ) -> bytes : \"\"\" Handle pre \"_send_client_capabilities\" tasks for consistency between sync/async versions Args: client_capabilities: string of client netconf capabilities to send to server Returns: bytes: bytes of client capabilities to send to the channel Raises: N/A \"\"\" self . logger . info ( \"sending client capabilities\" ) bytes_client_capabilities : bytes = client_capabilities . value . encode () . strip () self . logger . debug ( f \"attempting to send capabilities: { client_capabilities } \" ) self . write ( client_capabilities . value ) return bytes_client_capabilities","title":"BaseNetconfChannel"},{"location":"reference/channel/sync_channel/","text":"scrapli_netconf.channel.sync_channel NetconfChannel \u00b6 Bases: Channel , BaseNetconfChannel Source code in channel/sync_channel.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 class NetconfChannel ( Channel , BaseNetconfChannel ): def __init__ ( self , transport : Transport , base_channel_args : BaseChannelArgs , netconf_base_channel_args : NetconfBaseChannelArgs , ): super () . __init__ ( transport = transport , base_channel_args = base_channel_args ) self . _netconf_base_channel_args = netconf_base_channel_args # always use `]]>]]>` as the initial prompt to match self . _base_channel_args . comms_prompt_pattern = \"]]>]]>\" self . _server_echo : Optional [ bool ] = None self . _capabilities_buf = b \"\" def open_netconf ( self ) -> None : \"\"\" Open the netconf channel Args: N/A Returns: None Raises: N/A \"\"\" # open in scrapli core is where we open channel log (if applicable), do that self . open () raw_server_capabilities = self . _get_server_capabilities () self . _process_capabilities_exchange ( raw_server_capabilities = raw_server_capabilities ) self . _send_client_capabilities () @staticmethod def _authenticate_check_hello ( buf : bytes ) -> bool : \"\"\" Check if \"hello\" message is in output Args: buf: bytes output from the channel Returns: bool: true if hello message is seen, otherwise false Raises: N/A \"\"\" hello_match = re . search ( pattern = HELLO_MATCH , string = buf ) if hello_match : return True return False @timeout_wrapper def channel_authenticate_netconf ( self , auth_password : str , auth_private_key_passphrase : str ) -> None : \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self . logger . debug ( \"attempting in channel netconf authentication\" ) password_count = 0 passphrase_count = 0 authenticate_buf = b \"\" with self . _channel_lock (): while True : buf = self . read () authenticate_buf += buf . lower () self . _capabilities_buf += buf self . _ssh_message_handler ( output = authenticate_buf ) if b \"password\" in authenticate_buf : # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b \"\" password_count += 1 if password_count > 2 : msg = \"password prompt seen more than once, assuming auth failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) self . write ( channel_input = auth_password , redacted = True ) self . send_return () if b \"enter passphrase for key\" in authenticate_buf : # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b \"\" passphrase_count += 1 if passphrase_count > 2 : msg = \"passphrase prompt seen more than once, assuming auth failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) self . write ( channel_input = auth_private_key_passphrase , redacted = True ) self . send_return () if self . _authenticate_check_hello ( buf = authenticate_buf ): self . logger . info ( \"found start of server capabilities, authentication successful\" ) return @timeout_wrapper def _get_server_capabilities ( self ) -> bytes : \"\"\" Read until all server capabilities have been sent by server Args: N/A Returns: bytes: raw bytes containing server capabilities Raises: N/A \"\"\" capabilities_buf = self . _capabilities_buf # reset this to empty to avoid any confusion now that we are moving on self . _capabilities_buf = b \"\" with self . _channel_lock (): while b \"]]>]]>\" not in capabilities_buf : capabilities_buf += self . read () self . logger . debug ( f \"received raw server capabilities: { repr ( capabilities_buf ) } \" ) return capabilities_buf @timeout_wrapper def _send_client_capabilities ( self , ) -> None : \"\"\" Send client capabilities to the netconf server Args: N/A Returns: None Raises: N/A \"\"\" with self . _channel_lock (): bytes_client_capabilities = self . _pre_send_client_capabilities ( client_capabilities = self . _netconf_base_channel_args . client_capabilities ) self . _read_until_input ( channel_input = bytes_client_capabilities ) self . send_return () def _read_until_input ( self , channel_input : bytes ) -> bytes : \"\"\" Async read until all input has been entered. Args: channel_input: string to write to channel Returns: bytes: output read from channel Raises: N/A \"\"\" output = b \"\" if self . _server_echo is None or self . _server_echo is False : # if server_echo is `None` we dont know if the server echoes yet, so just return nothing # if its False we know it doesnt echo and we can return empty byte string anyway return output if not channel_input : self . logger . info ( f \"Read: { repr ( output ) } \" ) return output while True : output += self . read () # if we have all the input *or* we see the closing rpc tag we know we are done here if channel_input in output or b \"rpc>\" in output : break self . logger . info ( f \"Read: { repr ( output ) } \" ) return output def send_input_netconf ( self , channel_input : str ) -> bytes : \"\"\" Send inputs to netconf server Args: channel_input: string of the base xml message to send to netconf server Returns: bytes: bytes result of message sent to netconf server Raises: ScrapliTimeout: re-raises channel timeouts with additional message if channel input may be big enough to require setting `use_compressed_parser` to false -- note that this has only been seen as an issue with NXOS so far. \"\"\" bytes_final_channel_input = channel_input . encode () buf : bytes buf , _ = super () . send_input ( channel_input = channel_input , strip_prompt = False , eager = True ) if bytes_final_channel_input in buf : # if we got the input AND the rpc-reply we can strip out our inputs so we just have the # reply remaining buf = buf . split ( bytes_final_channel_input )[ 1 ] try : buf = self . _read_until_prompt ( buf = buf ) except ScrapliTimeout as exc : if len ( channel_input ) >= 4096 : msg = ( \"timed out finding prompt after sending input, input is greater than 4096 \" \"chars, try setting 'use_compressed_parser' to False\" ) self . logger . info ( msg ) raise ScrapliTimeout ( msg ) from exc raise ScrapliTimeout from exc if self . _server_echo is None : # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT # echo the input commands back to the client. In the case of \"normal\" scrapli netconf # with the system transport this happens anyway because we combine the stdin and stdout # fds into a single pty, however for other transports we have an actual stdin and # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems # to want to echo inputs back onto to the stdout for the channel. This is totally ok # and we can deal with it, we just need to *know* that it is happening, so while the # _server_echo attribute is still `None`, we can go ahead and see if the input we sent # is in the output we read off the channel. If it is *not* we know the server does *not* # echo and we can move on. If it *is* in the output, we know the server echoes, and we # also have one additional step in that we need to read \"until prompt\" again in order to # capture the reply to our rpc. # # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\") self . logger . debug ( \"server echo is unset, determining if server echoes inputs now\" ) if bytes_final_channel_input in buf : self . logger . debug ( \"server echoes inputs, setting _server_echo to 'true'\" ) self . _server_echo = True # since echo is True and we only read until our input (because our inputs always end # with a \"prompt\" that we read until) we need to once again read until prompt, this # read will read all the way up through the *reply* to the prompt at end of the # reply message buf = self . _read_until_prompt ( buf = b \"\" ) else : self . logger . debug ( \"server does *not* echo inputs, setting _server_echo to 'false'\" ) self . _server_echo = False if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_1 : # netconf 1.1 with \"chunking\" style message format needs an extra return char here self . send_return () return buf channel_authenticate_netconf ( auth_password : str , auth_private_key_passphrase : str ) -> None \u00b6 Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Parameters: Name Type Description Default auth_password str password to authenticate with required auth_private_key_passphrase str passphrase for ssh key if necessary required Returns: Type Description None None Raises: Type Description ScrapliAuthenticationFailed if password prompt seen more than twice ScrapliAuthenticationFailed if passphrase prompt seen more than twice Source code in channel/sync_channel.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 @timeout_wrapper def channel_authenticate_netconf ( self , auth_password : str , auth_private_key_passphrase : str ) -> None : \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self . logger . debug ( \"attempting in channel netconf authentication\" ) password_count = 0 passphrase_count = 0 authenticate_buf = b \"\" with self . _channel_lock (): while True : buf = self . read () authenticate_buf += buf . lower () self . _capabilities_buf += buf self . _ssh_message_handler ( output = authenticate_buf ) if b \"password\" in authenticate_buf : # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b \"\" password_count += 1 if password_count > 2 : msg = \"password prompt seen more than once, assuming auth failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) self . write ( channel_input = auth_password , redacted = True ) self . send_return () if b \"enter passphrase for key\" in authenticate_buf : # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b \"\" passphrase_count += 1 if passphrase_count > 2 : msg = \"passphrase prompt seen more than once, assuming auth failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) self . write ( channel_input = auth_private_key_passphrase , redacted = True ) self . send_return () if self . _authenticate_check_hello ( buf = authenticate_buf ): self . logger . info ( \"found start of server capabilities, authentication successful\" ) return open_netconf () -> None \u00b6 Open the netconf channel Returns: Type Description None None Source code in channel/sync_channel.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def open_netconf ( self ) -> None : \"\"\" Open the netconf channel Args: N/A Returns: None Raises: N/A \"\"\" # open in scrapli core is where we open channel log (if applicable), do that self . open () raw_server_capabilities = self . _get_server_capabilities () self . _process_capabilities_exchange ( raw_server_capabilities = raw_server_capabilities ) self . _send_client_capabilities () send_input_netconf ( channel_input : str ) -> bytes \u00b6 Send inputs to netconf server Parameters: Name Type Description Default channel_input str string of the base xml message to send to netconf server required Returns: Name Type Description bytes bytes bytes result of message sent to netconf server Raises: Type Description ScrapliTimeout re-raises channel timeouts with additional message if channel input may be big enough to require setting use_compressed_parser to false -- note that this has only been seen as an issue with NXOS so far. Source code in channel/sync_channel.py 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 def send_input_netconf ( self , channel_input : str ) -> bytes : \"\"\" Send inputs to netconf server Args: channel_input: string of the base xml message to send to netconf server Returns: bytes: bytes result of message sent to netconf server Raises: ScrapliTimeout: re-raises channel timeouts with additional message if channel input may be big enough to require setting `use_compressed_parser` to false -- note that this has only been seen as an issue with NXOS so far. \"\"\" bytes_final_channel_input = channel_input . encode () buf : bytes buf , _ = super () . send_input ( channel_input = channel_input , strip_prompt = False , eager = True ) if bytes_final_channel_input in buf : # if we got the input AND the rpc-reply we can strip out our inputs so we just have the # reply remaining buf = buf . split ( bytes_final_channel_input )[ 1 ] try : buf = self . _read_until_prompt ( buf = buf ) except ScrapliTimeout as exc : if len ( channel_input ) >= 4096 : msg = ( \"timed out finding prompt after sending input, input is greater than 4096 \" \"chars, try setting 'use_compressed_parser' to False\" ) self . logger . info ( msg ) raise ScrapliTimeout ( msg ) from exc raise ScrapliTimeout from exc if self . _server_echo is None : # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT # echo the input commands back to the client. In the case of \"normal\" scrapli netconf # with the system transport this happens anyway because we combine the stdin and stdout # fds into a single pty, however for other transports we have an actual stdin and # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems # to want to echo inputs back onto to the stdout for the channel. This is totally ok # and we can deal with it, we just need to *know* that it is happening, so while the # _server_echo attribute is still `None`, we can go ahead and see if the input we sent # is in the output we read off the channel. If it is *not* we know the server does *not* # echo and we can move on. If it *is* in the output, we know the server echoes, and we # also have one additional step in that we need to read \"until prompt\" again in order to # capture the reply to our rpc. # # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\") self . logger . debug ( \"server echo is unset, determining if server echoes inputs now\" ) if bytes_final_channel_input in buf : self . logger . debug ( \"server echoes inputs, setting _server_echo to 'true'\" ) self . _server_echo = True # since echo is True and we only read until our input (because our inputs always end # with a \"prompt\" that we read until) we need to once again read until prompt, this # read will read all the way up through the *reply* to the prompt at end of the # reply message buf = self . _read_until_prompt ( buf = b \"\" ) else : self . logger . debug ( \"server does *not* echo inputs, setting _server_echo to 'false'\" ) self . _server_echo = False if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_1 : # netconf 1.1 with \"chunking\" style message format needs an extra return char here self . send_return () return buf","title":"sync_channel"},{"location":"reference/channel/sync_channel/#channel.sync_channel.NetconfChannel","text":"Bases: Channel , BaseNetconfChannel Source code in channel/sync_channel.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 class NetconfChannel ( Channel , BaseNetconfChannel ): def __init__ ( self , transport : Transport , base_channel_args : BaseChannelArgs , netconf_base_channel_args : NetconfBaseChannelArgs , ): super () . __init__ ( transport = transport , base_channel_args = base_channel_args ) self . _netconf_base_channel_args = netconf_base_channel_args # always use `]]>]]>` as the initial prompt to match self . _base_channel_args . comms_prompt_pattern = \"]]>]]>\" self . _server_echo : Optional [ bool ] = None self . _capabilities_buf = b \"\" def open_netconf ( self ) -> None : \"\"\" Open the netconf channel Args: N/A Returns: None Raises: N/A \"\"\" # open in scrapli core is where we open channel log (if applicable), do that self . open () raw_server_capabilities = self . _get_server_capabilities () self . _process_capabilities_exchange ( raw_server_capabilities = raw_server_capabilities ) self . _send_client_capabilities () @staticmethod def _authenticate_check_hello ( buf : bytes ) -> bool : \"\"\" Check if \"hello\" message is in output Args: buf: bytes output from the channel Returns: bool: true if hello message is seen, otherwise false Raises: N/A \"\"\" hello_match = re . search ( pattern = HELLO_MATCH , string = buf ) if hello_match : return True return False @timeout_wrapper def channel_authenticate_netconf ( self , auth_password : str , auth_private_key_passphrase : str ) -> None : \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self . logger . debug ( \"attempting in channel netconf authentication\" ) password_count = 0 passphrase_count = 0 authenticate_buf = b \"\" with self . _channel_lock (): while True : buf = self . read () authenticate_buf += buf . lower () self . _capabilities_buf += buf self . _ssh_message_handler ( output = authenticate_buf ) if b \"password\" in authenticate_buf : # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b \"\" password_count += 1 if password_count > 2 : msg = \"password prompt seen more than once, assuming auth failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) self . write ( channel_input = auth_password , redacted = True ) self . send_return () if b \"enter passphrase for key\" in authenticate_buf : # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b \"\" passphrase_count += 1 if passphrase_count > 2 : msg = \"passphrase prompt seen more than once, assuming auth failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) self . write ( channel_input = auth_private_key_passphrase , redacted = True ) self . send_return () if self . _authenticate_check_hello ( buf = authenticate_buf ): self . logger . info ( \"found start of server capabilities, authentication successful\" ) return @timeout_wrapper def _get_server_capabilities ( self ) -> bytes : \"\"\" Read until all server capabilities have been sent by server Args: N/A Returns: bytes: raw bytes containing server capabilities Raises: N/A \"\"\" capabilities_buf = self . _capabilities_buf # reset this to empty to avoid any confusion now that we are moving on self . _capabilities_buf = b \"\" with self . _channel_lock (): while b \"]]>]]>\" not in capabilities_buf : capabilities_buf += self . read () self . logger . debug ( f \"received raw server capabilities: { repr ( capabilities_buf ) } \" ) return capabilities_buf @timeout_wrapper def _send_client_capabilities ( self , ) -> None : \"\"\" Send client capabilities to the netconf server Args: N/A Returns: None Raises: N/A \"\"\" with self . _channel_lock (): bytes_client_capabilities = self . _pre_send_client_capabilities ( client_capabilities = self . _netconf_base_channel_args . client_capabilities ) self . _read_until_input ( channel_input = bytes_client_capabilities ) self . send_return () def _read_until_input ( self , channel_input : bytes ) -> bytes : \"\"\" Async read until all input has been entered. Args: channel_input: string to write to channel Returns: bytes: output read from channel Raises: N/A \"\"\" output = b \"\" if self . _server_echo is None or self . _server_echo is False : # if server_echo is `None` we dont know if the server echoes yet, so just return nothing # if its False we know it doesnt echo and we can return empty byte string anyway return output if not channel_input : self . logger . info ( f \"Read: { repr ( output ) } \" ) return output while True : output += self . read () # if we have all the input *or* we see the closing rpc tag we know we are done here if channel_input in output or b \"rpc>\" in output : break self . logger . info ( f \"Read: { repr ( output ) } \" ) return output def send_input_netconf ( self , channel_input : str ) -> bytes : \"\"\" Send inputs to netconf server Args: channel_input: string of the base xml message to send to netconf server Returns: bytes: bytes result of message sent to netconf server Raises: ScrapliTimeout: re-raises channel timeouts with additional message if channel input may be big enough to require setting `use_compressed_parser` to false -- note that this has only been seen as an issue with NXOS so far. \"\"\" bytes_final_channel_input = channel_input . encode () buf : bytes buf , _ = super () . send_input ( channel_input = channel_input , strip_prompt = False , eager = True ) if bytes_final_channel_input in buf : # if we got the input AND the rpc-reply we can strip out our inputs so we just have the # reply remaining buf = buf . split ( bytes_final_channel_input )[ 1 ] try : buf = self . _read_until_prompt ( buf = buf ) except ScrapliTimeout as exc : if len ( channel_input ) >= 4096 : msg = ( \"timed out finding prompt after sending input, input is greater than 4096 \" \"chars, try setting 'use_compressed_parser' to False\" ) self . logger . info ( msg ) raise ScrapliTimeout ( msg ) from exc raise ScrapliTimeout from exc if self . _server_echo is None : # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT # echo the input commands back to the client. In the case of \"normal\" scrapli netconf # with the system transport this happens anyway because we combine the stdin and stdout # fds into a single pty, however for other transports we have an actual stdin and # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems # to want to echo inputs back onto to the stdout for the channel. This is totally ok # and we can deal with it, we just need to *know* that it is happening, so while the # _server_echo attribute is still `None`, we can go ahead and see if the input we sent # is in the output we read off the channel. If it is *not* we know the server does *not* # echo and we can move on. If it *is* in the output, we know the server echoes, and we # also have one additional step in that we need to read \"until prompt\" again in order to # capture the reply to our rpc. # # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\") self . logger . debug ( \"server echo is unset, determining if server echoes inputs now\" ) if bytes_final_channel_input in buf : self . logger . debug ( \"server echoes inputs, setting _server_echo to 'true'\" ) self . _server_echo = True # since echo is True and we only read until our input (because our inputs always end # with a \"prompt\" that we read until) we need to once again read until prompt, this # read will read all the way up through the *reply* to the prompt at end of the # reply message buf = self . _read_until_prompt ( buf = b \"\" ) else : self . logger . debug ( \"server does *not* echo inputs, setting _server_echo to 'false'\" ) self . _server_echo = False if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_1 : # netconf 1.1 with \"chunking\" style message format needs an extra return char here self . send_return () return buf","title":"NetconfChannel"},{"location":"reference/channel/sync_channel/#channel.sync_channel.NetconfChannel.channel_authenticate_netconf","text":"Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Parameters: Name Type Description Default auth_password str password to authenticate with required auth_private_key_passphrase str passphrase for ssh key if necessary required Returns: Type Description None None Raises: Type Description ScrapliAuthenticationFailed if password prompt seen more than twice ScrapliAuthenticationFailed if passphrase prompt seen more than twice Source code in channel/sync_channel.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 @timeout_wrapper def channel_authenticate_netconf ( self , auth_password : str , auth_private_key_passphrase : str ) -> None : \"\"\" Handle SSH Authentication for transports that only operate \"in the channel\" (i.e. system) Args: auth_password: password to authenticate with auth_private_key_passphrase: passphrase for ssh key if necessary Returns: None Raises: ScrapliAuthenticationFailed: if password prompt seen more than twice ScrapliAuthenticationFailed: if passphrase prompt seen more than twice \"\"\" self . logger . debug ( \"attempting in channel netconf authentication\" ) password_count = 0 passphrase_count = 0 authenticate_buf = b \"\" with self . _channel_lock (): while True : buf = self . read () authenticate_buf += buf . lower () self . _capabilities_buf += buf self . _ssh_message_handler ( output = authenticate_buf ) if b \"password\" in authenticate_buf : # clear the authentication buffer so we don't re-read the password prompt authenticate_buf = b \"\" password_count += 1 if password_count > 2 : msg = \"password prompt seen more than once, assuming auth failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) self . write ( channel_input = auth_password , redacted = True ) self . send_return () if b \"enter passphrase for key\" in authenticate_buf : # clear the authentication buffer so we don't re-read the passphrase prompt authenticate_buf = b \"\" passphrase_count += 1 if passphrase_count > 2 : msg = \"passphrase prompt seen more than once, assuming auth failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) self . write ( channel_input = auth_private_key_passphrase , redacted = True ) self . send_return () if self . _authenticate_check_hello ( buf = authenticate_buf ): self . logger . info ( \"found start of server capabilities, authentication successful\" ) return","title":"channel_authenticate_netconf()"},{"location":"reference/channel/sync_channel/#channel.sync_channel.NetconfChannel.open_netconf","text":"Open the netconf channel Returns: Type Description None None Source code in channel/sync_channel.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def open_netconf ( self ) -> None : \"\"\" Open the netconf channel Args: N/A Returns: None Raises: N/A \"\"\" # open in scrapli core is where we open channel log (if applicable), do that self . open () raw_server_capabilities = self . _get_server_capabilities () self . _process_capabilities_exchange ( raw_server_capabilities = raw_server_capabilities ) self . _send_client_capabilities ()","title":"open_netconf()"},{"location":"reference/channel/sync_channel/#channel.sync_channel.NetconfChannel.send_input_netconf","text":"Send inputs to netconf server Parameters: Name Type Description Default channel_input str string of the base xml message to send to netconf server required Returns: Name Type Description bytes bytes bytes result of message sent to netconf server Raises: Type Description ScrapliTimeout re-raises channel timeouts with additional message if channel input may be big enough to require setting use_compressed_parser to false -- note that this has only been seen as an issue with NXOS so far. Source code in channel/sync_channel.py 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 def send_input_netconf ( self , channel_input : str ) -> bytes : \"\"\" Send inputs to netconf server Args: channel_input: string of the base xml message to send to netconf server Returns: bytes: bytes result of message sent to netconf server Raises: ScrapliTimeout: re-raises channel timeouts with additional message if channel input may be big enough to require setting `use_compressed_parser` to false -- note that this has only been seen as an issue with NXOS so far. \"\"\" bytes_final_channel_input = channel_input . encode () buf : bytes buf , _ = super () . send_input ( channel_input = channel_input , strip_prompt = False , eager = True ) if bytes_final_channel_input in buf : # if we got the input AND the rpc-reply we can strip out our inputs so we just have the # reply remaining buf = buf . split ( bytes_final_channel_input )[ 1 ] try : buf = self . _read_until_prompt ( buf = buf ) except ScrapliTimeout as exc : if len ( channel_input ) >= 4096 : msg = ( \"timed out finding prompt after sending input, input is greater than 4096 \" \"chars, try setting 'use_compressed_parser' to False\" ) self . logger . info ( msg ) raise ScrapliTimeout ( msg ) from exc raise ScrapliTimeout from exc if self . _server_echo is None : # At least per early drafts of the netconf over ssh rfcs the netconf servers MUST NOT # echo the input commands back to the client. In the case of \"normal\" scrapli netconf # with the system transport this happens anyway because we combine the stdin and stdout # fds into a single pty, however for other transports we have an actual stdin and # stdout fd to read/write. It seems that at the very least IOSXE with NETCONF 1.1 seems # to want to echo inputs back onto to the stdout for the channel. This is totally ok # and we can deal with it, we just need to *know* that it is happening, so while the # _server_echo attribute is still `None`, we can go ahead and see if the input we sent # is in the output we read off the channel. If it is *not* we know the server does *not* # echo and we can move on. If it *is* in the output, we know the server echoes, and we # also have one additional step in that we need to read \"until prompt\" again in order to # capture the reply to our rpc. # # See: https://tools.ietf.org/html/draft-ietf-netconf-ssh-02 (search for \"echo\") self . logger . debug ( \"server echo is unset, determining if server echoes inputs now\" ) if bytes_final_channel_input in buf : self . logger . debug ( \"server echoes inputs, setting _server_echo to 'true'\" ) self . _server_echo = True # since echo is True and we only read until our input (because our inputs always end # with a \"prompt\" that we read until) we need to once again read until prompt, this # read will read all the way up through the *reply* to the prompt at end of the # reply message buf = self . _read_until_prompt ( buf = b \"\" ) else : self . logger . debug ( \"server does *not* echo inputs, setting _server_echo to 'false'\" ) self . _server_echo = False if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_1 : # netconf 1.1 with \"chunking\" style message format needs an extra return char here self . send_return () return buf","title":"send_input_netconf()"},{"location":"reference/driver/","text":"scrapli_netconf.driver","title":"driver"},{"location":"reference/driver/async_driver/","text":"scrapli_netconf.driver.async_driver AsyncNetconfDriver \u00b6 Bases: AsyncDriver , NetconfBaseDriver Source code in driver/async_driver.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 class AsyncNetconfDriver ( AsyncDriver , NetconfBaseDriver ): # kinda hate this but need to tell mypy that channel in netconf land is in fact a channel of # type `NetconfChannel` channel : AsyncNetconfChannel def __init__ ( self , host : str , port : int = 830 , strip_namespaces : bool = False , strict_datastores : bool = False , auth_username : str = \"\" , auth_password : str = \"\" , auth_private_key : str = \"\" , auth_private_key_passphrase : str = \"\" , auth_strict_key : bool = True , auth_bypass : bool = False , timeout_socket : float = 15.0 , timeout_transport : float = 30.0 , timeout_ops : float = 30.0 , comms_prompt_pattern : str = r \"^[a-z0-9.\\-@()/:]{1,48}[#>$]\\s*$\" , comms_return_char : str = \" \\n \" , ssh_config_file : Union [ str , bool ] = False , ssh_known_hosts_file : Union [ str , bool ] = False , on_init : Optional [ Callable [ ... , Any ]] = None , on_open : Optional [ Callable [ ... , Any ]] = None , on_close : Optional [ Callable [ ... , Any ]] = None , transport : str = \"system\" , transport_options : Optional [ Dict [ str , Any ]] = None , channel_log : Union [ str , bool ] = False , channel_lock : bool = False , preferred_netconf_version : Optional [ str ] = None , use_compressed_parser : bool = True , ) -> None : super () . __init__ ( host = host , port = port , auth_username = auth_username , auth_password = auth_password , auth_private_key = auth_private_key , auth_private_key_passphrase = auth_private_key_passphrase , auth_strict_key = auth_strict_key , auth_bypass = auth_bypass , timeout_socket = timeout_socket , timeout_transport = timeout_transport , timeout_ops = timeout_ops , comms_prompt_pattern = comms_prompt_pattern , comms_return_char = comms_return_char , ssh_config_file = ssh_config_file , ssh_known_hosts_file = ssh_known_hosts_file , on_init = on_init , on_open = on_open , on_close = on_close , transport = transport , transport_options = transport_options , channel_log = channel_log , channel_lock = channel_lock , ) _preferred_netconf_version = self . _determine_preferred_netconf_version ( preferred_netconf_version = preferred_netconf_version ) _preferred_xml_parser = self . _determine_preferred_xml_parser ( use_compressed_parser = use_compressed_parser ) self . _netconf_base_channel_args = NetconfBaseChannelArgs ( netconf_version = _preferred_netconf_version , xml_parser = _preferred_xml_parser ) self . channel = AsyncNetconfChannel ( transport = self . transport , base_channel_args = self . _base_channel_args , netconf_base_channel_args = self . _netconf_base_channel_args , ) self . strip_namespaces = strip_namespaces self . strict_datastores = strict_datastores self . server_capabilities : List [ str ] = [] self . readable_datastores : List [ str ] = [] self . writeable_datastores : List [ str ] = [] self . message_id = 101 async def open ( self ) -> None : \"\"\" Open netconf connection to server Args: N/A Returns: None Raises: N/A \"\"\" self . _pre_open_closing_log ( closing = False ) await self . transport . open_netconf () await self . channel . open_netconf () self . _build_readable_datastores () self . _build_writeable_datastores () self . _post_open_closing_log ( closing = False ) async def get ( self , filter_ : str , filter_type : str = \"subtree\" ) -> NetconfResponse : \"\"\" Netconf get operation Args: filter_: string filter to apply to the get filter_type: type of filter; subtree|xpath Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get ( filter_ = filter_ , filter_type = filter_type ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def get_config ( self , source : str = \"running\" , filter_ : Optional [ str ] = None , filter_type : str = \"subtree\" , default_type : Optional [ str ] = None , ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: source: configuration source to get; typically one of running|startup|candidate filter_: string of filter(s) to apply to configuration filter_type: type of filter; subtree|xpath default_type: string of with-default mode to apply when retrieving configuration Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get_config ( source = source , filter_ = filter_ , filter_type = filter_type , default_type = default_type ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def edit_config ( self , config : str , target : str = \"running\" ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: config: configuration to send to device target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_edit_config ( config = config , target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def delete_config ( self , target : str = \"candidate\" ) -> NetconfResponse : \"\"\" Netconf delete-config operation Args: target: configuration source to target; startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_delete_config ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def commit ( self , confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None , ) -> NetconfResponse : \"\"\" Netconf commit config operation Args: confirmed: whether this is a confirmed commit timeout: specifies the confirm timeout in seconds persist: make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit persist_id: value must be equal to the value given in the <persist> parameter to the original <commit> operation. Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_commit ( confirmed = confirmed , timeout = timeout , persist = persist , persist_id = persist_id , ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def discard ( self ) -> NetconfResponse : \"\"\" Netconf discard config operation Args: N/A Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_discard () raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def lock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf lock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_lock ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def unlock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf unlock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_unlock ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def rpc ( self , filter_ : Union [ str , _Element ]) -> NetconfResponse : \"\"\" Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Args: filter_: filter/rpc to execute Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_rpc ( filter_ = filter_ ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def validate ( self , source : str ) -> NetconfResponse : \"\"\" Netconf \"validate\" operation Args: source: configuration source to validate; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_validate ( source = source ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def copy_config ( self , source : str , target : str ) -> NetconfResponse : \"\"\" Netconf \"copy-config\" operation Args: source: configuration, url, or datastore to copy into the target datastore target: destination to copy the source to Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_copy_config ( source = source , target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response commit ( confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None ) -> NetconfResponse async \u00b6 Netconf commit config operation Parameters: Name Type Description Default confirmed bool whether this is a confirmed commit False timeout Optional [ int ] specifies the confirm timeout in seconds None persist Optional [ Union [ int , str ]] make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit None persist_id Optional [ Union [ int , str ]] value must be equal to the value given in the parameter to the original operation. None Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 async def commit ( self , confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None , ) -> NetconfResponse : \"\"\" Netconf commit config operation Args: confirmed: whether this is a confirmed commit timeout: specifies the confirm timeout in seconds persist: make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit persist_id: value must be equal to the value given in the <persist> parameter to the original <commit> operation. Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_commit ( confirmed = confirmed , timeout = timeout , persist = persist , persist_id = persist_id , ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response copy_config ( source : str , target : str ) -> NetconfResponse async \u00b6 Netconf \"copy-config\" operation Parameters: Name Type Description Default source str configuration, url, or datastore to copy into the target datastore required target str destination to copy the source to required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 async def copy_config ( self , source : str , target : str ) -> NetconfResponse : \"\"\" Netconf \"copy-config\" operation Args: source: configuration, url, or datastore to copy into the target datastore target: destination to copy the source to Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_copy_config ( source = source , target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response delete_config ( target : str = 'candidate' ) -> NetconfResponse async \u00b6 Netconf delete-config operation Parameters: Name Type Description Default target str configuration source to target; startup|candidate 'candidate' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 async def delete_config ( self , target : str = \"candidate\" ) -> NetconfResponse : \"\"\" Netconf delete-config operation Args: target: configuration source to target; startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_delete_config ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response discard () -> NetconfResponse async \u00b6 Netconf discard config operation Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 async def discard ( self ) -> NetconfResponse : \"\"\" Netconf discard config operation Args: N/A Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_discard () raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response edit_config ( config : str , target : str = 'running' ) -> NetconfResponse async \u00b6 Netconf get-config operation Parameters: Name Type Description Default config str configuration to send to device required target str configuration source to target; running|startup|candidate 'running' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 async def edit_config ( self , config : str , target : str = \"running\" ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: config: configuration to send to device target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_edit_config ( config = config , target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response get ( filter_ : str , filter_type : str = 'subtree' ) -> NetconfResponse async \u00b6 Netconf get operation Parameters: Name Type Description Default filter_ str string filter to apply to the get required filter_type str type of filter; subtree|xpath 'subtree' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 async def get ( self , filter_ : str , filter_type : str = \"subtree\" ) -> NetconfResponse : \"\"\" Netconf get operation Args: filter_: string filter to apply to the get filter_type: type of filter; subtree|xpath Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get ( filter_ = filter_ , filter_type = filter_type ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response get_config ( source : str = 'running' , filter_ : Optional [ str ] = None , filter_type : str = 'subtree' , default_type : Optional [ str ] = None ) -> NetconfResponse async \u00b6 Netconf get-config operation Parameters: Name Type Description Default source str configuration source to get; typically one of running|startup|candidate 'running' filter_ Optional [ str ] string of filter(s) to apply to configuration None filter_type str type of filter; subtree|xpath 'subtree' default_type Optional [ str ] string of with-default mode to apply when retrieving configuration None Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 async def get_config ( self , source : str = \"running\" , filter_ : Optional [ str ] = None , filter_type : str = \"subtree\" , default_type : Optional [ str ] = None , ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: source: configuration source to get; typically one of running|startup|candidate filter_: string of filter(s) to apply to configuration filter_type: type of filter; subtree|xpath default_type: string of with-default mode to apply when retrieving configuration Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get_config ( source = source , filter_ = filter_ , filter_type = filter_type , default_type = default_type ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response lock ( target : str ) -> NetconfResponse async \u00b6 Netconf lock operation Parameters: Name Type Description Default target str configuration source to target; running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 async def lock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf lock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_lock ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response open () -> None async \u00b6 Open netconf connection to server Returns: Type Description None None Source code in driver/async_driver.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 async def open ( self ) -> None : \"\"\" Open netconf connection to server Args: N/A Returns: None Raises: N/A \"\"\" self . _pre_open_closing_log ( closing = False ) await self . transport . open_netconf () await self . channel . open_netconf () self . _build_readable_datastores () self . _build_writeable_datastores () self . _post_open_closing_log ( closing = False ) rpc ( filter_ : Union [ str , _Element ]) -> NetconfResponse async \u00b6 Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Parameters: Name Type Description Default filter_ Union [ str , _Element ] filter/rpc to execute required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 async def rpc ( self , filter_ : Union [ str , _Element ]) -> NetconfResponse : \"\"\" Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Args: filter_: filter/rpc to execute Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_rpc ( filter_ = filter_ ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response unlock ( target : str ) -> NetconfResponse async \u00b6 Netconf unlock operation Parameters: Name Type Description Default target str configuration source to target; running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 async def unlock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf unlock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_unlock ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response validate ( source : str ) -> NetconfResponse async \u00b6 Netconf \"validate\" operation Parameters: Name Type Description Default source str configuration source to validate; typically one of running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 async def validate ( self , source : str ) -> NetconfResponse : \"\"\" Netconf \"validate\" operation Args: source: configuration source to validate; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_validate ( source = source ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"async_driver"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver","text":"Bases: AsyncDriver , NetconfBaseDriver Source code in driver/async_driver.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 class AsyncNetconfDriver ( AsyncDriver , NetconfBaseDriver ): # kinda hate this but need to tell mypy that channel in netconf land is in fact a channel of # type `NetconfChannel` channel : AsyncNetconfChannel def __init__ ( self , host : str , port : int = 830 , strip_namespaces : bool = False , strict_datastores : bool = False , auth_username : str = \"\" , auth_password : str = \"\" , auth_private_key : str = \"\" , auth_private_key_passphrase : str = \"\" , auth_strict_key : bool = True , auth_bypass : bool = False , timeout_socket : float = 15.0 , timeout_transport : float = 30.0 , timeout_ops : float = 30.0 , comms_prompt_pattern : str = r \"^[a-z0-9.\\-@()/:]{1,48}[#>$]\\s*$\" , comms_return_char : str = \" \\n \" , ssh_config_file : Union [ str , bool ] = False , ssh_known_hosts_file : Union [ str , bool ] = False , on_init : Optional [ Callable [ ... , Any ]] = None , on_open : Optional [ Callable [ ... , Any ]] = None , on_close : Optional [ Callable [ ... , Any ]] = None , transport : str = \"system\" , transport_options : Optional [ Dict [ str , Any ]] = None , channel_log : Union [ str , bool ] = False , channel_lock : bool = False , preferred_netconf_version : Optional [ str ] = None , use_compressed_parser : bool = True , ) -> None : super () . __init__ ( host = host , port = port , auth_username = auth_username , auth_password = auth_password , auth_private_key = auth_private_key , auth_private_key_passphrase = auth_private_key_passphrase , auth_strict_key = auth_strict_key , auth_bypass = auth_bypass , timeout_socket = timeout_socket , timeout_transport = timeout_transport , timeout_ops = timeout_ops , comms_prompt_pattern = comms_prompt_pattern , comms_return_char = comms_return_char , ssh_config_file = ssh_config_file , ssh_known_hosts_file = ssh_known_hosts_file , on_init = on_init , on_open = on_open , on_close = on_close , transport = transport , transport_options = transport_options , channel_log = channel_log , channel_lock = channel_lock , ) _preferred_netconf_version = self . _determine_preferred_netconf_version ( preferred_netconf_version = preferred_netconf_version ) _preferred_xml_parser = self . _determine_preferred_xml_parser ( use_compressed_parser = use_compressed_parser ) self . _netconf_base_channel_args = NetconfBaseChannelArgs ( netconf_version = _preferred_netconf_version , xml_parser = _preferred_xml_parser ) self . channel = AsyncNetconfChannel ( transport = self . transport , base_channel_args = self . _base_channel_args , netconf_base_channel_args = self . _netconf_base_channel_args , ) self . strip_namespaces = strip_namespaces self . strict_datastores = strict_datastores self . server_capabilities : List [ str ] = [] self . readable_datastores : List [ str ] = [] self . writeable_datastores : List [ str ] = [] self . message_id = 101 async def open ( self ) -> None : \"\"\" Open netconf connection to server Args: N/A Returns: None Raises: N/A \"\"\" self . _pre_open_closing_log ( closing = False ) await self . transport . open_netconf () await self . channel . open_netconf () self . _build_readable_datastores () self . _build_writeable_datastores () self . _post_open_closing_log ( closing = False ) async def get ( self , filter_ : str , filter_type : str = \"subtree\" ) -> NetconfResponse : \"\"\" Netconf get operation Args: filter_: string filter to apply to the get filter_type: type of filter; subtree|xpath Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get ( filter_ = filter_ , filter_type = filter_type ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def get_config ( self , source : str = \"running\" , filter_ : Optional [ str ] = None , filter_type : str = \"subtree\" , default_type : Optional [ str ] = None , ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: source: configuration source to get; typically one of running|startup|candidate filter_: string of filter(s) to apply to configuration filter_type: type of filter; subtree|xpath default_type: string of with-default mode to apply when retrieving configuration Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get_config ( source = source , filter_ = filter_ , filter_type = filter_type , default_type = default_type ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def edit_config ( self , config : str , target : str = \"running\" ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: config: configuration to send to device target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_edit_config ( config = config , target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def delete_config ( self , target : str = \"candidate\" ) -> NetconfResponse : \"\"\" Netconf delete-config operation Args: target: configuration source to target; startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_delete_config ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def commit ( self , confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None , ) -> NetconfResponse : \"\"\" Netconf commit config operation Args: confirmed: whether this is a confirmed commit timeout: specifies the confirm timeout in seconds persist: make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit persist_id: value must be equal to the value given in the <persist> parameter to the original <commit> operation. Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_commit ( confirmed = confirmed , timeout = timeout , persist = persist , persist_id = persist_id , ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def discard ( self ) -> NetconfResponse : \"\"\" Netconf discard config operation Args: N/A Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_discard () raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def lock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf lock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_lock ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def unlock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf unlock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_unlock ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def rpc ( self , filter_ : Union [ str , _Element ]) -> NetconfResponse : \"\"\" Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Args: filter_: filter/rpc to execute Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_rpc ( filter_ = filter_ ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def validate ( self , source : str ) -> NetconfResponse : \"\"\" Netconf \"validate\" operation Args: source: configuration source to validate; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_validate ( source = source ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response async def copy_config ( self , source : str , target : str ) -> NetconfResponse : \"\"\" Netconf \"copy-config\" operation Args: source: configuration, url, or datastore to copy into the target datastore target: destination to copy the source to Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_copy_config ( source = source , target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"AsyncNetconfDriver"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.commit","text":"Netconf commit config operation Parameters: Name Type Description Default confirmed bool whether this is a confirmed commit False timeout Optional [ int ] specifies the confirm timeout in seconds None persist Optional [ Union [ int , str ]] make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit None persist_id Optional [ Union [ int , str ]] value must be equal to the value given in the parameter to the original operation. None Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 async def commit ( self , confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None , ) -> NetconfResponse : \"\"\" Netconf commit config operation Args: confirmed: whether this is a confirmed commit timeout: specifies the confirm timeout in seconds persist: make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit persist_id: value must be equal to the value given in the <persist> parameter to the original <commit> operation. Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_commit ( confirmed = confirmed , timeout = timeout , persist = persist , persist_id = persist_id , ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"commit()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.copy_config","text":"Netconf \"copy-config\" operation Parameters: Name Type Description Default source str configuration, url, or datastore to copy into the target datastore required target str destination to copy the source to required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 async def copy_config ( self , source : str , target : str ) -> NetconfResponse : \"\"\" Netconf \"copy-config\" operation Args: source: configuration, url, or datastore to copy into the target datastore target: destination to copy the source to Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_copy_config ( source = source , target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"copy_config()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.delete_config","text":"Netconf delete-config operation Parameters: Name Type Description Default target str configuration source to target; startup|candidate 'candidate' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 async def delete_config ( self , target : str = \"candidate\" ) -> NetconfResponse : \"\"\" Netconf delete-config operation Args: target: configuration source to target; startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_delete_config ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"delete_config()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.discard","text":"Netconf discard config operation Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 async def discard ( self ) -> NetconfResponse : \"\"\" Netconf discard config operation Args: N/A Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_discard () raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"discard()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.edit_config","text":"Netconf get-config operation Parameters: Name Type Description Default config str configuration to send to device required target str configuration source to target; running|startup|candidate 'running' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 async def edit_config ( self , config : str , target : str = \"running\" ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: config: configuration to send to device target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_edit_config ( config = config , target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"edit_config()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.get","text":"Netconf get operation Parameters: Name Type Description Default filter_ str string filter to apply to the get required filter_type str type of filter; subtree|xpath 'subtree' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 async def get ( self , filter_ : str , filter_type : str = \"subtree\" ) -> NetconfResponse : \"\"\" Netconf get operation Args: filter_: string filter to apply to the get filter_type: type of filter; subtree|xpath Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get ( filter_ = filter_ , filter_type = filter_type ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"get()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.get_config","text":"Netconf get-config operation Parameters: Name Type Description Default source str configuration source to get; typically one of running|startup|candidate 'running' filter_ Optional [ str ] string of filter(s) to apply to configuration None filter_type str type of filter; subtree|xpath 'subtree' default_type Optional [ str ] string of with-default mode to apply when retrieving configuration None Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 async def get_config ( self , source : str = \"running\" , filter_ : Optional [ str ] = None , filter_type : str = \"subtree\" , default_type : Optional [ str ] = None , ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: source: configuration source to get; typically one of running|startup|candidate filter_: string of filter(s) to apply to configuration filter_type: type of filter; subtree|xpath default_type: string of with-default mode to apply when retrieving configuration Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get_config ( source = source , filter_ = filter_ , filter_type = filter_type , default_type = default_type ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"get_config()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.lock","text":"Netconf lock operation Parameters: Name Type Description Default target str configuration source to target; running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 async def lock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf lock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_lock ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"lock()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.open","text":"Open netconf connection to server Returns: Type Description None None Source code in driver/async_driver.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 async def open ( self ) -> None : \"\"\" Open netconf connection to server Args: N/A Returns: None Raises: N/A \"\"\" self . _pre_open_closing_log ( closing = False ) await self . transport . open_netconf () await self . channel . open_netconf () self . _build_readable_datastores () self . _build_writeable_datastores () self . _post_open_closing_log ( closing = False )","title":"open()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.rpc","text":"Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Parameters: Name Type Description Default filter_ Union [ str , _Element ] filter/rpc to execute required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 async def rpc ( self , filter_ : Union [ str , _Element ]) -> NetconfResponse : \"\"\" Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Args: filter_: filter/rpc to execute Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_rpc ( filter_ = filter_ ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"rpc()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.unlock","text":"Netconf unlock operation Parameters: Name Type Description Default target str configuration source to target; running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 async def unlock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf unlock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_unlock ( target = target ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"unlock()"},{"location":"reference/driver/async_driver/#driver.async_driver.AsyncNetconfDriver.validate","text":"Netconf \"validate\" operation Parameters: Name Type Description Default source str configuration source to validate; typically one of running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/async_driver.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 async def validate ( self , source : str ) -> NetconfResponse : \"\"\" Netconf \"validate\" operation Args: source: configuration source to validate; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_validate ( source = source ) raw_response = await self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"validate()"},{"location":"reference/driver/base_driver/","text":"scrapli_netconf.driver.base_driver NetconfBaseDriver \u00b6 Bases: BaseDriver Source code in driver/base_driver.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 class NetconfBaseDriver ( BaseDriver ): host : str readable_datastores : List [ str ] writeable_datastores : List [ str ] strip_namespaces : bool strict_datastores : bool flatten_input : bool _netconf_base_channel_args : NetconfBaseChannelArgs @property def netconf_version ( self ) -> NetconfVersion : \"\"\" Getter for 'netconf_version' attribute Args: N/A Returns: NetconfVersion: netconf_version enum Raises: N/A \"\"\" return self . _netconf_base_channel_args . netconf_version @netconf_version . setter def netconf_version ( self , value : NetconfVersion ) -> None : \"\"\" Setter for 'netconf_version' attribute Args: value: NetconfVersion Returns: None Raises: ScrapliTypeError: if value is not of type NetconfVersion \"\"\" if not isinstance ( value , NetconfVersion ): raise ScrapliTypeError self . logger . debug ( f \"setting 'netconf_version' value to ' { value . value } '\" ) self . _netconf_base_channel_args . netconf_version = value if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_0 : self . _base_channel_args . comms_prompt_pattern = \"]]>]]>\" else : self . _base_channel_args . comms_prompt_pattern = r \"^##$\" @property def client_capabilities ( self ) -> NetconfClientCapabilities : \"\"\" Getter for 'client_capabilities' attribute Args: N/A Returns: NetconfClientCapabilities: netconf client capabilities enum Raises: N/A \"\"\" return self . _netconf_base_channel_args . client_capabilities @client_capabilities . setter def client_capabilities ( self , value : NetconfClientCapabilities ) -> None : \"\"\" Setter for 'client_capabilities' attribute Args: value: NetconfClientCapabilities value for client_capabilities Returns: None Raises: ScrapliTypeError: if value is not of type NetconfClientCapabilities \"\"\" if not isinstance ( value , NetconfClientCapabilities ): raise ScrapliTypeError self . logger . debug ( f \"setting 'client_capabilities' value to ' { value . value } '\" ) self . _netconf_base_channel_args . client_capabilities = value @property def server_capabilities ( self ) -> List [ str ]: \"\"\" Getter for 'server_capabilities' attribute Args: N/A Returns: list: list of strings of server capabilities Raises: N/A \"\"\" return self . _netconf_base_channel_args . server_capabilities or [] @server_capabilities . setter def server_capabilities ( self , value : NetconfClientCapabilities ) -> None : \"\"\" Setter for 'server_capabilities' attribute Args: value: list of strings of netconf server capabilities Returns: None Raises: ScrapliTypeError: if value is not of type list \"\"\" if not isinstance ( value , list ): raise ScrapliTypeError self . logger . debug ( f \"setting 'server_capabilities' value to ' { value } '\" ) self . _netconf_base_channel_args . server_capabilities = value @staticmethod def _determine_preferred_netconf_version ( preferred_netconf_version : Optional [ str ], ) -> NetconfVersion : \"\"\" Determine users preferred netconf version (if applicable) Args: preferred_netconf_version: optional string indicating users preferred netconf version Returns: NetconfVersion: users preferred netconf version Raises: ScrapliValueError: if preferred_netconf_version is not None or a valid option \"\"\" if preferred_netconf_version is None : return NetconfVersion . UNKNOWN if preferred_netconf_version == \"1.0\" : return NetconfVersion . VERSION_1_0 if preferred_netconf_version == \"1.1\" : return NetconfVersion . VERSION_1_1 raise ScrapliValueError ( \"'preferred_netconf_version' provided with invalid value, must be one of: \" \"None, '1.0', or '1.1'\" ) @staticmethod def _determine_preferred_xml_parser ( use_compressed_parser : bool ) -> XmlParserVersion : \"\"\" Determine users preferred xml payload parser Args: use_compressed_parser: bool indicating use of compressed parser or not Returns: XmlParserVersion: users xml parser version Raises: N/A \"\"\" if use_compressed_parser is True : return XmlParserVersion . COMPRESSED_PARSER return XmlParserVersion . STANDARD_PARSER @property def xml_parser ( self ) -> etree . XMLParser : \"\"\" Getter for 'xml_parser' attribute Args: N/A Returns: etree.XMLParser: parser to use for parsing xml documents Raises: N/A \"\"\" if self . _netconf_base_channel_args . xml_parser == XmlParserVersion . COMPRESSED_PARSER : return COMPRESSED_PARSER return STANDARD_PARSER @xml_parser . setter def xml_parser ( self , value : XmlParserVersion ) -> None : \"\"\" Setter for 'xml_parser' attribute Args: value: enum indicating parser version to use Returns: None Raises: ScrapliTypeError: if value is not of type XmlParserVersion \"\"\" if not isinstance ( value , XmlParserVersion ): raise ScrapliTypeError self . _netconf_base_channel_args . xml_parser = value def _transport_factory ( self ) -> Tuple [ Callable [ ... , Any ], object ]: \"\"\" Determine proper transport class and necessary arguments to initialize that class Args: N/A Returns: Tuple[Callable[..., Any], object]: tuple of transport class and dataclass of transport class specific arguments Raises: N/A \"\"\" transport_plugin_module = importlib . import_module ( f \"scrapli_netconf.transport.plugins. { self . transport_name } .transport\" ) transport_class = getattr ( transport_plugin_module , f \"Netconf { self . transport_name . capitalize () } Transport\" ) plugin_transport_args_class = getattr ( transport_plugin_module , \"PluginTransportArgs\" ) _plugin_transport_args = { field . name : getattr ( self , field . name ) for field in fields ( plugin_transport_args_class ) } plugin_transport_args = plugin_transport_args_class ( ** _plugin_transport_args ) return transport_class , plugin_transport_args def _build_readable_datastores ( self ) -> None : \"\"\" Build a list of readable datastores based on server's advertised capabilities Args: N/A Returns: None Raises: N/A \"\"\" self . readable_datastores = [] self . readable_datastores . append ( \"running\" ) if \"urn:ietf:params:netconf:capability:candidate:1.0\" in self . server_capabilities : self . readable_datastores . append ( \"candidate\" ) if \"urn:ietf:params:netconf:capability:startup:1.0\" in self . server_capabilities : self . readable_datastores . append ( \"startup\" ) def _build_writeable_datastores ( self ) -> None : \"\"\" Build a list of writeable/editable datastores based on server's advertised capabilities Args: N/A Returns: None Raises: N/A \"\"\" self . writeable_datastores = [] if \"urn:ietf:params:netconf:capability:writeable-running:1.0\" in self . server_capabilities : self . writeable_datastores . append ( \"running\" ) if \"urn:ietf:params:netconf:capability:writable-running:1.0\" in self . server_capabilities : # NOTE: iosxe shows \"writable\" (as of 2020.07.01) despite RFC being \"writeable\" self . writeable_datastores . append ( \"running\" ) if \"urn:ietf:params:netconf:capability:candidate:1.0\" in self . server_capabilities : self . writeable_datastores . append ( \"candidate\" ) if \"urn:ietf:params:netconf:capability:startup:1.0\" in self . server_capabilities : self . writeable_datastores . append ( \"startup\" ) def _validate_get_config_target ( self , source : str ) -> None : \"\"\" Validate get-config source is acceptable Args: source: configuration source to get; typically one of running|startup|candidate Returns: None Raises: ScrapliValueError: if an invalid source was selected and strict_datastores is True \"\"\" if source not in self . readable_datastores : msg = f \"'source' should be one of { self . readable_datastores } , got ' { source } '\" self . logger . warning ( msg ) if self . strict_datastores is True : raise ScrapliValueError ( msg ) user_warning ( title = \"Invalid datastore source!\" , message = msg ) def _validate_edit_config_target ( self , target : str ) -> None : \"\"\" Validate edit-config/lock/unlock target is acceptable Args: target: configuration source to edit/lock; typically one of running|startup|candidate Returns: None Raises: ScrapliValueError: if an invalid source was selected \"\"\" if target not in self . writeable_datastores : msg = f \"'target' should be one of { self . writeable_datastores } , got ' { target } '\" self . logger . warning ( msg ) if self . strict_datastores is True : raise ScrapliValueError ( msg ) user_warning ( title = \"Invalid datastore target!\" , message = msg ) def _validate_delete_config_target ( self , target : str ) -> None : \"\"\" Validate delete-config/lock/unlock target is acceptable Args: target: configuration source to delete; typically one of startup|candidate Returns: None Raises: ScrapliValueError: if an invalid target was selected \"\"\" if target == \"running\" or target not in self . writeable_datastores : msg = f \"'target' should be one of { self . writeable_datastores } , got ' { target } '\" if target == \"running\" : msg = \"delete-config 'target' may not be 'running'\" self . logger . warning ( msg ) if self . strict_datastores is True : raise ScrapliValueError ( msg ) user_warning ( title = \"Invalid datastore target!\" , message = msg ) def _build_base_elem ( self ) -> _Element : \"\"\" Create base element for netconf operations Args: N/A Returns: _Element: lxml base element to use for netconf operation Raises: N/A \"\"\" # pylint did not seem to want to be ok with assigning this as a class attribute... and its # only used here so... here we are self . message_id : int # pylint: disable=W0201 self . logger . debug ( f \"Building base element for message id { self . message_id } \" ) base_xml_str = NetconfBaseOperations . RPC . value . format ( message_id = self . message_id ) self . message_id += 1 base_elem = etree . fromstring ( text = base_xml_str ) return base_elem def _build_filter ( self , filter_ : str , filter_type : str = \"subtree\" ) -> _Element : \"\"\" Create filter element for a given rpc The `filter_` string may contain multiple xml elements at its \"root\" (subtree filters); we will simply place the payload into a temporary \"tmp\" outer tag so that when we cast it to an etree object the elements are all preserved; without this outer \"tmp\" tag, lxml will scoop up only the first element provided as it appears to be the root of the document presumably. An example valid (to scrapli netconf at least) xml filter would be: ``` <interface-configurations xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-ifmgr-cfg\"> <interface-configuration> <active>act</active> </interface-configuration> </interface-configurations> <netconf-yang xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-man-netconf-cfg\"> </netconf-yang> ``` Args: filter_: strings of filters to build into a filter element or (for subtree) a full filter string (in filter tags) filter_type: type of filter; subtree|xpath Returns: _Element: lxml filter element to use for netconf operation Raises: CapabilityNotSupported: if xpath selected and not supported on server ScrapliValueError: if filter_type is not one of subtree|xpath \"\"\" if filter_type == \"subtree\" : # tmp tags to place the users kinda not valid xml filter into _filter_ = f \"<tmp> { filter_ } </tmp>\" # \"validate\" subtree filter by forcing it into xml, parser \"flattens\" it as well tmp_xml_filter_element = etree . fromstring ( _filter_ , parser = self . xml_parser ) if tmp_xml_filter_element . getchildren ()[ 0 ] . tag == \"filter\" : # if the user filter was already wrapped in filter tags we'll end up here, we will # blindly reuse the users filter but we'll make sure that the filter \"type\" is set xml_filter_elem = tmp_xml_filter_element . getchildren ()[ 0 ] xml_filter_elem . attrib [ \"type\" ] = \"subtree\" else : xml_filter_elem = etree . fromstring ( NetconfBaseOperations . FILTER_SUBTREE . value . format ( filter_type = filter_type ), ) # iterate through the children inside the tmp tags and insert *those* elements into # the actual final filter payload for xml_filter_element in tmp_xml_filter_element : # insert the subtree filter into the parent filter element xml_filter_elem . insert ( 1 , xml_filter_element ) elif filter_type == \"xpath\" : if \"urn:ietf:params:netconf:capability:xpath:1.0\" not in self . server_capabilities : msg = \"xpath filter requested, but is not supported by the server\" self . logger . exception ( msg ) raise CapabilityNotSupported ( msg ) xml_filter_elem = etree . fromstring ( NetconfBaseOperations . FILTER_XPATH . value . format ( filter_type = filter_type , xpath = filter_ ), parser = self . xml_parser , ) else : raise ScrapliValueError ( f \"'filter_type' should be one of subtree|xpath, got ' { filter_type } '\" ) return xml_filter_elem def _build_with_defaults ( self , default_type : str = \"report-all\" ) -> _Element : \"\"\" Create with-defaults element for a given operation Args: default_type: enumeration of with-defaults; report-all|trim|explicit|report-all-tagged Returns: _Element: lxml with-defaults element to use for netconf operation Raises: CapabilityNotSupported: if default_type provided but not supported by device ScrapliValueError: if default_type is not one of report-all|trim|explicit|report-all-tagged \"\"\" if default_type in [ \"report-all\" , \"trim\" , \"explicit\" , \"report-all-tagged\" ]: if ( \"urn:ietf:params:netconf:capability:with-defaults:1.0\" not in self . server_capabilities ): msg = \"with-defaults requested, but is not supported by the server\" self . logger . exception ( msg ) raise CapabilityNotSupported ( msg ) xml_with_defaults_element = etree . fromstring ( NetconfBaseOperations . WITH_DEFAULTS_SUBTREE . value . format ( default_type = default_type ), parser = self . xml_parser , ) else : raise ScrapliValueError ( \"'default_type' should be one of report-all|trim|explicit|report-all-tagged, \" f \"got ' { default_type } '\" ) return xml_with_defaults_element def _finalize_channel_input ( self , xml_request : _Element ) -> bytes : \"\"\" Create finalized channel input (as bytes) Args: xml_request: finalized xml element to cast to bytes and add declaration to Returns: bytes: finalized bytes input -- with 1.0 delimiter or 1.1 encoding Raises: N/A \"\"\" channel_input : bytes = etree . tostring ( element_or_tree = xml_request , xml_declaration = True , encoding = \"utf-8\" ) if self . netconf_version == NetconfVersion . VERSION_1_0 : channel_input = channel_input + b \"]]>]]>\" else : # format message for chunk (netconf 1.1) style message channel_input = b \"#%b \\n \" % str ( len ( channel_input )) . encode () + channel_input + b \" \\n ##\" return channel_input def _pre_get ( self , filter_ : str , filter_type : str = \"subtree\" ) -> NetconfResponse : \"\"\" Handle pre \"get\" tasks for consistency between sync/async versions *NOTE* The channel input (filter_) is loaded up as an lxml etree element here, this is done with a parser that removes whitespace. This has a somewhat undesirable effect of making any \"pretty\" input not pretty, however... after we load the xml object (which we do to validate that it is valid xml) we dump that xml object back to a string to be used as the actual raw payload we send down the channel, which means we are sending \"flattened\" (not pretty/ indented xml) to the device. This is important it seems! Some devices seme to not mind having the \"nicely\" formatted input (pretty xml). But! On devices that \"echo\" the inputs back -- sometimes the device will respond to our rpc without \"finishing\" echoing our inputs to the device, this breaks the core \"read until input\" processing that scrapli always does. For whatever reason if there are no line breaks this does not seem to happen? /shrug. Note that this comment applies to all of the \"pre\" methods that we parse a filter/payload! Args: filter_: string filter to apply to the get filter_type: type of filter; subtree|xpath Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( f \"Building payload for 'get' operation. filter_type: { filter_type } , filter_: { filter_ } \" ) # build base request and insert the get element xml_request = self . _build_base_elem () xml_get_element = etree . fromstring ( NetconfBaseOperations . GET . value ) xml_request . insert ( 0 , xml_get_element ) # build filter element xml_filter_elem = self . _build_filter ( filter_ = filter_ , filter_type = filter_type ) # insert filter element into parent get element get_element = xml_request . find ( \"get\" ) get_element . insert ( 0 , xml_filter_elem ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'get' operation. Payload: { channel_input . decode () } \" ) return response def _pre_get_config ( self , source : str = \"running\" , filter_ : Optional [ str ] = None , filter_type : str = \"subtree\" , default_type : Optional [ str ] = None , ) -> NetconfResponse : \"\"\" Handle pre \"get_config\" tasks for consistency between sync/async versions Args: source: configuration source to get; typically one of running|startup|candidate filter_: string of filter(s) to apply to configuration filter_type: type of filter; subtree|xpath default_type: string of with-default mode to apply when retrieving configuration Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( f \"Building payload for 'get-config' operation. source: { source } , filter_type: \" f \" { filter_type } , filter: { filter_ } , default_type: { default_type } \" ) self . _validate_get_config_target ( source = source ) # build base request and insert the get-config element xml_request = self . _build_base_elem () xml_get_config_element = etree . fromstring ( NetconfBaseOperations . GET_CONFIG . value . format ( source = source ), parser = self . xml_parser ) xml_request . insert ( 0 , xml_get_config_element ) if filter_ is not None : xml_filter_elem = self . _build_filter ( filter_ = filter_ , filter_type = filter_type ) # insert filter element into parent get element get_element = xml_request . find ( \"get-config\" ) # insert *after* source, otherwise juniper seems to gripe, maybe/probably others as well get_element . insert ( 1 , xml_filter_elem ) if default_type is not None : xml_with_defaults_elem = self . _build_with_defaults ( default_type = default_type ) get_element = xml_request . find ( \"get-config\" ) get_element . insert ( 2 , xml_with_defaults_elem ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'get-config' operation. Payload: { channel_input . decode () } \" ) return response def _pre_edit_config ( self , config : str , target : str = \"running\" ) -> NetconfResponse : \"\"\" Handle pre \"edit_config\" tasks for consistency between sync/async versions Args: config: configuration to send to device target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( f \"Building payload for 'edit-config' operation. target: { target } , config: { config } \" ) self . _validate_edit_config_target ( target = target ) xml_config = etree . fromstring ( config , parser = self . xml_parser ) # build base request and insert the edit-config element xml_request = self . _build_base_elem () xml_edit_config_element = etree . fromstring ( NetconfBaseOperations . EDIT_CONFIG . value . format ( target = target ) ) xml_request . insert ( 0 , xml_edit_config_element ) # insert parent filter element to first position so that target stays first just for nice # output/readability edit_config_element = xml_request . find ( \"edit-config\" ) edit_config_element . insert ( 1 , xml_config ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'edit-config' operation. Payload: { channel_input . decode () } \" ) return response def _pre_delete_config ( self , target : str = \"running\" ) -> NetconfResponse : \"\"\" Handle pre \"edit_config\" tasks for consistency between sync/async versions Args: target: configuration source to target; startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( f \"Building payload for 'delete-config' operation. target: { target } \" ) self . _validate_delete_config_target ( target = target ) xml_request = self . _build_base_elem () xml_validate_element = etree . fromstring ( NetconfBaseOperations . DELETE_CONFIG . value . format ( target = target ), parser = self . xml_parser ) xml_request . insert ( 0 , xml_validate_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'delete-config' operation. Payload: { channel_input . decode () } \" ) return response def _pre_commit ( self , confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None , ) -> NetconfResponse : \"\"\" Handle pre \"commit\" tasks for consistency between sync/async versions Args: confirmed: whether this is a confirmed commit timeout: specifies the confirm timeout in seconds persist: make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit persist_id: value must be equal to the value given in the <persist> parameter to the original <commit> operation. Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: ScrapliValueError: if persist and persist_id are provided (cannot combine) ScrapliValueError: if confirmed and persist_id are provided (cannot combine) CapabilityNotSupported: if device does not have confirmed-commit capability \"\"\" self . logger . debug ( \"Building payload for 'commit' operation\" ) xml_request = self . _build_base_elem () xml_commit_element = etree . fromstring ( NetconfBaseOperations . COMMIT . value , parser = self . xml_parser ) if persist and persist_id : raise ScrapliValueError ( \"Invalid combination - 'persist' cannot be present with 'persist-id'\" ) if confirmed and persist_id : raise ScrapliValueError ( \"Invalid combination - 'confirmed' cannot be present with 'persist-id'\" ) if confirmed or persist_id : if not any ( cap in self . server_capabilities for cap in ( \"urn:ietf:params:netconf:capability:confirmed-commit:1.0\" , \"urn:ietf:params:netconf:capability:confirmed-commit:1.1\" , ) ): msg = \"confirmed-commit requested, but is not supported by the server\" self . logger . exception ( msg ) raise CapabilityNotSupported ( msg ) if confirmed : xml_confirmed_element = etree . fromstring ( NetconfBaseOperations . COMMIT_CONFIRMED . value , parser = self . xml_parser ) xml_commit_element . append ( xml_confirmed_element ) if timeout is not None : xml_timeout_element = etree . fromstring ( NetconfBaseOperations . COMMIT_CONFIRMED_TIMEOUT . value . format ( timeout = timeout ), parser = self . xml_parser , ) xml_commit_element . append ( xml_timeout_element ) if persist is not None : xml_persist_element = etree . fromstring ( NetconfBaseOperations . COMMIT_CONFIRMED_PERSIST . value . format ( persist = persist ), parser = self . xml_parser , ) xml_commit_element . append ( xml_persist_element ) if persist_id is not None : xml_persist_id_element = etree . fromstring ( NetconfBaseOperations . COMMIT_PERSIST_ID . value . format ( persist_id = persist_id ), parser = self . xml_parser , ) xml_commit_element . append ( xml_persist_id_element ) xml_request . insert ( 0 , xml_commit_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'commit' operation. Payload: { channel_input . decode () } \" ) return response def _pre_discard ( self ) -> NetconfResponse : \"\"\" Handle pre \"discard\" tasks for consistency between sync/async versions Args: N/A Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( \"Building payload for 'discard' operation.\" ) xml_request = self . _build_base_elem () xml_commit_element = etree . fromstring ( NetconfBaseOperations . DISCARD . value , parser = self . xml_parser ) xml_request . insert ( 0 , xml_commit_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'discard' operation. Payload: { channel_input . decode () } \" ) return response def _pre_lock ( self , target : str ) -> NetconfResponse : \"\"\" Handle pre \"lock\" tasks for consistency between sync/async versions Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( \"Building payload for 'lock' operation.\" ) self . _validate_edit_config_target ( target = target ) xml_request = self . _build_base_elem () xml_lock_element = etree . fromstring ( NetconfBaseOperations . LOCK . value . format ( target = target ), parser = self . xml_parser ) xml_request . insert ( 0 , xml_lock_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'lock' operation. Payload: { channel_input . decode () } \" ) return response def _pre_unlock ( self , target : str ) -> NetconfResponse : \"\"\" Handle pre \"unlock\" tasks for consistency between sync/async versions Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( \"Building payload for 'unlock' operation.\" ) self . _validate_edit_config_target ( target = target ) xml_request = self . _build_base_elem () xml_lock_element = etree . fromstring ( NetconfBaseOperations . UNLOCK . value . format ( target = target ), parser = self . xml_parser ) xml_request . insert ( 0 , xml_lock_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'unlock' operation. Payload: { channel_input . decode () } \" ) return response def _pre_rpc ( self , filter_ : Union [ str , _Element ]) -> NetconfResponse : \"\"\" Handle pre \"rpc\" tasks for consistency between sync/async versions Args: filter_: filter/rpc to execute Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( \"Building payload for 'rpc' operation.\" ) xml_request = self . _build_base_elem () # build filter element if isinstance ( filter_ , str ): xml_filter_elem = etree . fromstring ( filter_ , parser = self . xml_parser ) else : xml_filter_elem = filter_ # insert filter element xml_request . insert ( 0 , xml_filter_elem ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'rpc' operation. Payload: { channel_input . decode () } \" ) return response def _pre_validate ( self , source : str ) -> NetconfResponse : \"\"\" Handle pre \"validate\" tasks for consistency between sync/async versions Args: source: configuration source to validate; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: CapabilityNotSupported: if 'validate' capability does not exist \"\"\" self . logger . debug ( \"Building payload for 'validate' operation.\" ) if not any ( cap in self . server_capabilities for cap in ( \"urn:ietf:params:netconf:capability:validate:1.0\" , \"urn:ietf:params:netconf:capability:validate:1.1\" , ) ): msg = \"validate requested, but is not supported by the server\" self . logger . exception ( msg ) raise CapabilityNotSupported ( msg ) self . _validate_edit_config_target ( target = source ) xml_request = self . _build_base_elem () xml_validate_element = etree . fromstring ( NetconfBaseOperations . VALIDATE . value . format ( source = source ), parser = self . xml_parser ) xml_request . insert ( 0 , xml_validate_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'validate' operation. Payload: { channel_input . decode () } \" ) return response def _pre_copy_config ( self , source : str , target : str ) -> NetconfResponse : \"\"\" Handle pre \"copy_config\" tasks for consistency between sync/async versions Note that source is not validated/checked since it could be a url or a full configuration element itself. Args: source: configuration, url, or datastore to copy into the target datastore target: copy config destination/target; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( \"Building payload for 'copy_config' operation.\" ) self . _validate_edit_config_target ( target = target ) xml_request = self . _build_base_elem () xml_validate_element = etree . fromstring ( NetconfBaseOperations . COPY_CONFIG . value . format ( source = source , target = target ), parser = self . xml_parser , ) xml_request . insert ( 0 , xml_validate_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'copy-config' operation. Payload: { channel_input . decode () } \" ) return response client_capabilities () -> NetconfClientCapabilities property writable \u00b6 Getter for 'client_capabilities' attribute Returns: Name Type Description NetconfClientCapabilities NetconfClientCapabilities netconf client capabilities enum Source code in driver/base_driver.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 @property def client_capabilities ( self ) -> NetconfClientCapabilities : \"\"\" Getter for 'client_capabilities' attribute Args: N/A Returns: NetconfClientCapabilities: netconf client capabilities enum Raises: N/A \"\"\" return self . _netconf_base_channel_args . client_capabilities netconf_version () -> NetconfVersion property writable \u00b6 Getter for 'netconf_version' attribute Returns: Name Type Description NetconfVersion NetconfVersion netconf_version enum Source code in driver/base_driver.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 @property def netconf_version ( self ) -> NetconfVersion : \"\"\" Getter for 'netconf_version' attribute Args: N/A Returns: NetconfVersion: netconf_version enum Raises: N/A \"\"\" return self . _netconf_base_channel_args . netconf_version server_capabilities () -> List [ str ] property writable \u00b6 Getter for 'server_capabilities' attribute Returns: Name Type Description list List [ str ] list of strings of server capabilities Source code in driver/base_driver.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @property def server_capabilities ( self ) -> List [ str ]: \"\"\" Getter for 'server_capabilities' attribute Args: N/A Returns: list: list of strings of server capabilities Raises: N/A \"\"\" return self . _netconf_base_channel_args . server_capabilities or [] xml_parser () -> etree . XMLParser property writable \u00b6 Getter for 'xml_parser' attribute Returns: Type Description etree . XMLParser etree.XMLParser: parser to use for parsing xml documents Source code in driver/base_driver.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 @property def xml_parser ( self ) -> etree . XMLParser : \"\"\" Getter for 'xml_parser' attribute Args: N/A Returns: etree.XMLParser: parser to use for parsing xml documents Raises: N/A \"\"\" if self . _netconf_base_channel_args . xml_parser == XmlParserVersion . COMPRESSED_PARSER : return COMPRESSED_PARSER return STANDARD_PARSER","title":"base_driver"},{"location":"reference/driver/base_driver/#driver.base_driver.NetconfBaseDriver","text":"Bases: BaseDriver Source code in driver/base_driver.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 class NetconfBaseDriver ( BaseDriver ): host : str readable_datastores : List [ str ] writeable_datastores : List [ str ] strip_namespaces : bool strict_datastores : bool flatten_input : bool _netconf_base_channel_args : NetconfBaseChannelArgs @property def netconf_version ( self ) -> NetconfVersion : \"\"\" Getter for 'netconf_version' attribute Args: N/A Returns: NetconfVersion: netconf_version enum Raises: N/A \"\"\" return self . _netconf_base_channel_args . netconf_version @netconf_version . setter def netconf_version ( self , value : NetconfVersion ) -> None : \"\"\" Setter for 'netconf_version' attribute Args: value: NetconfVersion Returns: None Raises: ScrapliTypeError: if value is not of type NetconfVersion \"\"\" if not isinstance ( value , NetconfVersion ): raise ScrapliTypeError self . logger . debug ( f \"setting 'netconf_version' value to ' { value . value } '\" ) self . _netconf_base_channel_args . netconf_version = value if self . _netconf_base_channel_args . netconf_version == NetconfVersion . VERSION_1_0 : self . _base_channel_args . comms_prompt_pattern = \"]]>]]>\" else : self . _base_channel_args . comms_prompt_pattern = r \"^##$\" @property def client_capabilities ( self ) -> NetconfClientCapabilities : \"\"\" Getter for 'client_capabilities' attribute Args: N/A Returns: NetconfClientCapabilities: netconf client capabilities enum Raises: N/A \"\"\" return self . _netconf_base_channel_args . client_capabilities @client_capabilities . setter def client_capabilities ( self , value : NetconfClientCapabilities ) -> None : \"\"\" Setter for 'client_capabilities' attribute Args: value: NetconfClientCapabilities value for client_capabilities Returns: None Raises: ScrapliTypeError: if value is not of type NetconfClientCapabilities \"\"\" if not isinstance ( value , NetconfClientCapabilities ): raise ScrapliTypeError self . logger . debug ( f \"setting 'client_capabilities' value to ' { value . value } '\" ) self . _netconf_base_channel_args . client_capabilities = value @property def server_capabilities ( self ) -> List [ str ]: \"\"\" Getter for 'server_capabilities' attribute Args: N/A Returns: list: list of strings of server capabilities Raises: N/A \"\"\" return self . _netconf_base_channel_args . server_capabilities or [] @server_capabilities . setter def server_capabilities ( self , value : NetconfClientCapabilities ) -> None : \"\"\" Setter for 'server_capabilities' attribute Args: value: list of strings of netconf server capabilities Returns: None Raises: ScrapliTypeError: if value is not of type list \"\"\" if not isinstance ( value , list ): raise ScrapliTypeError self . logger . debug ( f \"setting 'server_capabilities' value to ' { value } '\" ) self . _netconf_base_channel_args . server_capabilities = value @staticmethod def _determine_preferred_netconf_version ( preferred_netconf_version : Optional [ str ], ) -> NetconfVersion : \"\"\" Determine users preferred netconf version (if applicable) Args: preferred_netconf_version: optional string indicating users preferred netconf version Returns: NetconfVersion: users preferred netconf version Raises: ScrapliValueError: if preferred_netconf_version is not None or a valid option \"\"\" if preferred_netconf_version is None : return NetconfVersion . UNKNOWN if preferred_netconf_version == \"1.0\" : return NetconfVersion . VERSION_1_0 if preferred_netconf_version == \"1.1\" : return NetconfVersion . VERSION_1_1 raise ScrapliValueError ( \"'preferred_netconf_version' provided with invalid value, must be one of: \" \"None, '1.0', or '1.1'\" ) @staticmethod def _determine_preferred_xml_parser ( use_compressed_parser : bool ) -> XmlParserVersion : \"\"\" Determine users preferred xml payload parser Args: use_compressed_parser: bool indicating use of compressed parser or not Returns: XmlParserVersion: users xml parser version Raises: N/A \"\"\" if use_compressed_parser is True : return XmlParserVersion . COMPRESSED_PARSER return XmlParserVersion . STANDARD_PARSER @property def xml_parser ( self ) -> etree . XMLParser : \"\"\" Getter for 'xml_parser' attribute Args: N/A Returns: etree.XMLParser: parser to use for parsing xml documents Raises: N/A \"\"\" if self . _netconf_base_channel_args . xml_parser == XmlParserVersion . COMPRESSED_PARSER : return COMPRESSED_PARSER return STANDARD_PARSER @xml_parser . setter def xml_parser ( self , value : XmlParserVersion ) -> None : \"\"\" Setter for 'xml_parser' attribute Args: value: enum indicating parser version to use Returns: None Raises: ScrapliTypeError: if value is not of type XmlParserVersion \"\"\" if not isinstance ( value , XmlParserVersion ): raise ScrapliTypeError self . _netconf_base_channel_args . xml_parser = value def _transport_factory ( self ) -> Tuple [ Callable [ ... , Any ], object ]: \"\"\" Determine proper transport class and necessary arguments to initialize that class Args: N/A Returns: Tuple[Callable[..., Any], object]: tuple of transport class and dataclass of transport class specific arguments Raises: N/A \"\"\" transport_plugin_module = importlib . import_module ( f \"scrapli_netconf.transport.plugins. { self . transport_name } .transport\" ) transport_class = getattr ( transport_plugin_module , f \"Netconf { self . transport_name . capitalize () } Transport\" ) plugin_transport_args_class = getattr ( transport_plugin_module , \"PluginTransportArgs\" ) _plugin_transport_args = { field . name : getattr ( self , field . name ) for field in fields ( plugin_transport_args_class ) } plugin_transport_args = plugin_transport_args_class ( ** _plugin_transport_args ) return transport_class , plugin_transport_args def _build_readable_datastores ( self ) -> None : \"\"\" Build a list of readable datastores based on server's advertised capabilities Args: N/A Returns: None Raises: N/A \"\"\" self . readable_datastores = [] self . readable_datastores . append ( \"running\" ) if \"urn:ietf:params:netconf:capability:candidate:1.0\" in self . server_capabilities : self . readable_datastores . append ( \"candidate\" ) if \"urn:ietf:params:netconf:capability:startup:1.0\" in self . server_capabilities : self . readable_datastores . append ( \"startup\" ) def _build_writeable_datastores ( self ) -> None : \"\"\" Build a list of writeable/editable datastores based on server's advertised capabilities Args: N/A Returns: None Raises: N/A \"\"\" self . writeable_datastores = [] if \"urn:ietf:params:netconf:capability:writeable-running:1.0\" in self . server_capabilities : self . writeable_datastores . append ( \"running\" ) if \"urn:ietf:params:netconf:capability:writable-running:1.0\" in self . server_capabilities : # NOTE: iosxe shows \"writable\" (as of 2020.07.01) despite RFC being \"writeable\" self . writeable_datastores . append ( \"running\" ) if \"urn:ietf:params:netconf:capability:candidate:1.0\" in self . server_capabilities : self . writeable_datastores . append ( \"candidate\" ) if \"urn:ietf:params:netconf:capability:startup:1.0\" in self . server_capabilities : self . writeable_datastores . append ( \"startup\" ) def _validate_get_config_target ( self , source : str ) -> None : \"\"\" Validate get-config source is acceptable Args: source: configuration source to get; typically one of running|startup|candidate Returns: None Raises: ScrapliValueError: if an invalid source was selected and strict_datastores is True \"\"\" if source not in self . readable_datastores : msg = f \"'source' should be one of { self . readable_datastores } , got ' { source } '\" self . logger . warning ( msg ) if self . strict_datastores is True : raise ScrapliValueError ( msg ) user_warning ( title = \"Invalid datastore source!\" , message = msg ) def _validate_edit_config_target ( self , target : str ) -> None : \"\"\" Validate edit-config/lock/unlock target is acceptable Args: target: configuration source to edit/lock; typically one of running|startup|candidate Returns: None Raises: ScrapliValueError: if an invalid source was selected \"\"\" if target not in self . writeable_datastores : msg = f \"'target' should be one of { self . writeable_datastores } , got ' { target } '\" self . logger . warning ( msg ) if self . strict_datastores is True : raise ScrapliValueError ( msg ) user_warning ( title = \"Invalid datastore target!\" , message = msg ) def _validate_delete_config_target ( self , target : str ) -> None : \"\"\" Validate delete-config/lock/unlock target is acceptable Args: target: configuration source to delete; typically one of startup|candidate Returns: None Raises: ScrapliValueError: if an invalid target was selected \"\"\" if target == \"running\" or target not in self . writeable_datastores : msg = f \"'target' should be one of { self . writeable_datastores } , got ' { target } '\" if target == \"running\" : msg = \"delete-config 'target' may not be 'running'\" self . logger . warning ( msg ) if self . strict_datastores is True : raise ScrapliValueError ( msg ) user_warning ( title = \"Invalid datastore target!\" , message = msg ) def _build_base_elem ( self ) -> _Element : \"\"\" Create base element for netconf operations Args: N/A Returns: _Element: lxml base element to use for netconf operation Raises: N/A \"\"\" # pylint did not seem to want to be ok with assigning this as a class attribute... and its # only used here so... here we are self . message_id : int # pylint: disable=W0201 self . logger . debug ( f \"Building base element for message id { self . message_id } \" ) base_xml_str = NetconfBaseOperations . RPC . value . format ( message_id = self . message_id ) self . message_id += 1 base_elem = etree . fromstring ( text = base_xml_str ) return base_elem def _build_filter ( self , filter_ : str , filter_type : str = \"subtree\" ) -> _Element : \"\"\" Create filter element for a given rpc The `filter_` string may contain multiple xml elements at its \"root\" (subtree filters); we will simply place the payload into a temporary \"tmp\" outer tag so that when we cast it to an etree object the elements are all preserved; without this outer \"tmp\" tag, lxml will scoop up only the first element provided as it appears to be the root of the document presumably. An example valid (to scrapli netconf at least) xml filter would be: ``` <interface-configurations xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-ifmgr-cfg\"> <interface-configuration> <active>act</active> </interface-configuration> </interface-configurations> <netconf-yang xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-man-netconf-cfg\"> </netconf-yang> ``` Args: filter_: strings of filters to build into a filter element or (for subtree) a full filter string (in filter tags) filter_type: type of filter; subtree|xpath Returns: _Element: lxml filter element to use for netconf operation Raises: CapabilityNotSupported: if xpath selected and not supported on server ScrapliValueError: if filter_type is not one of subtree|xpath \"\"\" if filter_type == \"subtree\" : # tmp tags to place the users kinda not valid xml filter into _filter_ = f \"<tmp> { filter_ } </tmp>\" # \"validate\" subtree filter by forcing it into xml, parser \"flattens\" it as well tmp_xml_filter_element = etree . fromstring ( _filter_ , parser = self . xml_parser ) if tmp_xml_filter_element . getchildren ()[ 0 ] . tag == \"filter\" : # if the user filter was already wrapped in filter tags we'll end up here, we will # blindly reuse the users filter but we'll make sure that the filter \"type\" is set xml_filter_elem = tmp_xml_filter_element . getchildren ()[ 0 ] xml_filter_elem . attrib [ \"type\" ] = \"subtree\" else : xml_filter_elem = etree . fromstring ( NetconfBaseOperations . FILTER_SUBTREE . value . format ( filter_type = filter_type ), ) # iterate through the children inside the tmp tags and insert *those* elements into # the actual final filter payload for xml_filter_element in tmp_xml_filter_element : # insert the subtree filter into the parent filter element xml_filter_elem . insert ( 1 , xml_filter_element ) elif filter_type == \"xpath\" : if \"urn:ietf:params:netconf:capability:xpath:1.0\" not in self . server_capabilities : msg = \"xpath filter requested, but is not supported by the server\" self . logger . exception ( msg ) raise CapabilityNotSupported ( msg ) xml_filter_elem = etree . fromstring ( NetconfBaseOperations . FILTER_XPATH . value . format ( filter_type = filter_type , xpath = filter_ ), parser = self . xml_parser , ) else : raise ScrapliValueError ( f \"'filter_type' should be one of subtree|xpath, got ' { filter_type } '\" ) return xml_filter_elem def _build_with_defaults ( self , default_type : str = \"report-all\" ) -> _Element : \"\"\" Create with-defaults element for a given operation Args: default_type: enumeration of with-defaults; report-all|trim|explicit|report-all-tagged Returns: _Element: lxml with-defaults element to use for netconf operation Raises: CapabilityNotSupported: if default_type provided but not supported by device ScrapliValueError: if default_type is not one of report-all|trim|explicit|report-all-tagged \"\"\" if default_type in [ \"report-all\" , \"trim\" , \"explicit\" , \"report-all-tagged\" ]: if ( \"urn:ietf:params:netconf:capability:with-defaults:1.0\" not in self . server_capabilities ): msg = \"with-defaults requested, but is not supported by the server\" self . logger . exception ( msg ) raise CapabilityNotSupported ( msg ) xml_with_defaults_element = etree . fromstring ( NetconfBaseOperations . WITH_DEFAULTS_SUBTREE . value . format ( default_type = default_type ), parser = self . xml_parser , ) else : raise ScrapliValueError ( \"'default_type' should be one of report-all|trim|explicit|report-all-tagged, \" f \"got ' { default_type } '\" ) return xml_with_defaults_element def _finalize_channel_input ( self , xml_request : _Element ) -> bytes : \"\"\" Create finalized channel input (as bytes) Args: xml_request: finalized xml element to cast to bytes and add declaration to Returns: bytes: finalized bytes input -- with 1.0 delimiter or 1.1 encoding Raises: N/A \"\"\" channel_input : bytes = etree . tostring ( element_or_tree = xml_request , xml_declaration = True , encoding = \"utf-8\" ) if self . netconf_version == NetconfVersion . VERSION_1_0 : channel_input = channel_input + b \"]]>]]>\" else : # format message for chunk (netconf 1.1) style message channel_input = b \"#%b \\n \" % str ( len ( channel_input )) . encode () + channel_input + b \" \\n ##\" return channel_input def _pre_get ( self , filter_ : str , filter_type : str = \"subtree\" ) -> NetconfResponse : \"\"\" Handle pre \"get\" tasks for consistency between sync/async versions *NOTE* The channel input (filter_) is loaded up as an lxml etree element here, this is done with a parser that removes whitespace. This has a somewhat undesirable effect of making any \"pretty\" input not pretty, however... after we load the xml object (which we do to validate that it is valid xml) we dump that xml object back to a string to be used as the actual raw payload we send down the channel, which means we are sending \"flattened\" (not pretty/ indented xml) to the device. This is important it seems! Some devices seme to not mind having the \"nicely\" formatted input (pretty xml). But! On devices that \"echo\" the inputs back -- sometimes the device will respond to our rpc without \"finishing\" echoing our inputs to the device, this breaks the core \"read until input\" processing that scrapli always does. For whatever reason if there are no line breaks this does not seem to happen? /shrug. Note that this comment applies to all of the \"pre\" methods that we parse a filter/payload! Args: filter_: string filter to apply to the get filter_type: type of filter; subtree|xpath Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( f \"Building payload for 'get' operation. filter_type: { filter_type } , filter_: { filter_ } \" ) # build base request and insert the get element xml_request = self . _build_base_elem () xml_get_element = etree . fromstring ( NetconfBaseOperations . GET . value ) xml_request . insert ( 0 , xml_get_element ) # build filter element xml_filter_elem = self . _build_filter ( filter_ = filter_ , filter_type = filter_type ) # insert filter element into parent get element get_element = xml_request . find ( \"get\" ) get_element . insert ( 0 , xml_filter_elem ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'get' operation. Payload: { channel_input . decode () } \" ) return response def _pre_get_config ( self , source : str = \"running\" , filter_ : Optional [ str ] = None , filter_type : str = \"subtree\" , default_type : Optional [ str ] = None , ) -> NetconfResponse : \"\"\" Handle pre \"get_config\" tasks for consistency between sync/async versions Args: source: configuration source to get; typically one of running|startup|candidate filter_: string of filter(s) to apply to configuration filter_type: type of filter; subtree|xpath default_type: string of with-default mode to apply when retrieving configuration Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( f \"Building payload for 'get-config' operation. source: { source } , filter_type: \" f \" { filter_type } , filter: { filter_ } , default_type: { default_type } \" ) self . _validate_get_config_target ( source = source ) # build base request and insert the get-config element xml_request = self . _build_base_elem () xml_get_config_element = etree . fromstring ( NetconfBaseOperations . GET_CONFIG . value . format ( source = source ), parser = self . xml_parser ) xml_request . insert ( 0 , xml_get_config_element ) if filter_ is not None : xml_filter_elem = self . _build_filter ( filter_ = filter_ , filter_type = filter_type ) # insert filter element into parent get element get_element = xml_request . find ( \"get-config\" ) # insert *after* source, otherwise juniper seems to gripe, maybe/probably others as well get_element . insert ( 1 , xml_filter_elem ) if default_type is not None : xml_with_defaults_elem = self . _build_with_defaults ( default_type = default_type ) get_element = xml_request . find ( \"get-config\" ) get_element . insert ( 2 , xml_with_defaults_elem ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'get-config' operation. Payload: { channel_input . decode () } \" ) return response def _pre_edit_config ( self , config : str , target : str = \"running\" ) -> NetconfResponse : \"\"\" Handle pre \"edit_config\" tasks for consistency between sync/async versions Args: config: configuration to send to device target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( f \"Building payload for 'edit-config' operation. target: { target } , config: { config } \" ) self . _validate_edit_config_target ( target = target ) xml_config = etree . fromstring ( config , parser = self . xml_parser ) # build base request and insert the edit-config element xml_request = self . _build_base_elem () xml_edit_config_element = etree . fromstring ( NetconfBaseOperations . EDIT_CONFIG . value . format ( target = target ) ) xml_request . insert ( 0 , xml_edit_config_element ) # insert parent filter element to first position so that target stays first just for nice # output/readability edit_config_element = xml_request . find ( \"edit-config\" ) edit_config_element . insert ( 1 , xml_config ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'edit-config' operation. Payload: { channel_input . decode () } \" ) return response def _pre_delete_config ( self , target : str = \"running\" ) -> NetconfResponse : \"\"\" Handle pre \"edit_config\" tasks for consistency between sync/async versions Args: target: configuration source to target; startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( f \"Building payload for 'delete-config' operation. target: { target } \" ) self . _validate_delete_config_target ( target = target ) xml_request = self . _build_base_elem () xml_validate_element = etree . fromstring ( NetconfBaseOperations . DELETE_CONFIG . value . format ( target = target ), parser = self . xml_parser ) xml_request . insert ( 0 , xml_validate_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'delete-config' operation. Payload: { channel_input . decode () } \" ) return response def _pre_commit ( self , confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None , ) -> NetconfResponse : \"\"\" Handle pre \"commit\" tasks for consistency between sync/async versions Args: confirmed: whether this is a confirmed commit timeout: specifies the confirm timeout in seconds persist: make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit persist_id: value must be equal to the value given in the <persist> parameter to the original <commit> operation. Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: ScrapliValueError: if persist and persist_id are provided (cannot combine) ScrapliValueError: if confirmed and persist_id are provided (cannot combine) CapabilityNotSupported: if device does not have confirmed-commit capability \"\"\" self . logger . debug ( \"Building payload for 'commit' operation\" ) xml_request = self . _build_base_elem () xml_commit_element = etree . fromstring ( NetconfBaseOperations . COMMIT . value , parser = self . xml_parser ) if persist and persist_id : raise ScrapliValueError ( \"Invalid combination - 'persist' cannot be present with 'persist-id'\" ) if confirmed and persist_id : raise ScrapliValueError ( \"Invalid combination - 'confirmed' cannot be present with 'persist-id'\" ) if confirmed or persist_id : if not any ( cap in self . server_capabilities for cap in ( \"urn:ietf:params:netconf:capability:confirmed-commit:1.0\" , \"urn:ietf:params:netconf:capability:confirmed-commit:1.1\" , ) ): msg = \"confirmed-commit requested, but is not supported by the server\" self . logger . exception ( msg ) raise CapabilityNotSupported ( msg ) if confirmed : xml_confirmed_element = etree . fromstring ( NetconfBaseOperations . COMMIT_CONFIRMED . value , parser = self . xml_parser ) xml_commit_element . append ( xml_confirmed_element ) if timeout is not None : xml_timeout_element = etree . fromstring ( NetconfBaseOperations . COMMIT_CONFIRMED_TIMEOUT . value . format ( timeout = timeout ), parser = self . xml_parser , ) xml_commit_element . append ( xml_timeout_element ) if persist is not None : xml_persist_element = etree . fromstring ( NetconfBaseOperations . COMMIT_CONFIRMED_PERSIST . value . format ( persist = persist ), parser = self . xml_parser , ) xml_commit_element . append ( xml_persist_element ) if persist_id is not None : xml_persist_id_element = etree . fromstring ( NetconfBaseOperations . COMMIT_PERSIST_ID . value . format ( persist_id = persist_id ), parser = self . xml_parser , ) xml_commit_element . append ( xml_persist_id_element ) xml_request . insert ( 0 , xml_commit_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'commit' operation. Payload: { channel_input . decode () } \" ) return response def _pre_discard ( self ) -> NetconfResponse : \"\"\" Handle pre \"discard\" tasks for consistency between sync/async versions Args: N/A Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( \"Building payload for 'discard' operation.\" ) xml_request = self . _build_base_elem () xml_commit_element = etree . fromstring ( NetconfBaseOperations . DISCARD . value , parser = self . xml_parser ) xml_request . insert ( 0 , xml_commit_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'discard' operation. Payload: { channel_input . decode () } \" ) return response def _pre_lock ( self , target : str ) -> NetconfResponse : \"\"\" Handle pre \"lock\" tasks for consistency between sync/async versions Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( \"Building payload for 'lock' operation.\" ) self . _validate_edit_config_target ( target = target ) xml_request = self . _build_base_elem () xml_lock_element = etree . fromstring ( NetconfBaseOperations . LOCK . value . format ( target = target ), parser = self . xml_parser ) xml_request . insert ( 0 , xml_lock_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'lock' operation. Payload: { channel_input . decode () } \" ) return response def _pre_unlock ( self , target : str ) -> NetconfResponse : \"\"\" Handle pre \"unlock\" tasks for consistency between sync/async versions Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( \"Building payload for 'unlock' operation.\" ) self . _validate_edit_config_target ( target = target ) xml_request = self . _build_base_elem () xml_lock_element = etree . fromstring ( NetconfBaseOperations . UNLOCK . value . format ( target = target ), parser = self . xml_parser ) xml_request . insert ( 0 , xml_lock_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'unlock' operation. Payload: { channel_input . decode () } \" ) return response def _pre_rpc ( self , filter_ : Union [ str , _Element ]) -> NetconfResponse : \"\"\" Handle pre \"rpc\" tasks for consistency between sync/async versions Args: filter_: filter/rpc to execute Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( \"Building payload for 'rpc' operation.\" ) xml_request = self . _build_base_elem () # build filter element if isinstance ( filter_ , str ): xml_filter_elem = etree . fromstring ( filter_ , parser = self . xml_parser ) else : xml_filter_elem = filter_ # insert filter element xml_request . insert ( 0 , xml_filter_elem ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'rpc' operation. Payload: { channel_input . decode () } \" ) return response def _pre_validate ( self , source : str ) -> NetconfResponse : \"\"\" Handle pre \"validate\" tasks for consistency between sync/async versions Args: source: configuration source to validate; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: CapabilityNotSupported: if 'validate' capability does not exist \"\"\" self . logger . debug ( \"Building payload for 'validate' operation.\" ) if not any ( cap in self . server_capabilities for cap in ( \"urn:ietf:params:netconf:capability:validate:1.0\" , \"urn:ietf:params:netconf:capability:validate:1.1\" , ) ): msg = \"validate requested, but is not supported by the server\" self . logger . exception ( msg ) raise CapabilityNotSupported ( msg ) self . _validate_edit_config_target ( target = source ) xml_request = self . _build_base_elem () xml_validate_element = etree . fromstring ( NetconfBaseOperations . VALIDATE . value . format ( source = source ), parser = self . xml_parser ) xml_request . insert ( 0 , xml_validate_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'validate' operation. Payload: { channel_input . decode () } \" ) return response def _pre_copy_config ( self , source : str , target : str ) -> NetconfResponse : \"\"\" Handle pre \"copy_config\" tasks for consistency between sync/async versions Note that source is not validated/checked since it could be a url or a full configuration element itself. Args: source: configuration, url, or datastore to copy into the target datastore target: copy config destination/target; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object containing all the necessary channel inputs (string and xml) Raises: N/A \"\"\" self . logger . debug ( \"Building payload for 'copy_config' operation.\" ) self . _validate_edit_config_target ( target = target ) xml_request = self . _build_base_elem () xml_validate_element = etree . fromstring ( NetconfBaseOperations . COPY_CONFIG . value . format ( source = source , target = target ), parser = self . xml_parser , ) xml_request . insert ( 0 , xml_validate_element ) channel_input = self . _finalize_channel_input ( xml_request = xml_request ) response = NetconfResponse ( host = self . host , channel_input = channel_input . decode (), xml_input = xml_request , netconf_version = self . netconf_version , strip_namespaces = self . strip_namespaces , ) self . logger . debug ( f \"Built payload for 'copy-config' operation. Payload: { channel_input . decode () } \" ) return response","title":"NetconfBaseDriver"},{"location":"reference/driver/base_driver/#driver.base_driver.NetconfBaseDriver.client_capabilities","text":"Getter for 'client_capabilities' attribute Returns: Name Type Description NetconfClientCapabilities NetconfClientCapabilities netconf client capabilities enum Source code in driver/base_driver.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 @property def client_capabilities ( self ) -> NetconfClientCapabilities : \"\"\" Getter for 'client_capabilities' attribute Args: N/A Returns: NetconfClientCapabilities: netconf client capabilities enum Raises: N/A \"\"\" return self . _netconf_base_channel_args . client_capabilities","title":"client_capabilities()"},{"location":"reference/driver/base_driver/#driver.base_driver.NetconfBaseDriver.netconf_version","text":"Getter for 'netconf_version' attribute Returns: Name Type Description NetconfVersion NetconfVersion netconf_version enum Source code in driver/base_driver.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 @property def netconf_version ( self ) -> NetconfVersion : \"\"\" Getter for 'netconf_version' attribute Args: N/A Returns: NetconfVersion: netconf_version enum Raises: N/A \"\"\" return self . _netconf_base_channel_args . netconf_version","title":"netconf_version()"},{"location":"reference/driver/base_driver/#driver.base_driver.NetconfBaseDriver.server_capabilities","text":"Getter for 'server_capabilities' attribute Returns: Name Type Description list List [ str ] list of strings of server capabilities Source code in driver/base_driver.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 @property def server_capabilities ( self ) -> List [ str ]: \"\"\" Getter for 'server_capabilities' attribute Args: N/A Returns: list: list of strings of server capabilities Raises: N/A \"\"\" return self . _netconf_base_channel_args . server_capabilities or []","title":"server_capabilities()"},{"location":"reference/driver/base_driver/#driver.base_driver.NetconfBaseDriver.xml_parser","text":"Getter for 'xml_parser' attribute Returns: Type Description etree . XMLParser etree.XMLParser: parser to use for parsing xml documents Source code in driver/base_driver.py 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 @property def xml_parser ( self ) -> etree . XMLParser : \"\"\" Getter for 'xml_parser' attribute Args: N/A Returns: etree.XMLParser: parser to use for parsing xml documents Raises: N/A \"\"\" if self . _netconf_base_channel_args . xml_parser == XmlParserVersion . COMPRESSED_PARSER : return COMPRESSED_PARSER return STANDARD_PARSER","title":"xml_parser()"},{"location":"reference/driver/sync_driver/","text":"scrapli_netconf.driver.sync_driver NetconfDriver \u00b6 Bases: Driver , NetconfBaseDriver Source code in driver/sync_driver.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 class NetconfDriver ( Driver , NetconfBaseDriver ): # kinda hate this but need to tell mypy that channel in netconf land is in fact a channel of # type `NetconfChannel` channel : NetconfChannel def __init__ ( self , host : str , port : int = 830 , strip_namespaces : bool = False , strict_datastores : bool = False , auth_username : str = \"\" , auth_password : str = \"\" , auth_private_key : str = \"\" , auth_private_key_passphrase : str = \"\" , auth_strict_key : bool = True , auth_bypass : bool = False , timeout_socket : float = 15.0 , timeout_transport : float = 30.0 , timeout_ops : float = 30.0 , comms_prompt_pattern : str = r \"^[a-z0-9.\\-@()/:]{1,48}[#>$]\\s*$\" , comms_return_char : str = \" \\n \" , ssh_config_file : Union [ str , bool ] = False , ssh_known_hosts_file : Union [ str , bool ] = False , on_init : Optional [ Callable [ ... , Any ]] = None , on_open : Optional [ Callable [ ... , Any ]] = None , on_close : Optional [ Callable [ ... , Any ]] = None , transport : str = \"system\" , transport_options : Optional [ Dict [ str , Any ]] = None , channel_log : Union [ str , bool ] = False , channel_lock : bool = False , preferred_netconf_version : Optional [ str ] = None , use_compressed_parser : bool = True , ) -> None : super () . __init__ ( host = host , port = port , auth_username = auth_username , auth_password = auth_password , auth_private_key = auth_private_key , auth_private_key_passphrase = auth_private_key_passphrase , auth_strict_key = auth_strict_key , auth_bypass = auth_bypass , timeout_socket = timeout_socket , timeout_transport = timeout_transport , timeout_ops = timeout_ops , comms_prompt_pattern = comms_prompt_pattern , comms_return_char = comms_return_char , ssh_config_file = ssh_config_file , ssh_known_hosts_file = ssh_known_hosts_file , on_init = on_init , on_open = on_open , on_close = on_close , transport = transport , transport_options = transport_options , channel_log = channel_log , channel_lock = channel_lock , ) _preferred_netconf_version = self . _determine_preferred_netconf_version ( preferred_netconf_version = preferred_netconf_version ) _preferred_xml_parser = self . _determine_preferred_xml_parser ( use_compressed_parser = use_compressed_parser ) self . _netconf_base_channel_args = NetconfBaseChannelArgs ( netconf_version = _preferred_netconf_version , xml_parser = _preferred_xml_parser ) self . channel = NetconfChannel ( transport = self . transport , base_channel_args = self . _base_channel_args , netconf_base_channel_args = self . _netconf_base_channel_args , ) self . strip_namespaces = strip_namespaces self . strict_datastores = strict_datastores self . server_capabilities : List [ str ] = [] self . readable_datastores : List [ str ] = [] self . writeable_datastores : List [ str ] = [] self . message_id = 101 def open ( self ) -> None : \"\"\" Open netconf connection to server Args: N/A Returns: None Raises: N/A \"\"\" self . _pre_open_closing_log ( closing = False ) self . transport . open_netconf () # in the future this and scrapli core should just have a class attribute of the transports # that require this \"in channel\" auth so we can dynamically figure that out rather than # just look at the name of the transport if \"system\" in self . transport_name : self . channel . channel_authenticate_netconf ( auth_password = self . auth_password , auth_private_key_passphrase = self . auth_private_key_passphrase , ) self . channel . open_netconf () self . _build_readable_datastores () self . _build_writeable_datastores () self . _post_open_closing_log ( closing = False ) def get ( self , filter_ : str , filter_type : str = \"subtree\" ) -> NetconfResponse : \"\"\" Netconf get operation Args: filter_: filter to apply to the get filter_type: type of filter; subtree|xpath Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get ( filter_ = filter_ , filter_type = filter_type ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def get_config ( self , source : str = \"running\" , filter_ : Optional [ str ] = None , filter_type : str = \"subtree\" , default_type : Optional [ str ] = None , ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: source: configuration source to get; typically one of running|startup|candidate filter_: string of filter(s) to apply to configuration filter_type: type of filter; subtree|xpath default_type: string of with-default mode to apply when retrieving configuration Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get_config ( source = source , filter_ = filter_ , filter_type = filter_type , default_type = default_type ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def edit_config ( self , config : str , target : str = \"running\" ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: config: configuration to send to device target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_edit_config ( config = config , target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def delete_config ( self , target : str = \"candidate\" ) -> NetconfResponse : \"\"\" Netconf delete-config operation Args: target: configuration source to target; startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_delete_config ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def commit ( self , confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None , ) -> NetconfResponse : \"\"\" Netconf commit config operation Args: confirmed: whether this is a confirmed commit timeout: specifies the confirm timeout in seconds persist: make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit persist_id: value must be equal to the value given in the <persist> parameter to the original <commit> operation. Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_commit ( confirmed = confirmed , timeout = timeout , persist = persist , persist_id = persist_id , ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def discard ( self ) -> NetconfResponse : \"\"\" Netconf discard config operation Args: N/A Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_discard () raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def lock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf lock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_lock ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def unlock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf unlock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_unlock ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def rpc ( self , filter_ : Union [ str , _Element ]) -> NetconfResponse : \"\"\" Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Args: filter_: filter/rpc to execute Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_rpc ( filter_ = filter_ ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def validate ( self , source : str ) -> NetconfResponse : \"\"\" Netconf \"validate\" operation Args: source: configuration source to validate; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_validate ( source = source ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def copy_config ( self , source : str , target : str ) -> NetconfResponse : \"\"\" Netconf \"copy-config\" operation Args: source: configuration, url, or datastore to copy into the target datastore target: destination to copy the source to Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_copy_config ( source = source , target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response commit ( confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None ) -> NetconfResponse \u00b6 Netconf commit config operation Parameters: Name Type Description Default confirmed bool whether this is a confirmed commit False timeout Optional [ int ] specifies the confirm timeout in seconds None persist Optional [ Union [ int , str ]] make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit None persist_id Optional [ Union [ int , str ]] value must be equal to the value given in the parameter to the original operation. None Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def commit ( self , confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None , ) -> NetconfResponse : \"\"\" Netconf commit config operation Args: confirmed: whether this is a confirmed commit timeout: specifies the confirm timeout in seconds persist: make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit persist_id: value must be equal to the value given in the <persist> parameter to the original <commit> operation. Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_commit ( confirmed = confirmed , timeout = timeout , persist = persist , persist_id = persist_id , ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response copy_config ( source : str , target : str ) -> NetconfResponse \u00b6 Netconf \"copy-config\" operation Parameters: Name Type Description Default source str configuration, url, or datastore to copy into the target datastore required target str destination to copy the source to required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 def copy_config ( self , source : str , target : str ) -> NetconfResponse : \"\"\" Netconf \"copy-config\" operation Args: source: configuration, url, or datastore to copy into the target datastore target: destination to copy the source to Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_copy_config ( source = source , target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response delete_config ( target : str = 'candidate' ) -> NetconfResponse \u00b6 Netconf delete-config operation Parameters: Name Type Description Default target str configuration source to target; startup|candidate 'candidate' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 def delete_config ( self , target : str = \"candidate\" ) -> NetconfResponse : \"\"\" Netconf delete-config operation Args: target: configuration source to target; startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_delete_config ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response discard () -> NetconfResponse \u00b6 Netconf discard config operation Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def discard ( self ) -> NetconfResponse : \"\"\" Netconf discard config operation Args: N/A Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_discard () raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response edit_config ( config : str , target : str = 'running' ) -> NetconfResponse \u00b6 Netconf get-config operation Parameters: Name Type Description Default config str configuration to send to device required target str configuration source to target; running|startup|candidate 'running' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 def edit_config ( self , config : str , target : str = \"running\" ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: config: configuration to send to device target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_edit_config ( config = config , target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response get ( filter_ : str , filter_type : str = 'subtree' ) -> NetconfResponse \u00b6 Netconf get operation Parameters: Name Type Description Default filter_ str filter to apply to the get required filter_type str type of filter; subtree|xpath 'subtree' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def get ( self , filter_ : str , filter_type : str = \"subtree\" ) -> NetconfResponse : \"\"\" Netconf get operation Args: filter_: filter to apply to the get filter_type: type of filter; subtree|xpath Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get ( filter_ = filter_ , filter_type = filter_type ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response get_config ( source : str = 'running' , filter_ : Optional [ str ] = None , filter_type : str = 'subtree' , default_type : Optional [ str ] = None ) -> NetconfResponse \u00b6 Netconf get-config operation Parameters: Name Type Description Default source str configuration source to get; typically one of running|startup|candidate 'running' filter_ Optional [ str ] string of filter(s) to apply to configuration None filter_type str type of filter; subtree|xpath 'subtree' default_type Optional [ str ] string of with-default mode to apply when retrieving configuration None Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def get_config ( self , source : str = \"running\" , filter_ : Optional [ str ] = None , filter_type : str = \"subtree\" , default_type : Optional [ str ] = None , ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: source: configuration source to get; typically one of running|startup|candidate filter_: string of filter(s) to apply to configuration filter_type: type of filter; subtree|xpath default_type: string of with-default mode to apply when retrieving configuration Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get_config ( source = source , filter_ = filter_ , filter_type = filter_type , default_type = default_type ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response lock ( target : str ) -> NetconfResponse \u00b6 Netconf lock operation Parameters: Name Type Description Default target str configuration source to target; running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 def lock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf lock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_lock ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response open () -> None \u00b6 Open netconf connection to server Returns: Type Description None None Source code in driver/sync_driver.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def open ( self ) -> None : \"\"\" Open netconf connection to server Args: N/A Returns: None Raises: N/A \"\"\" self . _pre_open_closing_log ( closing = False ) self . transport . open_netconf () # in the future this and scrapli core should just have a class attribute of the transports # that require this \"in channel\" auth so we can dynamically figure that out rather than # just look at the name of the transport if \"system\" in self . transport_name : self . channel . channel_authenticate_netconf ( auth_password = self . auth_password , auth_private_key_passphrase = self . auth_private_key_passphrase , ) self . channel . open_netconf () self . _build_readable_datastores () self . _build_writeable_datastores () self . _post_open_closing_log ( closing = False ) rpc ( filter_ : Union [ str , _Element ]) -> NetconfResponse \u00b6 Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Parameters: Name Type Description Default filter_ Union [ str , _Element ] filter/rpc to execute required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def rpc ( self , filter_ : Union [ str , _Element ]) -> NetconfResponse : \"\"\" Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Args: filter_: filter/rpc to execute Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_rpc ( filter_ = filter_ ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response unlock ( target : str ) -> NetconfResponse \u00b6 Netconf unlock operation Parameters: Name Type Description Default target str configuration source to target; running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 def unlock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf unlock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_unlock ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response validate ( source : str ) -> NetconfResponse \u00b6 Netconf \"validate\" operation Parameters: Name Type Description Default source str configuration source to validate; typically one of running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 def validate ( self , source : str ) -> NetconfResponse : \"\"\" Netconf \"validate\" operation Args: source: configuration source to validate; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_validate ( source = source ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"sync_driver"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver","text":"Bases: Driver , NetconfBaseDriver Source code in driver/sync_driver.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 class NetconfDriver ( Driver , NetconfBaseDriver ): # kinda hate this but need to tell mypy that channel in netconf land is in fact a channel of # type `NetconfChannel` channel : NetconfChannel def __init__ ( self , host : str , port : int = 830 , strip_namespaces : bool = False , strict_datastores : bool = False , auth_username : str = \"\" , auth_password : str = \"\" , auth_private_key : str = \"\" , auth_private_key_passphrase : str = \"\" , auth_strict_key : bool = True , auth_bypass : bool = False , timeout_socket : float = 15.0 , timeout_transport : float = 30.0 , timeout_ops : float = 30.0 , comms_prompt_pattern : str = r \"^[a-z0-9.\\-@()/:]{1,48}[#>$]\\s*$\" , comms_return_char : str = \" \\n \" , ssh_config_file : Union [ str , bool ] = False , ssh_known_hosts_file : Union [ str , bool ] = False , on_init : Optional [ Callable [ ... , Any ]] = None , on_open : Optional [ Callable [ ... , Any ]] = None , on_close : Optional [ Callable [ ... , Any ]] = None , transport : str = \"system\" , transport_options : Optional [ Dict [ str , Any ]] = None , channel_log : Union [ str , bool ] = False , channel_lock : bool = False , preferred_netconf_version : Optional [ str ] = None , use_compressed_parser : bool = True , ) -> None : super () . __init__ ( host = host , port = port , auth_username = auth_username , auth_password = auth_password , auth_private_key = auth_private_key , auth_private_key_passphrase = auth_private_key_passphrase , auth_strict_key = auth_strict_key , auth_bypass = auth_bypass , timeout_socket = timeout_socket , timeout_transport = timeout_transport , timeout_ops = timeout_ops , comms_prompt_pattern = comms_prompt_pattern , comms_return_char = comms_return_char , ssh_config_file = ssh_config_file , ssh_known_hosts_file = ssh_known_hosts_file , on_init = on_init , on_open = on_open , on_close = on_close , transport = transport , transport_options = transport_options , channel_log = channel_log , channel_lock = channel_lock , ) _preferred_netconf_version = self . _determine_preferred_netconf_version ( preferred_netconf_version = preferred_netconf_version ) _preferred_xml_parser = self . _determine_preferred_xml_parser ( use_compressed_parser = use_compressed_parser ) self . _netconf_base_channel_args = NetconfBaseChannelArgs ( netconf_version = _preferred_netconf_version , xml_parser = _preferred_xml_parser ) self . channel = NetconfChannel ( transport = self . transport , base_channel_args = self . _base_channel_args , netconf_base_channel_args = self . _netconf_base_channel_args , ) self . strip_namespaces = strip_namespaces self . strict_datastores = strict_datastores self . server_capabilities : List [ str ] = [] self . readable_datastores : List [ str ] = [] self . writeable_datastores : List [ str ] = [] self . message_id = 101 def open ( self ) -> None : \"\"\" Open netconf connection to server Args: N/A Returns: None Raises: N/A \"\"\" self . _pre_open_closing_log ( closing = False ) self . transport . open_netconf () # in the future this and scrapli core should just have a class attribute of the transports # that require this \"in channel\" auth so we can dynamically figure that out rather than # just look at the name of the transport if \"system\" in self . transport_name : self . channel . channel_authenticate_netconf ( auth_password = self . auth_password , auth_private_key_passphrase = self . auth_private_key_passphrase , ) self . channel . open_netconf () self . _build_readable_datastores () self . _build_writeable_datastores () self . _post_open_closing_log ( closing = False ) def get ( self , filter_ : str , filter_type : str = \"subtree\" ) -> NetconfResponse : \"\"\" Netconf get operation Args: filter_: filter to apply to the get filter_type: type of filter; subtree|xpath Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get ( filter_ = filter_ , filter_type = filter_type ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def get_config ( self , source : str = \"running\" , filter_ : Optional [ str ] = None , filter_type : str = \"subtree\" , default_type : Optional [ str ] = None , ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: source: configuration source to get; typically one of running|startup|candidate filter_: string of filter(s) to apply to configuration filter_type: type of filter; subtree|xpath default_type: string of with-default mode to apply when retrieving configuration Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get_config ( source = source , filter_ = filter_ , filter_type = filter_type , default_type = default_type ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def edit_config ( self , config : str , target : str = \"running\" ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: config: configuration to send to device target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_edit_config ( config = config , target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def delete_config ( self , target : str = \"candidate\" ) -> NetconfResponse : \"\"\" Netconf delete-config operation Args: target: configuration source to target; startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_delete_config ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def commit ( self , confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None , ) -> NetconfResponse : \"\"\" Netconf commit config operation Args: confirmed: whether this is a confirmed commit timeout: specifies the confirm timeout in seconds persist: make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit persist_id: value must be equal to the value given in the <persist> parameter to the original <commit> operation. Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_commit ( confirmed = confirmed , timeout = timeout , persist = persist , persist_id = persist_id , ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def discard ( self ) -> NetconfResponse : \"\"\" Netconf discard config operation Args: N/A Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_discard () raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def lock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf lock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_lock ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def unlock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf unlock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_unlock ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def rpc ( self , filter_ : Union [ str , _Element ]) -> NetconfResponse : \"\"\" Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Args: filter_: filter/rpc to execute Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_rpc ( filter_ = filter_ ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def validate ( self , source : str ) -> NetconfResponse : \"\"\" Netconf \"validate\" operation Args: source: configuration source to validate; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_validate ( source = source ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response def copy_config ( self , source : str , target : str ) -> NetconfResponse : \"\"\" Netconf \"copy-config\" operation Args: source: configuration, url, or datastore to copy into the target datastore target: destination to copy the source to Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_copy_config ( source = source , target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"NetconfDriver"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.commit","text":"Netconf commit config operation Parameters: Name Type Description Default confirmed bool whether this is a confirmed commit False timeout Optional [ int ] specifies the confirm timeout in seconds None persist Optional [ Union [ int , str ]] make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit None persist_id Optional [ Union [ int , str ]] value must be equal to the value given in the parameter to the original operation. None Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def commit ( self , confirmed : bool = False , timeout : Optional [ int ] = None , persist : Optional [ Union [ int , str ]] = None , persist_id : Optional [ Union [ int , str ]] = None , ) -> NetconfResponse : \"\"\" Netconf commit config operation Args: confirmed: whether this is a confirmed commit timeout: specifies the confirm timeout in seconds persist: make the confirmed commit survive a session termination, and set a token on the ongoing confirmed commit persist_id: value must be equal to the value given in the <persist> parameter to the original <commit> operation. Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_commit ( confirmed = confirmed , timeout = timeout , persist = persist , persist_id = persist_id , ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"commit()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.copy_config","text":"Netconf \"copy-config\" operation Parameters: Name Type Description Default source str configuration, url, or datastore to copy into the target datastore required target str destination to copy the source to required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 def copy_config ( self , source : str , target : str ) -> NetconfResponse : \"\"\" Netconf \"copy-config\" operation Args: source: configuration, url, or datastore to copy into the target datastore target: destination to copy the source to Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_copy_config ( source = source , target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"copy_config()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.delete_config","text":"Netconf delete-config operation Parameters: Name Type Description Default target str configuration source to target; startup|candidate 'candidate' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 def delete_config ( self , target : str = \"candidate\" ) -> NetconfResponse : \"\"\" Netconf delete-config operation Args: target: configuration source to target; startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_delete_config ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"delete_config()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.discard","text":"Netconf discard config operation Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def discard ( self ) -> NetconfResponse : \"\"\" Netconf discard config operation Args: N/A Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_discard () raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"discard()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.edit_config","text":"Netconf get-config operation Parameters: Name Type Description Default config str configuration to send to device required target str configuration source to target; running|startup|candidate 'running' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 def edit_config ( self , config : str , target : str = \"running\" ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: config: configuration to send to device target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_edit_config ( config = config , target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"edit_config()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.get","text":"Netconf get operation Parameters: Name Type Description Default filter_ str filter to apply to the get required filter_type str type of filter; subtree|xpath 'subtree' Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def get ( self , filter_ : str , filter_type : str = \"subtree\" ) -> NetconfResponse : \"\"\" Netconf get operation Args: filter_: filter to apply to the get filter_type: type of filter; subtree|xpath Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get ( filter_ = filter_ , filter_type = filter_type ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"get()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.get_config","text":"Netconf get-config operation Parameters: Name Type Description Default source str configuration source to get; typically one of running|startup|candidate 'running' filter_ Optional [ str ] string of filter(s) to apply to configuration None filter_type str type of filter; subtree|xpath 'subtree' default_type Optional [ str ] string of with-default mode to apply when retrieving configuration None Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 def get_config ( self , source : str = \"running\" , filter_ : Optional [ str ] = None , filter_type : str = \"subtree\" , default_type : Optional [ str ] = None , ) -> NetconfResponse : \"\"\" Netconf get-config operation Args: source: configuration source to get; typically one of running|startup|candidate filter_: string of filter(s) to apply to configuration filter_type: type of filter; subtree|xpath default_type: string of with-default mode to apply when retrieving configuration Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_get_config ( source = source , filter_ = filter_ , filter_type = filter_type , default_type = default_type ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"get_config()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.lock","text":"Netconf lock operation Parameters: Name Type Description Default target str configuration source to target; running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 def lock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf lock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_lock ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"lock()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.open","text":"Open netconf connection to server Returns: Type Description None None Source code in driver/sync_driver.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def open ( self ) -> None : \"\"\" Open netconf connection to server Args: N/A Returns: None Raises: N/A \"\"\" self . _pre_open_closing_log ( closing = False ) self . transport . open_netconf () # in the future this and scrapli core should just have a class attribute of the transports # that require this \"in channel\" auth so we can dynamically figure that out rather than # just look at the name of the transport if \"system\" in self . transport_name : self . channel . channel_authenticate_netconf ( auth_password = self . auth_password , auth_private_key_passphrase = self . auth_private_key_passphrase , ) self . channel . open_netconf () self . _build_readable_datastores () self . _build_writeable_datastores () self . _post_open_closing_log ( closing = False )","title":"open()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.rpc","text":"Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Parameters: Name Type Description Default filter_ Union [ str , _Element ] filter/rpc to execute required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def rpc ( self , filter_ : Union [ str , _Element ]) -> NetconfResponse : \"\"\" Netconf \"rpc\" operation Typically used with juniper devices or if you want to build/send your own payload in a more manual fashion. You can provide a string that will be loaded as an lxml element, or you can provide an lxml element yourself. Args: filter_: filter/rpc to execute Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_rpc ( filter_ = filter_ ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"rpc()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.unlock","text":"Netconf unlock operation Parameters: Name Type Description Default target str configuration source to target; running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 def unlock ( self , target : str ) -> NetconfResponse : \"\"\" Netconf unlock operation Args: target: configuration source to target; running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_unlock ( target = target ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"unlock()"},{"location":"reference/driver/sync_driver/#driver.sync_driver.NetconfDriver.validate","text":"Netconf \"validate\" operation Parameters: Name Type Description Default source str configuration source to validate; typically one of running|startup|candidate required Returns: Name Type Description NetconfResponse NetconfResponse scrapli_netconf NetconfResponse object Source code in driver/sync_driver.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 def validate ( self , source : str ) -> NetconfResponse : \"\"\" Netconf \"validate\" operation Args: source: configuration source to validate; typically one of running|startup|candidate Returns: NetconfResponse: scrapli_netconf NetconfResponse object Raises: N/A \"\"\" response = self . _pre_validate ( source = source ) raw_response = self . channel . send_input_netconf ( response . channel_input ) response . record_response ( raw_response ) return response","title":"validate()"},{"location":"reference/transport/","text":"scrapli_netconf.transport","title":"transport"},{"location":"reference/transport/plugins/","text":"scrapli_netconf.transport.plugins","title":"plugins"},{"location":"reference/transport/plugins/asyncssh/","text":"scrapli_netconf.transport.plugins.asyncssh","title":"asyncssh"},{"location":"reference/transport/plugins/asyncssh/transport/","text":"scrapli_netconf.transport.plugins.asyncssh.transport NetconfAsyncsshTransport \u00b6 Bases: AsyncsshTransport Source code in transport/plugins/asyncssh/transport.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class NetconfAsyncsshTransport ( AsyncsshTransport ): async def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: ScrapliAuthenticationFailed: if auth fails ScrapliConnectionNotOpened: if connection cant be opened (but is not an auth failure) \"\"\" if self . plugin_transport_args . auth_strict_key : self . logger . debug ( f \"Attempting to validate { self . _base_transport_args . host } public key is in known \" f \"hosts\" ) self . _verify_key () # we already fetched host/port/user from the user input and/or the ssh config file, so we # want to use those explicitly. likewise we pass config file we already found. set known # hosts and agent to None so we can not have an agent and deal w/ known hosts ourselves common_args = { \"host\" : self . _base_transport_args . host , \"port\" : self . _base_transport_args . port , \"username\" : self . plugin_transport_args . auth_username , \"known_hosts\" : None , \"agent_path\" : None , \"config\" : self . plugin_transport_args . ssh_config_file , } try : self . session : SSHClientConnection = await asyncio . wait_for ( connect ( client_keys = self . plugin_transport_args . auth_private_key , password = self . plugin_transport_args . auth_password , preferred_auth = ( \"publickey\" , \"keyboard-interactive\" , \"password\" , ), ** common_args , ), timeout = self . _base_transport_args . timeout_socket , ) except PermissionDenied as exc : msg = \"all authentication methods failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) from exc except asyncio . TimeoutError as exc : msg = \"timed out opening connection to device\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) from exc # it seems we must pass a terminal type to force a pty(?) which i think we want in like... # every case?? https://invisible-island.net/ncurses/ncurses.faq.html#xterm_color # set encoding to None so we get bytes for consistency w/ other scrapli transports # request_pty seems to be safe to set to \"false\" but leaving it at auto which seems closer # to the default behavior. With this omitted (as was previously) connecting to junos devices # on port 830 worked w/ system transport but *not* asyncssh because the pty request failed try : self . stdin , self . stdout , _ = await self . session . open_session ( term_type = \"xterm\" , encoding = None , subsystem = \"netconf\" , request_pty = \"auto\" ) except ChannelOpenError as exc : msg = ( \"Failed to open Channel -- do you have the right port? Most often the netconf \" \"port is 22 or 830!\" ) self . logger . critical ( msg ) raise ScrapliConnectionNotOpened ( msg ) from exc if not self . session : raise ScrapliConnectionNotOpened if self . plugin_transport_args . auth_strict_key : self . logger . debug ( f \"Attempting to validate { self . _base_transport_args . host } public key is in known \" f \"hosts and is valid\" ) self . _verify_key_value () open_netconf () -> None async \u00b6 Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Returns: Type Description None None Raises: Type Description ScrapliAuthenticationFailed if auth fails ScrapliConnectionNotOpened if connection cant be opened (but is not an auth failure) Source code in transport/plugins/asyncssh/transport.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 async def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: ScrapliAuthenticationFailed: if auth fails ScrapliConnectionNotOpened: if connection cant be opened (but is not an auth failure) \"\"\" if self . plugin_transport_args . auth_strict_key : self . logger . debug ( f \"Attempting to validate { self . _base_transport_args . host } public key is in known \" f \"hosts\" ) self . _verify_key () # we already fetched host/port/user from the user input and/or the ssh config file, so we # want to use those explicitly. likewise we pass config file we already found. set known # hosts and agent to None so we can not have an agent and deal w/ known hosts ourselves common_args = { \"host\" : self . _base_transport_args . host , \"port\" : self . _base_transport_args . port , \"username\" : self . plugin_transport_args . auth_username , \"known_hosts\" : None , \"agent_path\" : None , \"config\" : self . plugin_transport_args . ssh_config_file , } try : self . session : SSHClientConnection = await asyncio . wait_for ( connect ( client_keys = self . plugin_transport_args . auth_private_key , password = self . plugin_transport_args . auth_password , preferred_auth = ( \"publickey\" , \"keyboard-interactive\" , \"password\" , ), ** common_args , ), timeout = self . _base_transport_args . timeout_socket , ) except PermissionDenied as exc : msg = \"all authentication methods failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) from exc except asyncio . TimeoutError as exc : msg = \"timed out opening connection to device\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) from exc # it seems we must pass a terminal type to force a pty(?) which i think we want in like... # every case?? https://invisible-island.net/ncurses/ncurses.faq.html#xterm_color # set encoding to None so we get bytes for consistency w/ other scrapli transports # request_pty seems to be safe to set to \"false\" but leaving it at auto which seems closer # to the default behavior. With this omitted (as was previously) connecting to junos devices # on port 830 worked w/ system transport but *not* asyncssh because the pty request failed try : self . stdin , self . stdout , _ = await self . session . open_session ( term_type = \"xterm\" , encoding = None , subsystem = \"netconf\" , request_pty = \"auto\" ) except ChannelOpenError as exc : msg = ( \"Failed to open Channel -- do you have the right port? Most often the netconf \" \"port is 22 or 830!\" ) self . logger . critical ( msg ) raise ScrapliConnectionNotOpened ( msg ) from exc if not self . session : raise ScrapliConnectionNotOpened if self . plugin_transport_args . auth_strict_key : self . logger . debug ( f \"Attempting to validate { self . _base_transport_args . host } public key is in known \" f \"hosts and is valid\" ) self . _verify_key_value ()","title":"transport"},{"location":"reference/transport/plugins/asyncssh/transport/#transport.plugins.asyncssh.transport.NetconfAsyncsshTransport","text":"Bases: AsyncsshTransport Source code in transport/plugins/asyncssh/transport.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 class NetconfAsyncsshTransport ( AsyncsshTransport ): async def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: ScrapliAuthenticationFailed: if auth fails ScrapliConnectionNotOpened: if connection cant be opened (but is not an auth failure) \"\"\" if self . plugin_transport_args . auth_strict_key : self . logger . debug ( f \"Attempting to validate { self . _base_transport_args . host } public key is in known \" f \"hosts\" ) self . _verify_key () # we already fetched host/port/user from the user input and/or the ssh config file, so we # want to use those explicitly. likewise we pass config file we already found. set known # hosts and agent to None so we can not have an agent and deal w/ known hosts ourselves common_args = { \"host\" : self . _base_transport_args . host , \"port\" : self . _base_transport_args . port , \"username\" : self . plugin_transport_args . auth_username , \"known_hosts\" : None , \"agent_path\" : None , \"config\" : self . plugin_transport_args . ssh_config_file , } try : self . session : SSHClientConnection = await asyncio . wait_for ( connect ( client_keys = self . plugin_transport_args . auth_private_key , password = self . plugin_transport_args . auth_password , preferred_auth = ( \"publickey\" , \"keyboard-interactive\" , \"password\" , ), ** common_args , ), timeout = self . _base_transport_args . timeout_socket , ) except PermissionDenied as exc : msg = \"all authentication methods failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) from exc except asyncio . TimeoutError as exc : msg = \"timed out opening connection to device\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) from exc # it seems we must pass a terminal type to force a pty(?) which i think we want in like... # every case?? https://invisible-island.net/ncurses/ncurses.faq.html#xterm_color # set encoding to None so we get bytes for consistency w/ other scrapli transports # request_pty seems to be safe to set to \"false\" but leaving it at auto which seems closer # to the default behavior. With this omitted (as was previously) connecting to junos devices # on port 830 worked w/ system transport but *not* asyncssh because the pty request failed try : self . stdin , self . stdout , _ = await self . session . open_session ( term_type = \"xterm\" , encoding = None , subsystem = \"netconf\" , request_pty = \"auto\" ) except ChannelOpenError as exc : msg = ( \"Failed to open Channel -- do you have the right port? Most often the netconf \" \"port is 22 or 830!\" ) self . logger . critical ( msg ) raise ScrapliConnectionNotOpened ( msg ) from exc if not self . session : raise ScrapliConnectionNotOpened if self . plugin_transport_args . auth_strict_key : self . logger . debug ( f \"Attempting to validate { self . _base_transport_args . host } public key is in known \" f \"hosts and is valid\" ) self . _verify_key_value ()","title":"NetconfAsyncsshTransport"},{"location":"reference/transport/plugins/asyncssh/transport/#transport.plugins.asyncssh.transport.NetconfAsyncsshTransport.open_netconf","text":"Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Returns: Type Description None None Raises: Type Description ScrapliAuthenticationFailed if auth fails ScrapliConnectionNotOpened if connection cant be opened (but is not an auth failure) Source code in transport/plugins/asyncssh/transport.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 async def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: ScrapliAuthenticationFailed: if auth fails ScrapliConnectionNotOpened: if connection cant be opened (but is not an auth failure) \"\"\" if self . plugin_transport_args . auth_strict_key : self . logger . debug ( f \"Attempting to validate { self . _base_transport_args . host } public key is in known \" f \"hosts\" ) self . _verify_key () # we already fetched host/port/user from the user input and/or the ssh config file, so we # want to use those explicitly. likewise we pass config file we already found. set known # hosts and agent to None so we can not have an agent and deal w/ known hosts ourselves common_args = { \"host\" : self . _base_transport_args . host , \"port\" : self . _base_transport_args . port , \"username\" : self . plugin_transport_args . auth_username , \"known_hosts\" : None , \"agent_path\" : None , \"config\" : self . plugin_transport_args . ssh_config_file , } try : self . session : SSHClientConnection = await asyncio . wait_for ( connect ( client_keys = self . plugin_transport_args . auth_private_key , password = self . plugin_transport_args . auth_password , preferred_auth = ( \"publickey\" , \"keyboard-interactive\" , \"password\" , ), ** common_args , ), timeout = self . _base_transport_args . timeout_socket , ) except PermissionDenied as exc : msg = \"all authentication methods failed\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) from exc except asyncio . TimeoutError as exc : msg = \"timed out opening connection to device\" self . logger . critical ( msg ) raise ScrapliAuthenticationFailed ( msg ) from exc # it seems we must pass a terminal type to force a pty(?) which i think we want in like... # every case?? https://invisible-island.net/ncurses/ncurses.faq.html#xterm_color # set encoding to None so we get bytes for consistency w/ other scrapli transports # request_pty seems to be safe to set to \"false\" but leaving it at auto which seems closer # to the default behavior. With this omitted (as was previously) connecting to junos devices # on port 830 worked w/ system transport but *not* asyncssh because the pty request failed try : self . stdin , self . stdout , _ = await self . session . open_session ( term_type = \"xterm\" , encoding = None , subsystem = \"netconf\" , request_pty = \"auto\" ) except ChannelOpenError as exc : msg = ( \"Failed to open Channel -- do you have the right port? Most often the netconf \" \"port is 22 or 830!\" ) self . logger . critical ( msg ) raise ScrapliConnectionNotOpened ( msg ) from exc if not self . session : raise ScrapliConnectionNotOpened if self . plugin_transport_args . auth_strict_key : self . logger . debug ( f \"Attempting to validate { self . _base_transport_args . host } public key is in known \" f \"hosts and is valid\" ) self . _verify_key_value ()","title":"open_netconf()"},{"location":"reference/transport/plugins/paramiko/","text":"scrapli_netconf.transport.plugins.paramiko","title":"paramiko"},{"location":"reference/transport/plugins/paramiko/transport/","text":"scrapli_netconf.transport.plugins.paramiko.transport NetconfParamikoTransport \u00b6 Bases: ParamikoTransport Source code in transport/plugins/paramiko/transport.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class NetconfParamikoTransport ( ParamikoTransport ): def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" super () . open () def _open_channel ( self ) -> None : \"\"\" Overriding the base open_channel to invoke netconf subsystem Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self . session : raise ScrapliConnectionNotOpened self . session_channel = self . session . open_session () self . _set_timeout ( self . _base_transport_args . timeout_transport ) self . session_channel . invoke_subsystem ( \"netconf\" ) open_netconf () -> None \u00b6 Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Returns: Type Description None None Source code in transport/plugins/paramiko/transport.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" super () . open ()","title":"transport"},{"location":"reference/transport/plugins/paramiko/transport/#transport.plugins.paramiko.transport.NetconfParamikoTransport","text":"Bases: ParamikoTransport Source code in transport/plugins/paramiko/transport.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 class NetconfParamikoTransport ( ParamikoTransport ): def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" super () . open () def _open_channel ( self ) -> None : \"\"\" Overriding the base open_channel to invoke netconf subsystem Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self . session : raise ScrapliConnectionNotOpened self . session_channel = self . session . open_session () self . _set_timeout ( self . _base_transport_args . timeout_transport ) self . session_channel . invoke_subsystem ( \"netconf\" )","title":"NetconfParamikoTransport"},{"location":"reference/transport/plugins/paramiko/transport/#transport.plugins.paramiko.transport.NetconfParamikoTransport.open_netconf","text":"Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Returns: Type Description None None Source code in transport/plugins/paramiko/transport.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" super () . open ()","title":"open_netconf()"},{"location":"reference/transport/plugins/ssh2/","text":"scrapli_netconf.transport.plugins.ssh2","title":"ssh2"},{"location":"reference/transport/plugins/ssh2/transport/","text":"scrapli_netconf.transport.plugins.ssh2.transport NetconfSsh2Transport \u00b6 Bases: Ssh2Transport Source code in transport/plugins/ssh2/transport.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class NetconfSsh2Transport ( Ssh2Transport ): def open_netconf ( self ) -> bytes : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" super () . open () return b \"\" def _open_channel ( self ) -> None : \"\"\" Overriding the base open_channel to invoke netconf subsystem Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self . session : raise ScrapliConnectionNotOpened self . session_channel = self . session . open_session () self . session_channel . subsystem ( \"netconf\" ) open_netconf () -> bytes \u00b6 Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Returns: Type Description bytes None Source code in transport/plugins/ssh2/transport.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def open_netconf ( self ) -> bytes : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" super () . open () return b \"\"","title":"transport"},{"location":"reference/transport/plugins/ssh2/transport/#transport.plugins.ssh2.transport.NetconfSsh2Transport","text":"Bases: Ssh2Transport Source code in transport/plugins/ssh2/transport.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class NetconfSsh2Transport ( Ssh2Transport ): def open_netconf ( self ) -> bytes : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" super () . open () return b \"\" def _open_channel ( self ) -> None : \"\"\" Overriding the base open_channel to invoke netconf subsystem Args: N/A Returns: None Raises: ScrapliConnectionNotOpened: if session is unopened/None \"\"\" if not self . session : raise ScrapliConnectionNotOpened self . session_channel = self . session . open_session () self . session_channel . subsystem ( \"netconf\" )","title":"NetconfSsh2Transport"},{"location":"reference/transport/plugins/ssh2/transport/#transport.plugins.ssh2.transport.NetconfSsh2Transport.open_netconf","text":"Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Returns: Type Description bytes None Source code in transport/plugins/ssh2/transport.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def open_netconf ( self ) -> bytes : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" super () . open () return b \"\"","title":"open_netconf()"},{"location":"reference/transport/plugins/system/","text":"scrapli_netconf.transport.plugins.system","title":"system"},{"location":"reference/transport/plugins/system/transport/","text":"scrapli_netconf.transport.plugins.system.transport NetconfSystemTransport \u00b6 Bases: SystemTransport Source code in transport/plugins/system/transport.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class NetconfSystemTransport ( SystemTransport ): def __init__ ( self , base_transport_args : BaseTransportArgs , plugin_transport_args : PluginTransportArgs ): self . write_chunk_size = 65535 super () . __init__ ( base_transport_args = base_transport_args , plugin_transport_args = plugin_transport_args ) def _build_open_cmd ( self ) -> None : super () . _build_open_cmd () # JunOS devices do not allocate pty on port 830 on some (all?) platforms, users can cause # system transport to *not* force the pty (forcing pty is *default behavior*) by setting the # transport arg `netconf_force_pty` to `False`. This defaults to `True` (forcing a pty) as # that has been the default behavior for a while and seems to work in almost all cases, # additionally without this -- in pytest (only in pytest for some reason?) output seems to # come from devices out of order causing all the echo check logic to break... with this pty # being forced that seems to never occur. Worth digging into more at some point... if self . _base_transport_args . transport_options . get ( \"netconf_force_pty\" , True ) is True : self . open_cmd . append ( \"-tt\" ) self . open_cmd . extend ([ \"-s\" , \"netconf\" ]) self . logger . debug ( f \"final open_cmd: { self . open_cmd } \" ) def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" self . open () def write ( self , channel_input : bytes ) -> None : if not self . session : raise ScrapliConnectionNotOpened if self . write_chunk_size <= 0 : self . session . write ( channel_input ) else : bytes_to_send_len = len ( channel_input ) bytes_to_send = BytesIO ( channel_input ) bytes_sent = 0 while bytes_sent < bytes_to_send_len : self . session . write ( bytes_to_send . read ( self . write_chunk_size )) bytes_sent += self . write_chunk_size open_netconf () -> None \u00b6 Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Returns: Type Description None None Source code in transport/plugins/system/transport.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" self . open ()","title":"transport"},{"location":"reference/transport/plugins/system/transport/#transport.plugins.system.transport.NetconfSystemTransport","text":"Bases: SystemTransport Source code in transport/plugins/system/transport.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 class NetconfSystemTransport ( SystemTransport ): def __init__ ( self , base_transport_args : BaseTransportArgs , plugin_transport_args : PluginTransportArgs ): self . write_chunk_size = 65535 super () . __init__ ( base_transport_args = base_transport_args , plugin_transport_args = plugin_transport_args ) def _build_open_cmd ( self ) -> None : super () . _build_open_cmd () # JunOS devices do not allocate pty on port 830 on some (all?) platforms, users can cause # system transport to *not* force the pty (forcing pty is *default behavior*) by setting the # transport arg `netconf_force_pty` to `False`. This defaults to `True` (forcing a pty) as # that has been the default behavior for a while and seems to work in almost all cases, # additionally without this -- in pytest (only in pytest for some reason?) output seems to # come from devices out of order causing all the echo check logic to break... with this pty # being forced that seems to never occur. Worth digging into more at some point... if self . _base_transport_args . transport_options . get ( \"netconf_force_pty\" , True ) is True : self . open_cmd . append ( \"-tt\" ) self . open_cmd . extend ([ \"-s\" , \"netconf\" ]) self . logger . debug ( f \"final open_cmd: { self . open_cmd } \" ) def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" self . open () def write ( self , channel_input : bytes ) -> None : if not self . session : raise ScrapliConnectionNotOpened if self . write_chunk_size <= 0 : self . session . write ( channel_input ) else : bytes_to_send_len = len ( channel_input ) bytes_to_send = BytesIO ( channel_input ) bytes_sent = 0 while bytes_sent < bytes_to_send_len : self . session . write ( bytes_to_send . read ( self . write_chunk_size )) bytes_sent += self . write_chunk_size","title":"NetconfSystemTransport"},{"location":"reference/transport/plugins/system/transport/#transport.plugins.system.transport.NetconfSystemTransport.open_netconf","text":"Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Returns: Type Description None None Source code in transport/plugins/system/transport.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def open_netconf ( self ) -> None : \"\"\" Netconf open method Simply calls the \"normal\" open method, but retaining an explicit \"netconf\" open for sanity Args: N/A Returns: None Raises: N/A \"\"\" self . open ()","title":"open_netconf()"},{"location":"user_guide/advanced_usage/","text":"Advanced Usage \u00b6 Capabilities \u00b6 Netconf capabilities are exchanged when the session is opened. scrapli_netconf stores the server's capabilities in the aptly named server_capabilities attribute of the driver. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> from scrapli_netconf.driver import NetconfDriver >>> >>> my_device = { ... \"host\" : \"172.18.0.13\" , ... \"auth_username\" : \"vrnetlab\" , ... \"auth_password\" : \"VR-netlab9\" , ... \"auth_strict_key\" : False , ... \"port\" : 830 ... } >>> conn = NetconfDriver ( ** my_device ) >>> conn . open () >>> conn . server_capabilities [ 'urn:ietf:params:netconf:base:1.1' , 'urn:ietf:params:netconf:capability:candidate:1.0' ] Capabilities truncated for readability As for capabilities that scrapli_netconf sends to the server, that depends on the capabilities advertised from the server! If netconf base 1.1 is in the advertised capabilities then scrapli_netconf will advertise netconf 1.1 capabilities, otherwise it will advertise 1.0 capabilities. Datastores \u00b6 scrapli_netconf drives contain an option strict_datastores which defaults to False . If this option is set to True scrapli will raise a ValueError when attempting to perform an operation against a datastore that has not been advertised as a capability by the server. With this option left to the default value of False , scrapli_netconf will simply issue a user warning. Using a Different Transport \u00b6 Just like scrapli \"core\" -- scrapli-netconf supports using different libraries for \"transport\" -- or the actual SSH communication piece. By default, and like scrapli \"core\", scrapli-netconf uses the \"system\" transport. This \"system \" transport means that scrapli-netconf has no external dependencies (other than lxml !) as it just relies on what is available on the machine running the scrapli script. If you wish to swap this out, scrapli-netconf also supports the paramiko , ssh2 , and asyncssh scrapli transport plugins. Like scrapli \"core\", transport selection can be made when instantiating the scrapli connection object by passing in paramiko , ssh2 , asyncssh \" to force scrapli to use the corresponding transport mechanism. If you are using the asyncssh transport you must use the AsyncNetconfScrape driver! While it will be a goal to ensure that these other transport mechanisms are supported and useful, the focus of scrapli development will be on the \"system\" SSH transport. Example using ssh2 as the transport: 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli_netconf import NetconfDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"transport\" : \"ssh2\" } with NetconfDriver ( ** my_device ) as conn : print ( conn . get_config ()) A Note about Filters \u00b6 The filter_ string value for the get and get_config methods may contain multiple xml elements at its \"root\" (for subtree filters) -- when cast to an lxml etree object this would normally result in the first filter being the only element in the resulting object. This is because etree.fromstring assumes (rather correctly) that this is the root of the document, and it ignores the remaining filter elements. In example, given the following string data: 1 2 3 4 5 6 7 <interface-configurations xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-ifmgr-cfg\"> <interface-configuration> <active>act</active> </interface-configuration> </interface-configurations> <netconf-yang xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-man-netconf-cfg\"> </netconf-yang> The resulting lxml object (when re-dumped back to string) would look like this: 1 2 3 4 5 <interface-configurations xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-ifmgr-cfg\"> <interface-configuration> <active>act</active> </interface-configuration> </interface-configurations> This is.... shall we say not ideal if we want to pass in a string like the previous section to filter for multiple things in our config. To cope with this scrapli_netconf will wrap the user provided string filter in a \"tmp\" tag, which allows us to load up the filter with all element(s) intact; we then simply ditch the outer temp tag when placing the filter element(s) into the final filter payload, allowing users to simply provide a big string containing as many or few filters as they want. If you preferred to craft your payloads more... \"correctly\" shall we say, then you are welcome to do so, and provide the valid lxml object to the rpc method. The rpc method does nothing but wrap the provided element in the outer-most xml tags needed for a NETCONF payload, so your provided element would need to contain the get/filter/edit/etc. tags as appropriate!","title":"Advanced Usage"},{"location":"user_guide/advanced_usage/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"user_guide/advanced_usage/#capabilities","text":"Netconf capabilities are exchanged when the session is opened. scrapli_netconf stores the server's capabilities in the aptly named server_capabilities attribute of the driver. 1 2 3 4 5 6 7 8 9 10 11 12 13 >>> from scrapli_netconf.driver import NetconfDriver >>> >>> my_device = { ... \"host\" : \"172.18.0.13\" , ... \"auth_username\" : \"vrnetlab\" , ... \"auth_password\" : \"VR-netlab9\" , ... \"auth_strict_key\" : False , ... \"port\" : 830 ... } >>> conn = NetconfDriver ( ** my_device ) >>> conn . open () >>> conn . server_capabilities [ 'urn:ietf:params:netconf:base:1.1' , 'urn:ietf:params:netconf:capability:candidate:1.0' ] Capabilities truncated for readability As for capabilities that scrapli_netconf sends to the server, that depends on the capabilities advertised from the server! If netconf base 1.1 is in the advertised capabilities then scrapli_netconf will advertise netconf 1.1 capabilities, otherwise it will advertise 1.0 capabilities.","title":"Capabilities"},{"location":"user_guide/advanced_usage/#datastores","text":"scrapli_netconf drives contain an option strict_datastores which defaults to False . If this option is set to True scrapli will raise a ValueError when attempting to perform an operation against a datastore that has not been advertised as a capability by the server. With this option left to the default value of False , scrapli_netconf will simply issue a user warning.","title":"Datastores"},{"location":"user_guide/advanced_usage/#using-a-different-transport","text":"Just like scrapli \"core\" -- scrapli-netconf supports using different libraries for \"transport\" -- or the actual SSH communication piece. By default, and like scrapli \"core\", scrapli-netconf uses the \"system\" transport. This \"system \" transport means that scrapli-netconf has no external dependencies (other than lxml !) as it just relies on what is available on the machine running the scrapli script. If you wish to swap this out, scrapli-netconf also supports the paramiko , ssh2 , and asyncssh scrapli transport plugins. Like scrapli \"core\", transport selection can be made when instantiating the scrapli connection object by passing in paramiko , ssh2 , asyncssh \" to force scrapli to use the corresponding transport mechanism. If you are using the asyncssh transport you must use the AsyncNetconfScrape driver! While it will be a goal to ensure that these other transport mechanisms are supported and useful, the focus of scrapli development will be on the \"system\" SSH transport. Example using ssh2 as the transport: 1 2 3 4 5 6 7 8 9 10 11 12 from scrapli_netconf import NetconfDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"transport\" : \"ssh2\" } with NetconfDriver ( ** my_device ) as conn : print ( conn . get_config ())","title":"Using a Different Transport"},{"location":"user_guide/advanced_usage/#a-note-about-filters","text":"The filter_ string value for the get and get_config methods may contain multiple xml elements at its \"root\" (for subtree filters) -- when cast to an lxml etree object this would normally result in the first filter being the only element in the resulting object. This is because etree.fromstring assumes (rather correctly) that this is the root of the document, and it ignores the remaining filter elements. In example, given the following string data: 1 2 3 4 5 6 7 <interface-configurations xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-ifmgr-cfg\"> <interface-configuration> <active>act</active> </interface-configuration> </interface-configurations> <netconf-yang xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-man-netconf-cfg\"> </netconf-yang> The resulting lxml object (when re-dumped back to string) would look like this: 1 2 3 4 5 <interface-configurations xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-ifmgr-cfg\"> <interface-configuration> <active>act</active> </interface-configuration> </interface-configurations> This is.... shall we say not ideal if we want to pass in a string like the previous section to filter for multiple things in our config. To cope with this scrapli_netconf will wrap the user provided string filter in a \"tmp\" tag, which allows us to load up the filter with all element(s) intact; we then simply ditch the outer temp tag when placing the filter element(s) into the final filter payload, allowing users to simply provide a big string containing as many or few filters as they want. If you preferred to craft your payloads more... \"correctly\" shall we say, then you are welcome to do so, and provide the valid lxml object to the rpc method. The rpc method does nothing but wrap the provided element in the outer-most xml tags needed for a NETCONF payload, so your provided element would need to contain the get/filter/edit/etc. tags as appropriate!","title":"A Note about Filters"},{"location":"user_guide/basic_usage/","text":"Basic Usage \u00b6 Picking the right Driver \u00b6 Because netconf is a standard we don't need to deal with \"platform\" type drivers for scrapli_netconf! Instead, there are only two options -- NetconfDriver or AsyncNetconfDriver , these can be imported from scrapli_netconf.driver like so: 1 2 from scrapli_netconf.driver import NetconfDriver from scrapli_netconf.driver import AsyncNetconfDriver Note: if you are using async you must set the transport to asyncssh -- this is the only async transport supported at this time! Basic Driver Arguments \u00b6 The drivers of course need some information about the device you are trying to connect to. The most common arguments to provide to the driver are outlined below: Argument Purpose/Value host name/ip of host to connect to port port of host to connect to (defaults to port 830) auth_username username for authentication auth_password password for authentication auth_secondary password for secondary authentication (enable password) auth_private_key private key for authentication auth_strict_key strict key checking -- TRUE by default! ssh_config_file True/False or path to ssh config file to use strip_namespaces True/False strip namespaces from returned XML (default False) These arguments may be passed as keyword arguments to the driver of your choice, or, commonly are passed via dictionary unpacking as show below: 1 2 3 4 5 6 7 8 9 10 11 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , } conn = NetconfDriver ( ** my_device ) conn . open () NOTE that scrapli enables strict host key checking by default! Opening and Closing a Connection \u00b6 scrapli_netconf does not open the connection for you when creating your scrapli connection object in normal operations , you must manually call the open method prior to sending any commands to the device as shown below. ```python from scrapli_netconf.driver import NetconfDriver my_device = { \"host\": \"172.18.0.11\", \"auth_username\": \"vrnetlab\", \"auth_password\": \"VR-netlab9\", \"auth_strict_key\": False, } conn = NetconfDriver(**my_device) conn.open() response = conn.get_config(source=\"running\") 1 2 3 4 Connections can be closed by calling the `close` method: ```python conn.close() Get Config \u00b6 Configurations can be retrieved from datastores on a netconf device using the get-config netconf method. The get_config method accepts a source argument which must refer to an available datastore on the device -- options for this would be one of: running startup candidate 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } conn = NetconfDriver ( ** my_device ) conn . open () response = conn . get_config ( source = \"running\" ) print ( response . result ) Get \u00b6 Much like get-config , the get method can be used to get data from the device, generally \"operational\" or \"show \" type data. The get method requires a \"filter\" to be applied in order to identify the data to get -- this filter can be one of two types -- \"subtree\" (default) or \"xpath\". In the context of network devices it seems that not many devices support \"xpath\" filters (only IOSXE with netconf 1.1 of the tested platforms supports xpath for example). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } filter_ = \"\"\" <components xmlns=\"http://openconfig.net/yang/platform\"> <component> <state> </state> </component> </components>\"\"\" conn = NetconfDriver ( ** my_device ) conn . open () response = conn . get ( filter_ = filter_ , filter_type = \"subtree\" ) print ( response . result ) Lock and Unlock \u00b6 Netconf provides the ability to lock a configuration datastore. Much like get-config a target datastore must be provided, and is dependent on the capabilities of the platform you are interacting with. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } conn = NetconfDriver ( ** my_device ) conn . open () response = conn . lock ( target = \"candidate\" ) print ( response . result ) response = conn . unlock ( target = \"candidate\" ) print ( response . result ) Commit and Discard \u00b6 If your platform supports commit operations (IOS-XR and Junos in the context of scrapli_netconf tested platforms ), any changes created using the edit-config method will need to be committed (or discarded). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } conn = NetconfDriver ( ** my_device ) conn . open () response = conn . commit () print ( response . result ) response = conn . discard () print ( response . result ) Edit Config \u00b6 To edit configs, simply use the edit_config method with an appropriate config payload and target. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } cdp_config = \"\"\" <config> <cdp xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-cdp-cfg\"> <timer>80</timer> <enable>true</enable> <log-adjacency></log-adjacency> <hold-time>200</hold-time> <advertise-v1-only></advertise-v1-only> </cdp> </config> \"\"\" conn = NetconfDriver ( ** my_device ) conn . open () result = conn . edit_config ( config = cdp_config , target = \"candidate\" ) print ( result . result ) Delete Config \u00b6 Some devices may allow you to delete a candidate/startup configuration. You can do so with the delete_config method ; note that this is only currently tested on Junos as the test environment IOSXR version does not support this method . Per the RFC, \"running\" is never a valid target; scrapli_netconf will produce a warning indicating this if \"running\" is set as the target; if strict_datastores is set to True an exception will be raised. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } conn = NetconfDriver ( ** my_device ) conn . open () result = conn . delete_config ( target = \"candidate\" ) print ( result . result ) RPC \u00b6 The rpc method is a \"bare-bones\" rpc call which does not apply any formatting/standardization beyond the outer most rpc tag. Generally this is used for Juniper devices and the \"bare rpc\" type calls supported on junos devices not supporting/using models (YANG/IETF/etc.), but can of course be used to send any kind of custom crafted rpc you'd like! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.15\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 22 } commit_filter = \"\"\" <get-commit-revision-information> <level>detail</level> </get-commit-revision-information> \"\"\" conn = NetconfDriver ( ** my_device ) conn . open () result = conn . rpc ( filter_ = commit_filter ) print ( result . result )","title":"Basic Usage"},{"location":"user_guide/basic_usage/#basic-usage","text":"","title":"Basic Usage"},{"location":"user_guide/basic_usage/#picking-the-right-driver","text":"Because netconf is a standard we don't need to deal with \"platform\" type drivers for scrapli_netconf! Instead, there are only two options -- NetconfDriver or AsyncNetconfDriver , these can be imported from scrapli_netconf.driver like so: 1 2 from scrapli_netconf.driver import NetconfDriver from scrapli_netconf.driver import AsyncNetconfDriver Note: if you are using async you must set the transport to asyncssh -- this is the only async transport supported at this time!","title":"Picking the right Driver"},{"location":"user_guide/basic_usage/#basic-driver-arguments","text":"The drivers of course need some information about the device you are trying to connect to. The most common arguments to provide to the driver are outlined below: Argument Purpose/Value host name/ip of host to connect to port port of host to connect to (defaults to port 830) auth_username username for authentication auth_password password for authentication auth_secondary password for secondary authentication (enable password) auth_private_key private key for authentication auth_strict_key strict key checking -- TRUE by default! ssh_config_file True/False or path to ssh config file to use strip_namespaces True/False strip namespaces from returned XML (default False) These arguments may be passed as keyword arguments to the driver of your choice, or, commonly are passed via dictionary unpacking as show below: 1 2 3 4 5 6 7 8 9 10 11 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.11\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , } conn = NetconfDriver ( ** my_device ) conn . open () NOTE that scrapli enables strict host key checking by default!","title":"Basic Driver Arguments"},{"location":"user_guide/basic_usage/#opening-and-closing-a-connection","text":"scrapli_netconf does not open the connection for you when creating your scrapli connection object in normal operations , you must manually call the open method prior to sending any commands to the device as shown below. ```python from scrapli_netconf.driver import NetconfDriver my_device = { \"host\": \"172.18.0.11\", \"auth_username\": \"vrnetlab\", \"auth_password\": \"VR-netlab9\", \"auth_strict_key\": False, } conn = NetconfDriver(**my_device) conn.open() response = conn.get_config(source=\"running\") 1 2 3 4 Connections can be closed by calling the `close` method: ```python conn.close()","title":"Opening and Closing a Connection"},{"location":"user_guide/basic_usage/#get-config","text":"Configurations can be retrieved from datastores on a netconf device using the get-config netconf method. The get_config method accepts a source argument which must refer to an available datastore on the device -- options for this would be one of: running startup candidate 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } conn = NetconfDriver ( ** my_device ) conn . open () response = conn . get_config ( source = \"running\" ) print ( response . result )","title":"Get Config"},{"location":"user_guide/basic_usage/#get","text":"Much like get-config , the get method can be used to get data from the device, generally \"operational\" or \"show \" type data. The get method requires a \"filter\" to be applied in order to identify the data to get -- this filter can be one of two types -- \"subtree\" (default) or \"xpath\". In the context of network devices it seems that not many devices support \"xpath\" filters (only IOSXE with netconf 1.1 of the tested platforms supports xpath for example). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } filter_ = \"\"\" <components xmlns=\"http://openconfig.net/yang/platform\"> <component> <state> </state> </component> </components>\"\"\" conn = NetconfDriver ( ** my_device ) conn . open () response = conn . get ( filter_ = filter_ , filter_type = \"subtree\" ) print ( response . result )","title":"Get"},{"location":"user_guide/basic_usage/#lock-and-unlock","text":"Netconf provides the ability to lock a configuration datastore. Much like get-config a target datastore must be provided, and is dependent on the capabilities of the platform you are interacting with. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } conn = NetconfDriver ( ** my_device ) conn . open () response = conn . lock ( target = \"candidate\" ) print ( response . result ) response = conn . unlock ( target = \"candidate\" ) print ( response . result )","title":"Lock and Unlock"},{"location":"user_guide/basic_usage/#commit-and-discard","text":"If your platform supports commit operations (IOS-XR and Junos in the context of scrapli_netconf tested platforms ), any changes created using the edit-config method will need to be committed (or discarded). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } conn = NetconfDriver ( ** my_device ) conn . open () response = conn . commit () print ( response . result ) response = conn . discard () print ( response . result )","title":"Commit and Discard"},{"location":"user_guide/basic_usage/#edit-config","text":"To edit configs, simply use the edit_config method with an appropriate config payload and target. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } cdp_config = \"\"\" <config> <cdp xmlns=\"http://cisco.com/ns/yang/Cisco-IOS-XR-cdp-cfg\"> <timer>80</timer> <enable>true</enable> <log-adjacency></log-adjacency> <hold-time>200</hold-time> <advertise-v1-only></advertise-v1-only> </cdp> </config> \"\"\" conn = NetconfDriver ( ** my_device ) conn . open () result = conn . edit_config ( config = cdp_config , target = \"candidate\" ) print ( result . result )","title":"Edit Config"},{"location":"user_guide/basic_usage/#delete-config","text":"Some devices may allow you to delete a candidate/startup configuration. You can do so with the delete_config method ; note that this is only currently tested on Junos as the test environment IOSXR version does not support this method . Per the RFC, \"running\" is never a valid target; scrapli_netconf will produce a warning indicating this if \"running\" is set as the target; if strict_datastores is set to True an exception will be raised. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } conn = NetconfDriver ( ** my_device ) conn . open () result = conn . delete_config ( target = \"candidate\" ) print ( result . result )","title":"Delete Config"},{"location":"user_guide/basic_usage/#rpc","text":"The rpc method is a \"bare-bones\" rpc call which does not apply any formatting/standardization beyond the outer most rpc tag. Generally this is used for Juniper devices and the \"bare rpc\" type calls supported on junos devices not supporting/using models (YANG/IETF/etc.), but can of course be used to send any kind of custom crafted rpc you'd like! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.15\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 22 } commit_filter = \"\"\" <get-commit-revision-information> <level>detail</level> </get-commit-revision-information> \"\"\" conn = NetconfDriver ( ** my_device ) conn . open () result = conn . rpc ( filter_ = commit_filter ) print ( result . result )","title":"RPC"},{"location":"user_guide/faq/","text":"FAQ \u00b6 Question: Why build this? ncclient exists? Answer: After building scrapli it was apparent that it could be fairly easily extended to handle netconf connections, at the time dayjob$ had lots of netconf-y things with ncclient happening. I'm not a big fan of ncclient as I find it rather obtuse/hard to understand whats going on, and the dependency on paramiko is not super great. I figured I could support enough netconf things with system transport so... I did. Then it was fairly trivial to add asyncssh to support netconf with asyncio! Question: Is this better than ncclient? Answer: Nope! Supporting asyncio may be a killer use case for some, but otherwise ncclient and scrapli_netconf accomplish much of the same things -- probably with ncclient having a wider/deeper range of netconf rfc support . Net/net though is they are just different! Use whichever you prefer! Question: Is this easy to use? Answer: Biased, but I think so! A big part of the goal of all of this was to have a consistent feel across ssh and netconf both with sync and async support, and (again, biased) I think that has been achieved. Other questions? Ask away!","title":"FAQ"},{"location":"user_guide/faq/#faq","text":"Question: Why build this? ncclient exists? Answer: After building scrapli it was apparent that it could be fairly easily extended to handle netconf connections, at the time dayjob$ had lots of netconf-y things with ncclient happening. I'm not a big fan of ncclient as I find it rather obtuse/hard to understand whats going on, and the dependency on paramiko is not super great. I figured I could support enough netconf things with system transport so... I did. Then it was fairly trivial to add asyncssh to support netconf with asyncio! Question: Is this better than ncclient? Answer: Nope! Supporting asyncio may be a killer use case for some, but otherwise ncclient and scrapli_netconf accomplish much of the same things -- probably with ncclient having a wider/deeper range of netconf rfc support . Net/net though is they are just different! Use whichever you prefer! Question: Is this easy to use? Answer: Biased, but I think so! A big part of the goal of all of this was to have a consistent feel across ssh and netconf both with sync and async support, and (again, biased) I think that has been achieved. Other questions? Ask away!","title":"FAQ"},{"location":"user_guide/installation/","text":"Installation \u00b6 Standard Installation \u00b6 As outlined in the quick start, you should be able to pip install scrapli_netconf \"normally\": 1 pip install scrapli_netconf Installing current master branch \u00b6 To install from the source repositories master branch: 1 pip install git+https://github.com/scrapli/scrapli_netconf Installing current develop branch \u00b6 To install from this repositories develop branch: 1 pip install -e git+https://github.com/scrapli/scrapli_netconf.git@develop#egg=scrapli_netconf Installation from Source \u00b6 To install from source: 1 2 3 git clone https://github.com/scrapli/scrapli_netconf cd scrapli_netconf python setup.py install Optional Extras \u00b6 Just like scrapli \"core\" scrapli_netconf tries to have as few dependencies as possible. scrapli_netconf requires scrapli (of course!) and lxml . If you would like to use any of the transport plugins that are not part of the standard library you can install those as optional extras via pip: 1 pip install scrapli_netconf[paramiko] The available optional installation extras options are: paramiko ssh2 asyncssh Supported Platforms \u00b6 As for platforms to run scrapli on -- it has and will be tested on MacOS and Ubuntu regularly and should work on any POSIX system. Windows at one point was being tested very minimally via GitHub Actions builds, however this is no longer the case as it is just not worth the effort. While scrapli/scrapli_netconf should work on Windows when using the paramiko or ssh2-python transport drivers, it is not \"officially\" supported. It is strongly recommended/preferred for folks to use WSL/Cygwin instead of Windows.","title":"Installation"},{"location":"user_guide/installation/#installation","text":"","title":"Installation"},{"location":"user_guide/installation/#standard-installation","text":"As outlined in the quick start, you should be able to pip install scrapli_netconf \"normally\": 1 pip install scrapli_netconf","title":"Standard Installation"},{"location":"user_guide/installation/#installing-current-master-branch","text":"To install from the source repositories master branch: 1 pip install git+https://github.com/scrapli/scrapli_netconf","title":"Installing current master branch"},{"location":"user_guide/installation/#installing-current-develop-branch","text":"To install from this repositories develop branch: 1 pip install -e git+https://github.com/scrapli/scrapli_netconf.git@develop#egg=scrapli_netconf","title":"Installing current develop branch"},{"location":"user_guide/installation/#installation-from-source","text":"To install from source: 1 2 3 git clone https://github.com/scrapli/scrapli_netconf cd scrapli_netconf python setup.py install","title":"Installation from Source"},{"location":"user_guide/installation/#optional-extras","text":"Just like scrapli \"core\" scrapli_netconf tries to have as few dependencies as possible. scrapli_netconf requires scrapli (of course!) and lxml . If you would like to use any of the transport plugins that are not part of the standard library you can install those as optional extras via pip: 1 pip install scrapli_netconf[paramiko] The available optional installation extras options are: paramiko ssh2 asyncssh","title":"Optional Extras"},{"location":"user_guide/installation/#supported-platforms","text":"As for platforms to run scrapli on -- it has and will be tested on MacOS and Ubuntu regularly and should work on any POSIX system. Windows at one point was being tested very minimally via GitHub Actions builds, however this is no longer the case as it is just not worth the effort. While scrapli/scrapli_netconf should work on Windows when using the paramiko or ssh2-python transport drivers, it is not \"officially\" supported. It is strongly recommended/preferred for folks to use WSL/Cygwin instead of Windows.","title":"Supported Platforms"},{"location":"user_guide/project_details/","text":"Project Details \u00b6 What is scrapli_netconf \u00b6 scrapli_netconf is a library to help send or receive netconf messages to devices, specifically routers (though could be anything speaking netconf in theory). Netconf is an IETF network management protocol that uses XML for message encoding, and SSH (or TLS, which is not supported by scrapli_netconf) for transport of messages. scrapli_netconf is simply an extension of the scrapli \"screen scraping\" library that adds proper message creation, framing, and validation to allow for scrapli to be used as a netconf client. scrapli_netconf adds new drivers ( NetconfScrape and AsyncNetconfScrape ), new transports ( NetconfTransport and AsyncNetconfTransport ), and new channels ( NetconfChannel and AsyncNetconfChannel ) all of which inherit from , and build on, the core scrapli components. scrapli_netconf also includes an extension of the Response object -- aptly named NetconfResponse that adds netconf-specific data to the existing object. A great question to ask right now is: \"why\"! The primary driver is to get ncclient like functionality without needing paramiko for the transport so that we can take full advantage of \"normal\" OpenSSH options, as well as have fewer dependencies (only absolute required dependency is lxml!). Additionally, as scrapli_netconf is just an extension of scrapli, this means that automation of devices over telnet, SSH, and netconf (over SSH) can be done all with an extremely consistent look and feel. Realistically this should cover most modes of present day network automation other than HTTP based APIs (which would likely have a pretty different look and feel anyway). Finally , but still quite important -- with the asyncssh transport plugin, scrapli_netconf provides asyncio support for netconf operations. Supported Platforms \u00b6 At this time scrapli_netconf is a base implementation of netconf 1.0 and netconf 1.1 (note that scrapli is not 100 % RFC compliant in that it currently does not support all methods/options). It should work on anything that runs those versions of netconf, but has only been tested against the following platforms/versions: Cisco IOS-XE (tested on: 16.12.03) with Netconf 1.0 and 1.1 Cisco IOS-XR (tested on: 6.5.3) with Netconf 1.1 Juniper JunOS (tested on: 17.3R2.10) with Netconf 1.0 In addition to the above devices, there has been testing on various versions of Juniper SRX, QFX, and MX platforms on ~18ish+ code, as well as Cisco NCS devices on 6.6.2+ code, and finally there has been limited testing on Nokia devices.","title":"Project Details"},{"location":"user_guide/project_details/#project-details","text":"","title":"Project Details"},{"location":"user_guide/project_details/#what-is-scrapli_netconf","text":"scrapli_netconf is a library to help send or receive netconf messages to devices, specifically routers (though could be anything speaking netconf in theory). Netconf is an IETF network management protocol that uses XML for message encoding, and SSH (or TLS, which is not supported by scrapli_netconf) for transport of messages. scrapli_netconf is simply an extension of the scrapli \"screen scraping\" library that adds proper message creation, framing, and validation to allow for scrapli to be used as a netconf client. scrapli_netconf adds new drivers ( NetconfScrape and AsyncNetconfScrape ), new transports ( NetconfTransport and AsyncNetconfTransport ), and new channels ( NetconfChannel and AsyncNetconfChannel ) all of which inherit from , and build on, the core scrapli components. scrapli_netconf also includes an extension of the Response object -- aptly named NetconfResponse that adds netconf-specific data to the existing object. A great question to ask right now is: \"why\"! The primary driver is to get ncclient like functionality without needing paramiko for the transport so that we can take full advantage of \"normal\" OpenSSH options, as well as have fewer dependencies (only absolute required dependency is lxml!). Additionally, as scrapli_netconf is just an extension of scrapli, this means that automation of devices over telnet, SSH, and netconf (over SSH) can be done all with an extremely consistent look and feel. Realistically this should cover most modes of present day network automation other than HTTP based APIs (which would likely have a pretty different look and feel anyway). Finally , but still quite important -- with the asyncssh transport plugin, scrapli_netconf provides asyncio support for netconf operations.","title":"What is scrapli_netconf"},{"location":"user_guide/project_details/#supported-platforms","text":"At this time scrapli_netconf is a base implementation of netconf 1.0 and netconf 1.1 (note that scrapli is not 100 % RFC compliant in that it currently does not support all methods/options). It should work on anything that runs those versions of netconf, but has only been tested against the following platforms/versions: Cisco IOS-XE (tested on: 16.12.03) with Netconf 1.0 and 1.1 Cisco IOS-XR (tested on: 6.5.3) with Netconf 1.1 Juniper JunOS (tested on: 17.3R2.10) with Netconf 1.0 In addition to the above devices, there has been testing on various versions of Juniper SRX, QFX, and MX platforms on ~18ish+ code, as well as Cisco NCS devices on 6.6.2+ code, and finally there has been limited testing on Nokia devices.","title":"Supported Platforms"},{"location":"user_guide/quickstart/","text":"Quick Start Guide \u00b6 Installation \u00b6 In most cases installation via pip is the simplest and best way to install scrapli_netconf. See here for advanced installation details. 1 pip install scrapli-netconf A Simple Example \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } conn = NetconfDriver ( ** my_device ) conn . open () response = conn . get_config ( source = \"running\" ) print ( response . result ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 $ python my_scrapli_script.py <rpc-reply message-id=\"101\"> <data> <ssh> <server> <v2/> <netconf>830</netconf> <netconf-vrf-table> <vrf> <vrf-name>default</vrf-name> <enable/> </vrf> </netconf-vrf-table> </server> </ssh> <interface-configurations> <interface-configuration> <active>act</active> <interface-name>MgmtEth0/RP0/CPU0/0</interface-name> <SNIP> </data> </rpc-reply> More Examples \u00b6 Basic Operations IOS-XR Basic Operations Junos Edit Config IOS-XR Asyncio Edit Config IOS-XR","title":"Quick Start Guide"},{"location":"user_guide/quickstart/#quick-start-guide","text":"","title":"Quick Start Guide"},{"location":"user_guide/quickstart/#installation","text":"In most cases installation via pip is the simplest and best way to install scrapli_netconf. See here for advanced installation details. 1 pip install scrapli-netconf","title":"Installation"},{"location":"user_guide/quickstart/#a-simple-example","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 from scrapli_netconf.driver import NetconfDriver my_device = { \"host\" : \"172.18.0.13\" , \"auth_username\" : \"vrnetlab\" , \"auth_password\" : \"VR-netlab9\" , \"auth_strict_key\" : False , \"port\" : 830 } conn = NetconfDriver ( ** my_device ) conn . open () response = conn . get_config ( source = \"running\" ) print ( response . result ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 $ python my_scrapli_script.py <rpc-reply message-id=\"101\"> <data> <ssh> <server> <v2/> <netconf>830</netconf> <netconf-vrf-table> <vrf> <vrf-name>default</vrf-name> <enable/> </vrf> </netconf-vrf-table> </server> </ssh> <interface-configurations> <interface-configuration> <active>act</active> <interface-name>MgmtEth0/RP0/CPU0/0</interface-name> <SNIP> </data> </rpc-reply>","title":"A Simple Example"},{"location":"user_guide/quickstart/#more-examples","text":"Basic Operations IOS-XR Basic Operations Junos Edit Config IOS-XR Asyncio Edit Config IOS-XR","title":"More Examples"},{"location":"user_guide/versioning/","text":"Versioning \u00b6 Just like scrapli, scrapli_netconf uses the CalVer versioning standard. All release versions follow the format YYYY.MM.DD , however PyPi will shorten/standardize this to remove leading zeros. The reason for choosing CalVer is simply to make it very clear how old a given release of scrapli is. While there are clearly some potential challenges around indicating when a \"breaking\" change occurs due to there not being the concept of a \"major\" version, this is hopefully not too big a deal for scrapli, and thus far the \"core\" API has been very stable -- there are only so many things you can/need to do over SSH after all! Please also note that the CHANGELOG contains notes about each version (and is updated in develop branch while updates are happening). A final note regarding versioning: scrapli updates are released as often as necessary/there are things to update . This means you should ALWAYS PIN YOUR REQUIREMENTS when using scrapli!! As stated, the \"core\" API has been very stable, but things will change over time -- always pin your requirements, and keep an eye on the changelog/api docs -- you can \"watch\" this repository to ensure you are notified of any releases.","title":"Versioning"},{"location":"user_guide/versioning/#versioning","text":"Just like scrapli, scrapli_netconf uses the CalVer versioning standard. All release versions follow the format YYYY.MM.DD , however PyPi will shorten/standardize this to remove leading zeros. The reason for choosing CalVer is simply to make it very clear how old a given release of scrapli is. While there are clearly some potential challenges around indicating when a \"breaking\" change occurs due to there not being the concept of a \"major\" version, this is hopefully not too big a deal for scrapli, and thus far the \"core\" API has been very stable -- there are only so many things you can/need to do over SSH after all! Please also note that the CHANGELOG contains notes about each version (and is updated in develop branch while updates are happening). A final note regarding versioning: scrapli updates are released as often as necessary/there are things to update . This means you should ALWAYS PIN YOUR REQUIREMENTS when using scrapli!! As stated, the \"core\" API has been very stable, but things will change over time -- always pin your requirements, and keep an eye on the changelog/api docs -- you can \"watch\" this repository to ensure you are notified of any releases.","title":"Versioning"}]}